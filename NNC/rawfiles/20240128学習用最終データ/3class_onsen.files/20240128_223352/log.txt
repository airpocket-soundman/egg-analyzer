2024-01-28 22:33:52,284 Training process is started.
python "C:\Users\yamas\Desktop\tools\neural_network_console\libs\Python\Lib\site-packages\nnabla\utils\cli\cli.py" train
	-c "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_223352\net.nntxt"
	-o "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_223352"
2024-01-28 22:33:52,811 [nnabla]: [CALLBACK]: Exec train on local
2024-01-28 22:33:52,817 [nnabla]: Using context "Context(backend=['cpu:float'], array_class='CpuCachedArray', device_id='')"
2024-01-28 22:33:52,818 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_test_3class_onsen.csv"
2024-01-28 22:33:53,402 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_valid_3class_onsen.csv"
2024-01-28 22:33:53,785 [nnabla]: Train with contexts ['cpu']
2024-01-28 22:33:53,806 [nnabla]: Training epoch 1 of 100 begin
2024-01-28 22:33:53,806 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 22:33:53,806 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 22:33:54,011 [nnabla]: epoch 1 of 100 cost=4.662159  {train_error=4.980042, valid_error=4.976941} time=(0.1s /9.5s) 
2024-01-28 22:33:54,103 [nnabla]: epoch 2 of 100 cost=4.418361  {train_error=4.210324, valid_error=4.197601} time=(0.2s /12.5s) 
2024-01-28 22:33:54,189 [nnabla]: epoch 3 of 100 cost=4.156658  {train_error=4.016147, valid_error=4.001611} time=(0.3s /11.3s) 
2024-01-28 22:33:54,277 [nnabla]: epoch 4 of 100 cost=3.857072  {train_error=3.701254, valid_error=3.683341} time=(0.4s /10.7s) 
2024-01-28 22:33:54,373 [nnabla]: epoch 5 of 100 cost=3.608030  {train_error=3.609643, valid_error=3.587478} time=(0.5s /10.3s) 
2024-01-28 22:33:54,415 [nnabla]: epoch 6 of 100 cost=3.468773  time=(0.6s /10.1s) 
2024-01-28 22:33:54,456 [nnabla]: epoch 7 of 100 cost=3.353813  time=(0.7s /9.3s) 
2024-01-28 22:33:54,499 [nnabla]: epoch 8 of 100 cost=3.260379  time=(0.7s /8.6s) 
2024-01-28 22:33:54,540 [nnabla]: epoch 9 of 100 cost=3.170070  time=(0.7s /8.2s) 
2024-01-28 22:33:54,635 [nnabla]: epoch 10 of 100 cost=3.077657  {train_error=3.125641, valid_error=3.105278} time=(0.8s /7.8s) 
2024-01-28 22:33:54,679 [nnabla]: epoch 11 of 100 cost=3.005767  time=(0.9s /7.9s) 
2024-01-28 22:33:54,727 [nnabla]: epoch 12 of 100 cost=2.912503  time=(0.9s /7.6s) 
2024-01-28 22:33:54,770 [nnabla]: epoch 13 of 100 cost=2.845471  time=(1.0s /7.4s) 
2024-01-28 22:33:54,812 [nnabla]: epoch 14 of 100 cost=2.766552  time=(1.0s /7.2s) 
2024-01-28 22:33:54,853 [nnabla]: epoch 15 of 100 cost=2.686631  time=(1.0s /7.0s) 
2024-01-28 22:33:54,896 [nnabla]: epoch 16 of 100 cost=2.618220  time=(1.1s /6.8s) 
2024-01-28 22:33:54,939 [nnabla]: epoch 17 of 100 cost=2.539438  time=(1.1s /6.7s) 
2024-01-28 22:33:54,981 [nnabla]: epoch 18 of 100 cost=2.472112  time=(1.2s /6.5s) 
2024-01-28 22:33:55,023 [nnabla]: epoch 19 of 100 cost=2.395667  time=(1.2s /6.4s) 
2024-01-28 22:33:55,118 [nnabla]: epoch 20 of 100 cost=2.331656  {train_error=2.333420, valid_error=2.326730} time=(1.3s /6.3s) 
2024-01-28 22:33:55,160 [nnabla]: epoch 21 of 100 cost=2.268392  time=(1.4s /6.4s) 
2024-01-28 22:33:55,203 [nnabla]: epoch 22 of 100 cost=2.203143  time=(1.4s /6.4s) 
2024-01-28 22:33:55,254 [nnabla]: epoch 23 of 100 cost=2.143233  time=(1.4s /6.3s) 
2024-01-28 22:33:55,295 [nnabla]: epoch 24 of 100 cost=2.074128  time=(1.5s /6.2s) 
2024-01-28 22:33:55,337 [nnabla]: epoch 25 of 100 cost=2.024864  time=(1.5s /6.1s) 
2024-01-28 22:33:55,380 [nnabla]: epoch 26 of 100 cost=1.961396  time=(1.6s /6.0s) 
2024-01-28 22:33:55,422 [nnabla]: epoch 27 of 100 cost=1.921229  time=(1.6s /6.0s) 
2024-01-28 22:33:55,465 [nnabla]: epoch 28 of 100 cost=1.861799  time=(1.7s /5.9s) 
2024-01-28 22:33:55,507 [nnabla]: epoch 29 of 100 cost=1.793170  time=(1.7s /5.9s) 
2024-01-28 22:33:55,602 [nnabla]: epoch 30 of 100 cost=1.768714  {train_error=1.740071, valid_error=1.738610} time=(1.7s /5.8s) 
2024-01-28 22:33:55,645 [nnabla]: epoch 31 of 100 cost=1.695477  time=(1.8s /5.9s) 
2024-01-28 22:33:55,687 [nnabla]: epoch 32 of 100 cost=1.674136  time=(1.9s /5.9s) 
2024-01-28 22:33:55,729 [nnabla]: epoch 33 of 100 cost=1.606286  time=(1.9s /5.8s) 
2024-01-28 22:33:55,778 [nnabla]: epoch 34 of 100 cost=1.565558  time=(2.0s /5.8s) 
2024-01-28 22:33:55,821 [nnabla]: epoch 35 of 100 cost=1.527288  time=(2.0s /5.8s) 
2024-01-28 22:33:55,863 [nnabla]: epoch 36 of 100 cost=1.486109  time=(2.1s /5.7s) 
2024-01-28 22:33:55,904 [nnabla]: epoch 37 of 100 cost=1.453819  time=(2.1s /5.7s) 
2024-01-28 22:33:55,947 [nnabla]: epoch 38 of 100 cost=1.432980  time=(2.1s /5.6s) 
2024-01-28 22:33:55,989 [nnabla]: epoch 39 of 100 cost=1.382249  time=(2.2s /5.6s) 
2024-01-28 22:33:56,084 [nnabla]: epoch 40 of 100 cost=1.329801  {train_error=1.306702, valid_error=1.315779} time=(2.2s /5.6s) 
2024-01-28 22:33:56,124 [nnabla]: epoch 41 of 100 cost=1.319863  time=(2.3s /5.7s) 
2024-01-28 22:33:56,166 [nnabla]: epoch 42 of 100 cost=1.268744  time=(2.4s /5.6s) 
2024-01-28 22:33:56,208 [nnabla]: epoch 43 of 100 cost=1.245053  time=(2.4s /5.6s) 
2024-01-28 22:33:56,251 [nnabla]: epoch 44 of 100 cost=1.210154  time=(2.4s /5.6s) 
2024-01-28 22:33:56,308 [nnabla]: epoch 45 of 100 cost=1.187931  time=(2.5s /5.5s) 
2024-01-28 22:33:56,353 [nnabla]: epoch 46 of 100 cost=1.159901  time=(2.5s /5.5s) 
2024-01-28 22:33:56,393 [nnabla]: epoch 47 of 100 cost=1.141641  time=(2.6s /5.5s) 
2024-01-28 22:33:56,436 [nnabla]: epoch 48 of 100 cost=1.109849  time=(2.6s /5.5s) 
2024-01-28 22:33:56,480 [nnabla]: epoch 49 of 100 cost=1.082507  time=(2.7s /5.5s) 
2024-01-28 22:33:56,577 [nnabla]: epoch 50 of 100 cost=1.067896  {train_error=1.012370, valid_error=1.031725} time=(2.7s /5.4s) 
2024-01-28 22:33:56,622 [nnabla]: epoch 51 of 100 cost=1.059439  time=(2.8s /5.5s) 
2024-01-28 22:33:56,663 [nnabla]: epoch 52 of 100 cost=1.032115  time=(2.9s /5.5s) 
2024-01-28 22:33:56,705 [nnabla]: epoch 53 of 100 cost=0.994108  time=(2.9s /5.5s) 
2024-01-28 22:33:56,748 [nnabla]: epoch 54 of 100 cost=0.976108  time=(2.9s /5.4s) 
2024-01-28 22:33:56,791 [nnabla]: epoch 55 of 100 cost=0.971247  time=(3.0s /5.4s) 
2024-01-28 22:33:56,840 [nnabla]: epoch 56 of 100 cost=0.956236  time=(3.0s /5.4s) 
2024-01-28 22:33:56,884 [nnabla]: epoch 57 of 100 cost=0.948307  time=(3.1s /5.4s) 
2024-01-28 22:33:56,925 [nnabla]: epoch 58 of 100 cost=0.904357  time=(3.1s /5.4s) 
2024-01-28 22:33:56,966 [nnabla]: epoch 59 of 100 cost=0.912050  time=(3.2s /5.4s) 
2024-01-28 22:33:57,063 [nnabla]: epoch 60 of 100 cost=0.881876  {train_error=0.835446, valid_error=0.842661} time=(3.2s /5.3s) 
2024-01-28 22:33:57,105 [nnabla]: epoch 61 of 100 cost=0.870638  time=(3.3s /5.4s) 
2024-01-28 22:33:57,150 [nnabla]: epoch 62 of 100 cost=0.873000  time=(3.3s /5.4s) 
2024-01-28 22:33:57,191 [nnabla]: epoch 63 of 100 cost=0.853836  time=(3.4s /5.4s) 
2024-01-28 22:33:57,233 [nnabla]: epoch 64 of 100 cost=0.844477  time=(3.4s /5.4s) 
2024-01-28 22:33:57,274 [nnabla]: epoch 65 of 100 cost=0.838790  time=(3.5s /5.3s) 
2024-01-28 22:33:57,316 [nnabla]: epoch 66 of 100 cost=0.816910  time=(3.5s /5.3s) 
2024-01-28 22:33:57,366 [nnabla]: epoch 67 of 100 cost=0.798859  time=(3.6s /5.3s) 
2024-01-28 22:33:57,412 [nnabla]: epoch 68 of 100 cost=0.789381  time=(3.6s /5.3s) 
2024-01-28 22:33:57,453 [nnabla]: epoch 69 of 100 cost=0.784298  time=(3.6s /5.3s) 
2024-01-28 22:33:57,550 [nnabla]: epoch 70 of 100 cost=0.774511  {train_error=0.735290, valid_error=0.751136} time=(3.7s /5.3s) 
2024-01-28 22:33:57,591 [nnabla]: epoch 71 of 100 cost=0.759694  time=(3.8s /5.3s) 
2024-01-28 22:33:57,633 [nnabla]: epoch 72 of 100 cost=0.765408  time=(3.8s /5.3s) 
2024-01-28 22:33:57,675 [nnabla]: epoch 73 of 100 cost=0.741537  time=(3.9s /5.3s) 
2024-01-28 22:33:57,718 [nnabla]: epoch 74 of 100 cost=0.725357  time=(3.9s /5.3s) 
2024-01-28 22:33:57,758 [nnabla]: epoch 75 of 100 cost=0.745373  time=(4.0s /5.3s) 
2024-01-28 22:33:57,799 [nnabla]: epoch 76 of 100 cost=0.707707  time=(4.0s /5.3s) 
2024-01-28 22:33:57,841 [nnabla]: epoch 77 of 100 cost=0.726814  time=(4.0s /5.2s) 
2024-01-28 22:33:57,891 [nnabla]: epoch 78 of 100 cost=0.704804  time=(4.1s /5.2s) 
2024-01-28 22:33:57,933 [nnabla]: epoch 79 of 100 cost=0.699587  time=(4.1s /5.2s) 
2024-01-28 22:33:58,027 [nnabla]: epoch 80 of 100 cost=0.689827  {train_error=0.664692, valid_error=0.680668} time=(4.2s /5.2s) 
2024-01-28 22:33:58,070 [nnabla]: epoch 81 of 100 cost=0.697712  time=(4.3s /5.3s) 
2024-01-28 22:33:58,111 [nnabla]: epoch 82 of 100 cost=0.678569  time=(4.3s /5.3s) 
2024-01-28 22:33:58,154 [nnabla]: epoch 83 of 100 cost=0.669296  time=(4.3s /5.2s) 
2024-01-28 22:33:58,195 [nnabla]: epoch 84 of 100 cost=0.687285  time=(4.4s /5.2s) 
2024-01-28 22:33:58,237 [nnabla]: epoch 85 of 100 cost=0.657897  time=(4.4s /5.2s) 
2024-01-28 22:33:58,279 [nnabla]: epoch 86 of 100 cost=0.656478  time=(4.5s /5.2s) 
2024-01-28 22:33:58,320 [nnabla]: epoch 87 of 100 cost=0.662476  time=(4.5s /5.2s) 
2024-01-28 22:33:58,361 [nnabla]: epoch 88 of 100 cost=0.658473  time=(4.6s /5.2s) 
2024-01-28 22:33:58,412 [nnabla]: epoch 89 of 100 cost=0.642057  time=(4.6s /5.2s) 
2024-01-28 22:33:58,506 [nnabla]: epoch 90 of 100 cost=0.643855  {train_error=0.605138, valid_error=0.622121} time=(4.6s /5.2s) 
2024-01-28 22:33:58,548 [nnabla]: epoch 91 of 100 cost=0.635914  time=(4.7s /5.2s) 
2024-01-28 22:33:58,591 [nnabla]: epoch 92 of 100 cost=0.619861  time=(4.8s /5.2s) 
2024-01-28 22:33:58,635 [nnabla]: epoch 93 of 100 cost=0.646991  time=(4.8s /5.2s) 
2024-01-28 22:33:58,676 [nnabla]: epoch 94 of 100 cost=0.611399  time=(4.9s /5.2s) 
2024-01-28 22:33:58,718 [nnabla]: epoch 95 of 100 cost=0.627463  time=(4.9s /5.2s) 
2024-01-28 22:33:58,760 [nnabla]: epoch 96 of 100 cost=0.622019  time=(5.0s /5.2s) 
2024-01-28 22:33:58,802 [nnabla]: epoch 97 of 100 cost=0.615403  time=(5.0s /5.1s) 
2024-01-28 22:33:58,842 [nnabla]: epoch 98 of 100 cost=0.600982  time=(5.0s /5.1s) 
2024-01-28 22:33:58,885 [nnabla]: epoch 99 of 100 cost=0.607644  time=(5.1s /5.1s) 
2024-01-28 22:33:58,994 [nnabla]: epoch 100 of 100 cost=0.605886  {train_error=0.568989, valid_error=0.590082} time=(5.1s /5.1s) 
2024-01-28 22:33:59,009 [nnabla]: Training Completed.
NNabla command line interface (Version:1.33.1, Build:230206070804, Callback:NNabla SSH callback module.)

2024-01-28 22:30:04,287 Training process is started.
python "C:\Users\yamas\Desktop\tools\neural_network_console\libs\Python\Lib\site-packages\nnabla\utils\cli\cli.py" train
	-c "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_223004\net.nntxt"
	-o "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_223004"
2024-01-28 22:30:04,826 [nnabla]: [CALLBACK]: Exec train on local
2024-01-28 22:30:04,831 [nnabla]: Using context "Context(backend=['cpu:float'], array_class='CpuCachedArray', device_id='')"
2024-01-28 22:30:04,831 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_test_3class_onsen.csv"
2024-01-28 22:30:05,422 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_valid_3class_onsen.csv"
2024-01-28 22:30:05,812 [nnabla]: Train with contexts ['cpu']
2024-01-28 22:30:05,837 [nnabla]: Training epoch 1 of 100 begin
2024-01-28 22:30:05,837 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 22:30:05,837 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 22:30:06,041 [nnabla]: epoch 1 of 100 cost=4.339579  {train_error=3.935205, valid_error=3.906207} time=(0.1s /9.2s) 
2024-01-28 22:30:06,124 [nnabla]: epoch 2 of 100 cost=3.855546  {train_error=3.599774, valid_error=3.569825} time=(0.2s /12.2s) 
2024-01-28 22:30:06,210 [nnabla]: epoch 3 of 100 cost=3.525281  {train_error=3.478358, valid_error=3.446541} time=(0.3s /11.0s) 
2024-01-28 22:30:06,293 [nnabla]: epoch 4 of 100 cost=3.302340  {train_error=3.183724, valid_error=3.173254} time=(0.4s /10.4s) 
2024-01-28 22:30:06,386 [nnabla]: epoch 5 of 100 cost=3.115998  {train_error=3.039738, valid_error=3.031287} time=(0.5s /10.0s) 
2024-01-28 22:30:06,444 [nnabla]: epoch 6 of 100 cost=2.978561  time=(0.6s /10.1s) 
2024-01-28 22:30:06,487 [nnabla]: epoch 7 of 100 cost=2.851924  time=(0.7s /9.3s) 
2024-01-28 22:30:06,529 [nnabla]: epoch 8 of 100 cost=2.745076  time=(0.7s /8.6s) 
2024-01-28 22:30:06,569 [nnabla]: epoch 9 of 100 cost=2.635631  time=(0.7s /8.1s) 
2024-01-28 22:30:06,667 [nnabla]: epoch 10 of 100 cost=2.543230  {train_error=2.481953, valid_error=2.489574} time=(0.8s /7.8s) 
2024-01-28 22:30:06,709 [nnabla]: epoch 11 of 100 cost=2.441961  time=(0.9s /7.9s) 
2024-01-28 22:30:06,757 [nnabla]: epoch 12 of 100 cost=2.349176  time=(0.9s /7.6s) 
2024-01-28 22:30:06,801 [nnabla]: epoch 13 of 100 cost=2.265786  time=(1.0s /7.4s) 
2024-01-28 22:30:06,842 [nnabla]: epoch 14 of 100 cost=2.171574  time=(1.0s /7.2s) 
2024-01-28 22:30:06,883 [nnabla]: epoch 15 of 100 cost=2.100857  time=(1.0s /7.0s) 
2024-01-28 22:30:06,926 [nnabla]: epoch 16 of 100 cost=2.012415  time=(1.1s /6.8s) 
2024-01-28 22:30:06,967 [nnabla]: epoch 17 of 100 cost=1.939333  time=(1.1s /6.7s) 
2024-01-28 22:30:07,010 [nnabla]: epoch 18 of 100 cost=1.866259  time=(1.2s /6.5s) 
2024-01-28 22:30:07,051 [nnabla]: epoch 19 of 100 cost=1.777925  time=(1.2s /6.4s) 
2024-01-28 22:30:07,147 [nnabla]: epoch 20 of 100 cost=1.721021  {train_error=1.617664, valid_error=1.627234} time=(1.3s /6.3s) 
2024-01-28 22:30:07,189 [nnabla]: epoch 21 of 100 cost=1.645869  time=(1.4s /6.4s) 
2024-01-28 22:30:07,232 [nnabla]: epoch 22 of 100 cost=1.583684  time=(1.4s /6.3s) 
2024-01-28 22:30:07,281 [nnabla]: epoch 23 of 100 cost=1.507815  time=(1.4s /6.2s) 
2024-01-28 22:30:07,322 [nnabla]: epoch 24 of 100 cost=1.446274  time=(1.5s /6.2s) 
2024-01-28 22:30:07,363 [nnabla]: epoch 25 of 100 cost=1.390413  time=(1.5s /6.1s) 
2024-01-28 22:30:07,404 [nnabla]: epoch 26 of 100 cost=1.326169  time=(1.6s /6.0s) 
2024-01-28 22:30:07,446 [nnabla]: epoch 27 of 100 cost=1.282495  time=(1.6s /6.0s) 
2024-01-28 22:30:07,487 [nnabla]: epoch 28 of 100 cost=1.224526  time=(1.7s /5.9s) 
2024-01-28 22:30:07,530 [nnabla]: epoch 29 of 100 cost=1.172992  time=(1.7s /5.8s) 
2024-01-28 22:30:07,620 [nnabla]: epoch 30 of 100 cost=1.126038  {train_error=1.037450, valid_error=1.046851} time=(1.7s /5.8s) 
2024-01-28 22:30:07,661 [nnabla]: epoch 31 of 100 cost=1.070661  time=(1.8s /5.9s) 
2024-01-28 22:30:07,702 [nnabla]: epoch 32 of 100 cost=1.031867  time=(1.9s /5.8s) 
2024-01-28 22:30:07,748 [nnabla]: epoch 33 of 100 cost=0.975904  time=(1.9s /5.8s) 
2024-01-28 22:30:07,797 [nnabla]: epoch 34 of 100 cost=0.947902  time=(2.0s /5.7s) 
2024-01-28 22:30:07,836 [nnabla]: epoch 35 of 100 cost=0.892570  time=(2.0s /5.7s) 
2024-01-28 22:30:07,880 [nnabla]: epoch 36 of 100 cost=0.859250  time=(2.0s /5.7s) 
2024-01-28 22:30:07,920 [nnabla]: epoch 37 of 100 cost=0.837583  time=(2.1s /5.6s) 
2024-01-28 22:30:07,960 [nnabla]: epoch 38 of 100 cost=0.797778  time=(2.1s /5.6s) 
2024-01-28 22:30:08,001 [nnabla]: epoch 39 of 100 cost=0.747252  time=(2.2s /5.5s) 
2024-01-28 22:30:08,107 [nnabla]: epoch 40 of 100 cost=0.722062  {train_error=0.653224, valid_error=0.658680} time=(2.2s /5.5s) 
2024-01-28 22:30:08,149 [nnabla]: epoch 41 of 100 cost=0.687099  time=(2.3s /5.6s) 
2024-01-28 22:30:08,190 [nnabla]: epoch 42 of 100 cost=0.664337  time=(2.4s /5.6s) 
2024-01-28 22:30:08,232 [nnabla]: epoch 43 of 100 cost=0.636591  time=(2.4s /5.6s) 
2024-01-28 22:30:08,276 [nnabla]: epoch 44 of 100 cost=0.603603  time=(2.4s /5.5s) 
2024-01-28 22:30:08,332 [nnabla]: epoch 45 of 100 cost=0.572007  time=(2.5s /5.5s) 
2024-01-28 22:30:08,375 [nnabla]: epoch 46 of 100 cost=0.564433  time=(2.5s /5.5s) 
2024-01-28 22:30:08,418 [nnabla]: epoch 47 of 100 cost=0.536679  time=(2.6s /5.5s) 
2024-01-28 22:30:08,462 [nnabla]: epoch 48 of 100 cost=0.515115  time=(2.6s /5.5s) 
2024-01-28 22:30:08,502 [nnabla]: epoch 49 of 100 cost=0.493221  time=(2.7s /5.4s) 
2024-01-28 22:30:08,610 [nnabla]: epoch 50 of 100 cost=0.468769  {train_error=0.402315, valid_error=0.411768} time=(2.7s /5.4s) 
2024-01-28 22:30:08,655 [nnabla]: epoch 51 of 100 cost=0.460314  time=(2.8s /5.5s) 
2024-01-28 22:30:08,699 [nnabla]: epoch 52 of 100 cost=0.439640  time=(2.9s /5.5s) 
2024-01-28 22:30:08,739 [nnabla]: epoch 53 of 100 cost=0.424672  time=(2.9s /5.5s) 
2024-01-28 22:30:08,780 [nnabla]: epoch 54 of 100 cost=0.404219  time=(2.9s /5.5s) 
2024-01-28 22:30:08,824 [nnabla]: epoch 55 of 100 cost=0.391241  time=(3.0s /5.4s) 
2024-01-28 22:30:08,874 [nnabla]: epoch 56 of 100 cost=0.371068  time=(3.0s /5.4s) 
2024-01-28 22:30:08,919 [nnabla]: epoch 57 of 100 cost=0.366168  time=(3.1s /5.4s) 
2024-01-28 22:30:08,963 [nnabla]: epoch 58 of 100 cost=0.354635  time=(3.1s /5.4s) 
2024-01-28 22:30:09,003 [nnabla]: epoch 59 of 100 cost=0.339002  time=(3.2s /5.4s) 
2024-01-28 22:30:09,097 [nnabla]: epoch 60 of 100 cost=0.321311  {train_error=0.244545, valid_error=0.246859} time=(3.2s /5.3s) 
2024-01-28 22:30:09,139 [nnabla]: epoch 61 of 100 cost=0.321470  time=(3.3s /5.4s) 
2024-01-28 22:30:09,181 [nnabla]: epoch 62 of 100 cost=0.310256  time=(3.3s /5.4s) 
2024-01-28 22:30:09,225 [nnabla]: epoch 63 of 100 cost=0.297488  time=(3.4s /5.4s) 
2024-01-28 22:30:09,264 [nnabla]: epoch 64 of 100 cost=0.292383  time=(3.4s /5.4s) 
2024-01-28 22:30:09,307 [nnabla]: epoch 65 of 100 cost=0.277208  time=(3.5s /5.3s) 
2024-01-28 22:30:09,347 [nnabla]: epoch 66 of 100 cost=0.277957  time=(3.5s /5.3s) 
2024-01-28 22:30:09,403 [nnabla]: epoch 67 of 100 cost=0.259638  time=(3.6s /5.3s) 
2024-01-28 22:30:09,446 [nnabla]: epoch 68 of 100 cost=0.250397  time=(3.6s /5.3s) 
2024-01-28 22:30:09,487 [nnabla]: epoch 69 of 100 cost=0.243048  time=(3.6s /5.3s) 
2024-01-28 22:30:09,582 [nnabla]: epoch 70 of 100 cost=0.244366  {train_error=0.170528, valid_error=0.175491} time=(3.7s /5.3s) 
2024-01-28 22:30:09,624 [nnabla]: epoch 71 of 100 cost=0.232752  time=(3.8s /5.3s) 
2024-01-28 22:30:09,665 [nnabla]: epoch 72 of 100 cost=0.223903  time=(3.8s /5.3s) 
2024-01-28 22:30:09,707 [nnabla]: epoch 73 of 100 cost=0.220742  time=(3.9s /5.3s) 
2024-01-28 22:30:09,750 [nnabla]: epoch 74 of 100 cost=0.207244  time=(3.9s /5.3s) 
2024-01-28 22:30:09,792 [nnabla]: epoch 75 of 100 cost=0.206698  time=(4.0s /5.3s) 
2024-01-28 22:30:09,833 [nnabla]: epoch 76 of 100 cost=0.196043  time=(4.0s /5.3s) 
2024-01-28 22:30:09,874 [nnabla]: epoch 77 of 100 cost=0.191349  time=(4.0s /5.2s) 
2024-01-28 22:30:09,928 [nnabla]: epoch 78 of 100 cost=0.191016  time=(4.1s /5.2s) 
2024-01-28 22:30:09,970 [nnabla]: epoch 79 of 100 cost=0.181742  time=(4.1s /5.2s) 
2024-01-28 22:30:10,062 [nnabla]: epoch 80 of 100 cost=0.179947  {train_error=0.124810, valid_error=0.129682} time=(4.2s /5.2s) 
2024-01-28 22:30:10,103 [nnabla]: epoch 81 of 100 cost=0.176233  time=(4.3s /5.3s) 
2024-01-28 22:30:10,145 [nnabla]: epoch 82 of 100 cost=0.172337  time=(4.3s /5.3s) 
2024-01-28 22:30:10,186 [nnabla]: epoch 83 of 100 cost=0.164892  time=(4.3s /5.2s) 
2024-01-28 22:30:10,229 [nnabla]: epoch 84 of 100 cost=0.157603  time=(4.4s /5.2s) 
2024-01-28 22:30:10,271 [nnabla]: epoch 85 of 100 cost=0.151310  time=(4.4s /5.2s) 
2024-01-28 22:30:10,313 [nnabla]: epoch 86 of 100 cost=0.151445  time=(4.5s /5.2s) 
2024-01-28 22:30:10,354 [nnabla]: epoch 87 of 100 cost=0.148157  time=(4.5s /5.2s) 
2024-01-28 22:30:10,396 [nnabla]: epoch 88 of 100 cost=0.149422  time=(4.6s /5.2s) 
2024-01-28 22:30:10,453 [nnabla]: epoch 89 of 100 cost=0.145713  time=(4.6s /5.2s) 
2024-01-28 22:30:10,545 [nnabla]: epoch 90 of 100 cost=0.141430  {train_error=0.095020, valid_error=0.099441} time=(4.7s /5.2s) 
2024-01-28 22:30:10,587 [nnabla]: epoch 91 of 100 cost=0.136921  time=(4.7s /5.2s) 
2024-01-28 22:30:10,629 [nnabla]: epoch 92 of 100 cost=0.129333  time=(4.8s /5.2s) 
2024-01-28 22:30:10,669 [nnabla]: epoch 93 of 100 cost=0.131127  time=(4.8s /5.2s) 
2024-01-28 22:30:10,711 [nnabla]: epoch 94 of 100 cost=0.120594  time=(4.9s /5.2s) 
2024-01-28 22:30:10,751 [nnabla]: epoch 95 of 100 cost=0.125758  time=(4.9s /5.2s) 
2024-01-28 22:30:10,792 [nnabla]: epoch 96 of 100 cost=0.115494  time=(5.0s /5.2s) 
2024-01-28 22:30:10,833 [nnabla]: epoch 97 of 100 cost=0.117052  time=(5.0s /5.1s) 
2024-01-28 22:30:10,876 [nnabla]: epoch 98 of 100 cost=0.113714  time=(5.0s /5.1s) 
2024-01-28 22:30:10,916 [nnabla]: epoch 99 of 100 cost=0.112624  time=(5.1s /5.1s) 
2024-01-28 22:30:11,036 [nnabla]: epoch 100 of 100 cost=0.107150  {train_error=0.070205, valid_error=0.073257} time=(5.1s /5.1s) 
2024-01-28 22:30:11,053 [nnabla]: Training Completed.
NNabla command line interface (Version:1.33.1, Build:230206070804, Callback:NNabla SSH callback module.)

2024-01-28 21:16:34,434 Training process is started.
python "C:\Users\yamas\Desktop\tools\neural_network_console\libs\Python\Lib\site-packages\nnabla\utils\cli\cli.py" train
	-c "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_211634\net.nntxt"
	-o "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_211634"
2024-01-28 21:16:34,973 [nnabla]: [CALLBACK]: Exec train on local
2024-01-28 21:16:34,980 [nnabla]: Using context "Context(backend=['cpu:float'], array_class='CpuCachedArray', device_id='')"
2024-01-28 21:16:34,980 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_test_3class_onsen.csv"
2024-01-28 21:16:35,571 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_valid_3class_onsen.csv"
2024-01-28 21:16:35,948 [nnabla]: Train with contexts ['cpu']
2024-01-28 21:16:35,968 [nnabla]: Training epoch 1 of 100 begin
2024-01-28 21:16:35,968 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 21:16:35,968 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 21:16:36,183 [nnabla]: epoch 1 of 100 cost=4.369141  {train_error=4.291318, valid_error=4.260733} time=(0.1s /10.7s) 
2024-01-28 21:16:36,279 [nnabla]: epoch 2 of 100 cost=3.927577  {train_error=3.755076, valid_error=3.716991} time=(0.3s /13.0s) 
2024-01-28 21:16:36,365 [nnabla]: epoch 3 of 100 cost=3.668553  {train_error=3.499791, valid_error=3.470607} time=(0.4s /11.8s) 
2024-01-28 21:16:36,452 [nnabla]: epoch 4 of 100 cost=3.455470  {train_error=3.350294, valid_error=3.328956} time=(0.4s /11.0s) 
2024-01-28 21:16:36,550 [nnabla]: epoch 5 of 100 cost=3.234804  {train_error=3.083579, valid_error=3.076478} time=(0.5s /10.6s) 
2024-01-28 21:16:36,593 [nnabla]: epoch 6 of 100 cost=3.035302  time=(0.6s /10.4s) 
2024-01-28 21:16:36,639 [nnabla]: epoch 7 of 100 cost=2.894674  time=(0.7s /9.6s) 
2024-01-28 21:16:36,681 [nnabla]: epoch 8 of 100 cost=2.765391  time=(0.7s /8.9s) 
2024-01-28 21:16:36,723 [nnabla]: epoch 9 of 100 cost=2.650678  time=(0.8s /8.4s) 
2024-01-28 21:16:36,820 [nnabla]: epoch 10 of 100 cost=2.558129  {train_error=2.465888, valid_error=2.474227} time=(0.8s /8.0s) 
2024-01-28 21:16:36,864 [nnabla]: epoch 11 of 100 cost=2.463689  time=(0.9s /8.1s) 
2024-01-28 21:16:36,914 [nnabla]: epoch 12 of 100 cost=2.366434  time=(0.9s /7.8s) 
2024-01-28 21:16:36,957 [nnabla]: epoch 13 of 100 cost=2.275095  time=(1.0s /7.6s) 
2024-01-28 21:16:37,000 [nnabla]: epoch 14 of 100 cost=2.195756  time=(1.0s /7.4s) 
2024-01-28 21:16:37,042 [nnabla]: epoch 15 of 100 cost=2.105998  time=(1.1s /7.2s) 
2024-01-28 21:16:37,086 [nnabla]: epoch 16 of 100 cost=2.031090  time=(1.1s /7.0s) 
2024-01-28 21:16:37,128 [nnabla]: epoch 17 of 100 cost=1.954426  time=(1.2s /6.8s) 
2024-01-28 21:16:37,171 [nnabla]: epoch 18 of 100 cost=1.880021  time=(1.2s /6.7s) 
2024-01-28 21:16:37,214 [nnabla]: epoch 19 of 100 cost=1.788580  time=(1.2s /6.6s) 
2024-01-28 21:16:37,310 [nnabla]: epoch 20 of 100 cost=1.746109  {train_error=1.642198, valid_error=1.657101} time=(1.3s /6.5s) 
2024-01-28 21:16:37,353 [nnabla]: epoch 21 of 100 cost=1.659473  time=(1.4s /6.6s) 
2024-01-28 21:16:37,396 [nnabla]: epoch 22 of 100 cost=1.599000  time=(1.4s /6.5s) 
2024-01-28 21:16:37,447 [nnabla]: epoch 23 of 100 cost=1.523605  time=(1.5s /6.4s) 
2024-01-28 21:16:37,490 [nnabla]: epoch 24 of 100 cost=1.464077  time=(1.5s /6.3s) 
2024-01-28 21:16:37,532 [nnabla]: epoch 25 of 100 cost=1.408644  time=(1.6s /6.3s) 
2024-01-28 21:16:37,575 [nnabla]: epoch 26 of 100 cost=1.344232  time=(1.6s /6.2s) 
2024-01-28 21:16:37,619 [nnabla]: epoch 27 of 100 cost=1.307964  time=(1.7s /6.1s) 
2024-01-28 21:16:37,662 [nnabla]: epoch 28 of 100 cost=1.236094  time=(1.7s /6.0s) 
2024-01-28 21:16:37,704 [nnabla]: epoch 29 of 100 cost=1.187442  time=(1.7s /6.0s) 
2024-01-28 21:16:37,798 [nnabla]: epoch 30 of 100 cost=1.141699  {train_error=1.006983, valid_error=1.015533} time=(1.8s /5.9s) 
2024-01-28 21:16:37,842 [nnabla]: epoch 31 of 100 cost=1.097752  time=(1.9s /6.0s) 
2024-01-28 21:16:37,885 [nnabla]: epoch 32 of 100 cost=1.055822  time=(1.9s /6.0s) 
2024-01-28 21:16:37,929 [nnabla]: epoch 33 of 100 cost=0.994315  time=(2.0s /5.9s) 
2024-01-28 21:16:37,980 [nnabla]: epoch 34 of 100 cost=0.957934  time=(2.0s /5.9s) 
2024-01-28 21:16:38,022 [nnabla]: epoch 35 of 100 cost=0.912202  time=(2.1s /5.9s) 
2024-01-28 21:16:38,065 [nnabla]: epoch 36 of 100 cost=0.869836  time=(2.1s /5.8s) 
2024-01-28 21:16:38,108 [nnabla]: epoch 37 of 100 cost=0.850878  time=(2.1s /5.8s) 
2024-01-28 21:16:38,150 [nnabla]: epoch 38 of 100 cost=0.817298  time=(2.2s /5.7s) 
2024-01-28 21:16:38,192 [nnabla]: epoch 39 of 100 cost=0.768679  time=(2.2s /5.7s) 
2024-01-28 21:16:38,285 [nnabla]: epoch 40 of 100 cost=0.738909  {train_error=0.619668, valid_error=0.626026} time=(2.3s /5.7s) 
2024-01-28 21:16:38,330 [nnabla]: epoch 41 of 100 cost=0.707657  time=(2.4s /5.8s) 
2024-01-28 21:16:38,373 [nnabla]: epoch 42 of 100 cost=0.686736  time=(2.4s /5.7s) 
2024-01-28 21:16:38,416 [nnabla]: epoch 43 of 100 cost=0.654959  time=(2.4s /5.7s) 
2024-01-28 21:16:38,459 [nnabla]: epoch 44 of 100 cost=0.623322  time=(2.5s /5.7s) 
2024-01-28 21:16:38,518 [nnabla]: epoch 45 of 100 cost=0.590405  time=(2.5s /5.6s) 
2024-01-28 21:16:38,562 [nnabla]: epoch 46 of 100 cost=0.585266  time=(2.6s /5.6s) 
2024-01-28 21:16:38,605 [nnabla]: epoch 47 of 100 cost=0.552890  time=(2.6s /5.6s) 
2024-01-28 21:16:38,646 [nnabla]: epoch 48 of 100 cost=0.523496  time=(2.7s /5.6s) 
2024-01-28 21:16:38,689 [nnabla]: epoch 49 of 100 cost=0.505033  time=(2.7s /5.6s) 
2024-01-28 21:16:38,782 [nnabla]: epoch 50 of 100 cost=0.488927  {train_error=0.387728, valid_error=0.397978} time=(2.8s /5.5s) 
2024-01-28 21:16:38,825 [nnabla]: epoch 51 of 100 cost=0.477358  time=(2.9s /5.6s) 
2024-01-28 21:16:38,880 [nnabla]: epoch 52 of 100 cost=0.451826  time=(2.9s /5.6s) 
2024-01-28 21:16:38,922 [nnabla]: epoch 53 of 100 cost=0.440244  time=(3.0s /5.6s) 
2024-01-28 21:16:38,964 [nnabla]: epoch 54 of 100 cost=0.419758  time=(3.0s /5.5s) 
2024-01-28 21:16:39,006 [nnabla]: epoch 55 of 100 cost=0.409012  time=(3.0s /5.5s) 
2024-01-28 21:16:39,057 [nnabla]: epoch 56 of 100 cost=0.380984  time=(3.1s /5.5s) 
2024-01-28 21:16:39,101 [nnabla]: epoch 57 of 100 cost=0.375391  time=(3.1s /5.5s) 
2024-01-28 21:16:39,144 [nnabla]: epoch 58 of 100 cost=0.354041  time=(3.2s /5.5s) 
2024-01-28 21:16:39,186 [nnabla]: epoch 59 of 100 cost=0.346857  time=(3.2s /5.5s) 
2024-01-28 21:16:39,282 [nnabla]: epoch 60 of 100 cost=0.322001  {train_error=0.245411, valid_error=0.248878} time=(3.3s /5.4s) 
2024-01-28 21:16:39,325 [nnabla]: epoch 61 of 100 cost=0.325116  time=(3.4s /5.5s) 
2024-01-28 21:16:39,369 [nnabla]: epoch 62 of 100 cost=0.320058  time=(3.4s /5.5s) 
2024-01-28 21:16:39,410 [nnabla]: epoch 63 of 100 cost=0.302921  time=(3.4s /5.5s) 
2024-01-28 21:16:39,455 [nnabla]: epoch 64 of 100 cost=0.298494  time=(3.5s /5.4s) 
2024-01-28 21:16:39,498 [nnabla]: epoch 65 of 100 cost=0.288142  time=(3.5s /5.4s) 
2024-01-28 21:16:39,541 [nnabla]: epoch 66 of 100 cost=0.284057  time=(3.6s /5.4s) 
2024-01-28 21:16:39,592 [nnabla]: epoch 67 of 100 cost=0.271246  time=(3.6s /5.4s) 
2024-01-28 21:16:39,634 [nnabla]: epoch 68 of 100 cost=0.255493  time=(3.7s /5.4s) 
2024-01-28 21:16:39,676 [nnabla]: epoch 69 of 100 cost=0.248946  time=(3.7s /5.4s) 
2024-01-28 21:16:39,776 [nnabla]: epoch 70 of 100 cost=0.248910  {train_error=0.180714, valid_error=0.186020} time=(3.8s /5.4s) 
2024-01-28 21:16:39,822 [nnabla]: epoch 71 of 100 cost=0.237112  time=(3.9s /5.4s) 
2024-01-28 21:16:39,864 [nnabla]: epoch 72 of 100 cost=0.229407  time=(3.9s /5.4s) 
2024-01-28 21:16:39,906 [nnabla]: epoch 73 of 100 cost=0.223694  time=(3.9s /5.4s) 
2024-01-28 21:16:39,949 [nnabla]: epoch 74 of 100 cost=0.214603  time=(4.0s /5.4s) 
2024-01-28 21:16:39,992 [nnabla]: epoch 75 of 100 cost=0.205465  time=(4.0s /5.4s) 
2024-01-28 21:16:40,037 [nnabla]: epoch 76 of 100 cost=0.200063  time=(4.1s /5.4s) 
2024-01-28 21:16:40,079 [nnabla]: epoch 77 of 100 cost=0.197281  time=(4.1s /5.3s) 
2024-01-28 21:16:40,129 [nnabla]: epoch 78 of 100 cost=0.195868  time=(4.2s /5.3s) 
2024-01-28 21:16:40,174 [nnabla]: epoch 79 of 100 cost=0.186103  time=(4.2s /5.3s) 
2024-01-28 21:16:40,267 [nnabla]: epoch 80 of 100 cost=0.181305  {train_error=0.124552, valid_error=0.129504} time=(4.2s /5.3s) 
2024-01-28 21:16:40,315 [nnabla]: epoch 81 of 100 cost=0.177438  time=(4.3s /5.4s) 
2024-01-28 21:16:40,365 [nnabla]: epoch 82 of 100 cost=0.175647  time=(4.4s /5.4s) 
2024-01-28 21:16:40,409 [nnabla]: epoch 83 of 100 cost=0.173534  time=(4.4s /5.3s) 
2024-01-28 21:16:40,450 [nnabla]: epoch 84 of 100 cost=0.162433  time=(4.5s /5.3s) 
2024-01-28 21:16:40,491 [nnabla]: epoch 85 of 100 cost=0.155614  time=(4.5s /5.3s) 
2024-01-28 21:16:40,535 [nnabla]: epoch 86 of 100 cost=0.158441  time=(4.6s /5.3s) 
2024-01-28 21:16:40,580 [nnabla]: epoch 87 of 100 cost=0.152497  time=(4.6s /5.3s) 
2024-01-28 21:16:40,623 [nnabla]: epoch 88 of 100 cost=0.154092  time=(4.7s /5.3s) 
2024-01-28 21:16:40,676 [nnabla]: epoch 89 of 100 cost=0.148649  time=(4.7s /5.3s) 
2024-01-28 21:16:40,769 [nnabla]: epoch 90 of 100 cost=0.146675  {train_error=0.095244, valid_error=0.099673} time=(4.8s /5.3s) 
2024-01-28 21:16:40,813 [nnabla]: epoch 91 of 100 cost=0.140368  time=(4.8s /5.3s) 
2024-01-28 21:16:40,857 [nnabla]: epoch 92 of 100 cost=0.131174  time=(4.9s /5.3s) 
2024-01-28 21:16:40,901 [nnabla]: epoch 93 of 100 cost=0.134708  time=(4.9s /5.3s) 
2024-01-28 21:16:40,943 [nnabla]: epoch 94 of 100 cost=0.127004  time=(5.0s /5.3s) 
2024-01-28 21:16:40,985 [nnabla]: epoch 95 of 100 cost=0.130857  time=(5.0s /5.3s) 
2024-01-28 21:16:41,028 [nnabla]: epoch 96 of 100 cost=0.119335  time=(5.1s /5.3s) 
2024-01-28 21:16:41,072 [nnabla]: epoch 97 of 100 cost=0.117073  time=(5.1s /5.3s) 
2024-01-28 21:16:41,115 [nnabla]: epoch 98 of 100 cost=0.115590  time=(5.1s /5.3s) 
2024-01-28 21:16:41,157 [nnabla]: epoch 99 of 100 cost=0.115700  time=(5.2s /5.2s) 
2024-01-28 21:16:41,267 [nnabla]: epoch 100 of 100 cost=0.109804  {train_error=0.072012, valid_error=0.075046} time=(5.2s /5.2s) 
2024-01-28 21:16:41,283 [nnabla]: Training Completed.
NNabla command line interface (Version:1.33.1, Build:230206070804, Callback:NNabla SSH callback module.)

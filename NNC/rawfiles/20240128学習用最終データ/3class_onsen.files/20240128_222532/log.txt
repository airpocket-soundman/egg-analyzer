2024-01-28 22:25:32,347 Training process is started.
python "C:\Users\yamas\Desktop\tools\neural_network_console\libs\Python\Lib\site-packages\nnabla\utils\cli\cli.py" train
	-c "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_222532\net.nntxt"
	-o "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_222532"
2024-01-28 22:25:32,874 [nnabla]: [CALLBACK]: Exec train on local
2024-01-28 22:25:32,881 [nnabla]: Using context "Context(backend=['cpu:float'], array_class='CpuCachedArray', device_id='')"
2024-01-28 22:25:32,881 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_test_3class_onsen.csv"
2024-01-28 22:25:33,469 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_valid_3class_onsen.csv"
2024-01-28 22:25:33,849 [nnabla]: Train with contexts ['cpu']
2024-01-28 22:25:33,870 [nnabla]: Training epoch 1 of 100 begin
2024-01-28 22:25:33,870 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 22:25:33,871 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 22:25:34,072 [nnabla]: epoch 1 of 100 cost=4.579324  {train_error=5.301450, valid_error=5.269840} time=(0.1s /8.8s) 
2024-01-28 22:25:34,151 [nnabla]: epoch 2 of 100 cost=4.525693  {train_error=4.493724, valid_error=4.495446} time=(0.2s /11.9s) 
2024-01-28 22:25:34,223 [nnabla]: epoch 3 of 100 cost=4.472149  {train_error=4.605365, valid_error=4.602303} time=(0.3s /10.6s) 
2024-01-28 22:25:34,297 [nnabla]: epoch 4 of 100 cost=4.418746  {train_error=4.588955, valid_error=4.588031} time=(0.4s /9.8s) 
2024-01-28 22:25:34,385 [nnabla]: epoch 5 of 100 cost=4.365507  {train_error=4.340765, valid_error=4.356831} time=(0.5s /9.3s) 
2024-01-28 22:25:34,440 [nnabla]: epoch 6 of 100 cost=4.312405  time=(0.6s /9.5s) 
2024-01-28 22:25:34,479 [nnabla]: epoch 7 of 100 cost=4.259474  time=(0.6s /8.7s) 
2024-01-28 22:25:34,519 [nnabla]: epoch 8 of 100 cost=4.206711  time=(0.6s /8.1s) 
2024-01-28 22:25:34,557 [nnabla]: epoch 9 of 100 cost=4.154138  time=(0.7s /7.6s) 
2024-01-28 22:25:34,643 [nnabla]: epoch 10 of 100 cost=4.101783  {train_error=4.239918, valid_error=4.245453} time=(0.7s /7.2s) 
2024-01-28 22:25:34,683 [nnabla]: epoch 11 of 100 cost=4.049627  time=(0.8s /7.4s) 
2024-01-28 22:25:34,728 [nnabla]: epoch 12 of 100 cost=3.997712  time=(0.8s /7.1s) 
2024-01-28 22:25:34,769 [nnabla]: epoch 13 of 100 cost=3.946022  time=(0.9s /6.9s) 
2024-01-28 22:25:34,808 [nnabla]: epoch 14 of 100 cost=3.894599  time=(0.9s /6.7s) 
2024-01-28 22:25:34,847 [nnabla]: epoch 15 of 100 cost=3.843432  time=(1.0s /6.5s) 
2024-01-28 22:25:34,887 [nnabla]: epoch 16 of 100 cost=3.792538  time=(1.0s /6.4s) 
2024-01-28 22:25:34,927 [nnabla]: epoch 17 of 100 cost=3.741936  time=(1.1s /6.2s) 
2024-01-28 22:25:34,965 [nnabla]: epoch 18 of 100 cost=3.691626  time=(1.1s /6.1s) 
2024-01-28 22:25:35,003 [nnabla]: epoch 19 of 100 cost=3.641646  time=(1.1s /6.0s) 
2024-01-28 22:25:35,088 [nnabla]: epoch 20 of 100 cost=3.591980  {train_error=3.306561, valid_error=3.292039} time=(1.2s /5.9s) 
2024-01-28 22:25:35,127 [nnabla]: epoch 21 of 100 cost=3.542654  time=(1.3s /6.0s) 
2024-01-28 22:25:35,167 [nnabla]: epoch 22 of 100 cost=3.493693  time=(1.3s /5.9s) 
2024-01-28 22:25:35,212 [nnabla]: epoch 23 of 100 cost=3.445103  time=(1.3s /5.8s) 
2024-01-28 22:25:35,254 [nnabla]: epoch 24 of 100 cost=3.396894  time=(1.4s /5.8s) 
2024-01-28 22:25:35,292 [nnabla]: epoch 25 of 100 cost=3.349079  time=(1.4s /5.7s) 
2024-01-28 22:25:35,331 [nnabla]: epoch 26 of 100 cost=3.301684  time=(1.5s /5.6s) 
2024-01-28 22:25:35,370 [nnabla]: epoch 27 of 100 cost=3.254726  time=(1.5s /5.6s) 
2024-01-28 22:25:35,408 [nnabla]: epoch 28 of 100 cost=3.208213  time=(1.5s /5.5s) 
2024-01-28 22:25:35,448 [nnabla]: epoch 29 of 100 cost=3.162182  time=(1.6s /5.4s) 
2024-01-28 22:25:35,520 [nnabla]: epoch 30 of 100 cost=3.116589  {train_error=3.333617, valid_error=3.323557} time=(1.6s /5.4s) 
2024-01-28 22:25:35,558 [nnabla]: epoch 31 of 100 cost=3.071541  time=(1.7s /5.4s) 
2024-01-28 22:25:35,596 [nnabla]: epoch 32 of 100 cost=3.026962  time=(1.7s /5.4s) 
2024-01-28 22:25:35,634 [nnabla]: epoch 33 of 100 cost=2.982944  time=(1.8s /5.3s) 
2024-01-28 22:25:35,682 [nnabla]: epoch 34 of 100 cost=2.939437  time=(1.8s /5.3s) 
2024-01-28 22:25:35,723 [nnabla]: epoch 35 of 100 cost=2.896492  time=(1.9s /5.3s) 
2024-01-28 22:25:35,761 [nnabla]: epoch 36 of 100 cost=2.854113  time=(1.9s /5.3s) 
2024-01-28 22:25:35,801 [nnabla]: epoch 37 of 100 cost=2.812333  time=(1.9s /5.2s) 
2024-01-28 22:25:35,840 [nnabla]: epoch 38 of 100 cost=2.771152  time=(2.0s /5.2s) 
2024-01-28 22:25:35,877 [nnabla]: epoch 39 of 100 cost=2.730540  time=(2.0s /5.1s) 
2024-01-28 22:25:35,965 [nnabla]: epoch 40 of 100 cost=2.690607  {train_error=2.742494, valid_error=2.731206} time=(2.0s /5.1s) 
2024-01-28 22:25:36,004 [nnabla]: epoch 41 of 100 cost=2.651260  time=(2.1s /5.2s) 
2024-01-28 22:25:36,044 [nnabla]: epoch 42 of 100 cost=2.612609  time=(2.2s /5.2s) 
2024-01-28 22:25:36,084 [nnabla]: epoch 43 of 100 cost=2.574583  time=(2.2s /5.1s) 
2024-01-28 22:25:36,122 [nnabla]: epoch 44 of 100 cost=2.537224  time=(2.3s /5.1s) 
2024-01-28 22:25:36,177 [nnabla]: epoch 45 of 100 cost=2.500528  time=(2.3s /5.1s) 
2024-01-28 22:25:36,217 [nnabla]: epoch 46 of 100 cost=2.464555  time=(2.3s /5.1s) 
2024-01-28 22:25:36,257 [nnabla]: epoch 47 of 100 cost=2.429226  time=(2.4s /5.1s) 
2024-01-28 22:25:36,295 [nnabla]: epoch 48 of 100 cost=2.394608  time=(2.4s /5.1s) 
2024-01-28 22:25:36,336 [nnabla]: epoch 49 of 100 cost=2.360696  time=(2.5s /5.0s) 
2024-01-28 22:25:36,424 [nnabla]: epoch 50 of 100 cost=2.327475  {train_error=2.318117, valid_error=2.306264} time=(2.5s /5.0s) 
2024-01-28 22:25:36,466 [nnabla]: epoch 51 of 100 cost=2.294952  time=(2.6s /5.1s) 
2024-01-28 22:25:36,506 [nnabla]: epoch 52 of 100 cost=2.263167  time=(2.6s /5.1s) 
2024-01-28 22:25:36,544 [nnabla]: epoch 53 of 100 cost=2.232076  time=(2.7s /5.0s) 
2024-01-28 22:25:36,584 [nnabla]: epoch 54 of 100 cost=2.201696  time=(2.7s /5.0s) 
2024-01-28 22:25:36,623 [nnabla]: epoch 55 of 100 cost=2.172019  time=(2.8s /5.0s) 
2024-01-28 22:25:36,669 [nnabla]: epoch 56 of 100 cost=2.143050  time=(2.8s /5.0s) 
2024-01-28 22:25:36,711 [nnabla]: epoch 57 of 100 cost=2.114773  time=(2.8s /5.0s) 
2024-01-28 22:25:36,751 [nnabla]: epoch 58 of 100 cost=2.087213  time=(2.9s /5.0s) 
2024-01-28 22:25:36,791 [nnabla]: epoch 59 of 100 cost=2.060319  time=(2.9s /4.9s) 
2024-01-28 22:25:36,875 [nnabla]: epoch 60 of 100 cost=2.034125  {train_error=1.913067, valid_error=1.903997} time=(3.0s /4.9s) 
2024-01-28 22:25:36,916 [nnabla]: epoch 61 of 100 cost=2.008617  time=(3.0s /5.0s) 
2024-01-28 22:25:36,956 [nnabla]: epoch 62 of 100 cost=1.983771  time=(3.1s /5.0s) 
2024-01-28 22:25:36,997 [nnabla]: epoch 63 of 100 cost=1.959578  time=(3.1s /5.0s) 
2024-01-28 22:25:37,036 [nnabla]: epoch 64 of 100 cost=1.936043  time=(3.2s /4.9s) 
2024-01-28 22:25:37,076 [nnabla]: epoch 65 of 100 cost=1.913149  time=(3.2s /4.9s) 
2024-01-28 22:25:37,115 [nnabla]: epoch 66 of 100 cost=1.890932  time=(3.2s /4.9s) 
2024-01-28 22:25:37,161 [nnabla]: epoch 67 of 100 cost=1.869282  time=(3.3s /4.9s) 
2024-01-28 22:25:37,201 [nnabla]: epoch 68 of 100 cost=1.848282  time=(3.3s /4.9s) 
2024-01-28 22:25:37,245 [nnabla]: epoch 69 of 100 cost=1.827855  time=(3.4s /4.9s) 
2024-01-28 22:25:37,329 [nnabla]: epoch 70 of 100 cost=1.808044  {train_error=1.856524, valid_error=1.849699} time=(3.4s /4.9s) 
2024-01-28 22:25:37,369 [nnabla]: epoch 71 of 100 cost=1.788779  time=(3.5s /4.9s) 
2024-01-28 22:25:37,409 [nnabla]: epoch 72 of 100 cost=1.770091  time=(3.5s /4.9s) 
2024-01-28 22:25:37,448 [nnabla]: epoch 73 of 100 cost=1.751967  time=(3.6s /4.9s) 
2024-01-28 22:25:37,488 [nnabla]: epoch 74 of 100 cost=1.734353  time=(3.6s /4.9s) 
2024-01-28 22:25:37,527 [nnabla]: epoch 75 of 100 cost=1.717274  time=(3.7s /4.9s) 
2024-01-28 22:25:37,567 [nnabla]: epoch 76 of 100 cost=1.700741  time=(3.7s /4.9s) 
2024-01-28 22:25:37,605 [nnabla]: epoch 77 of 100 cost=1.684648  time=(3.7s /4.9s) 
2024-01-28 22:25:37,652 [nnabla]: epoch 78 of 100 cost=1.669075  time=(3.8s /4.8s) 
2024-01-28 22:25:37,690 [nnabla]: epoch 79 of 100 cost=1.653948  time=(3.8s /4.8s) 
2024-01-28 22:25:37,776 [nnabla]: epoch 80 of 100 cost=1.639299  {train_error=1.592702, valid_error=1.587577} time=(3.9s /4.8s) 
2024-01-28 22:25:37,816 [nnabla]: epoch 81 of 100 cost=1.625085  time=(3.9s /4.9s) 
2024-01-28 22:25:37,854 [nnabla]: epoch 82 of 100 cost=1.611320  time=(4.0s /4.9s) 
2024-01-28 22:25:37,892 [nnabla]: epoch 83 of 100 cost=1.597953  time=(4.0s /4.8s) 
2024-01-28 22:25:37,933 [nnabla]: epoch 84 of 100 cost=1.585018  time=(4.1s /4.8s) 
2024-01-28 22:25:37,971 [nnabla]: epoch 85 of 100 cost=1.572457  time=(4.1s /4.8s) 
2024-01-28 22:25:38,010 [nnabla]: epoch 86 of 100 cost=1.560304  time=(4.1s /4.8s) 
2024-01-28 22:25:38,049 [nnabla]: epoch 87 of 100 cost=1.548497  time=(4.2s /4.8s) 
2024-01-28 22:25:38,088 [nnabla]: epoch 88 of 100 cost=1.537058  time=(4.2s /4.8s) 
2024-01-28 22:25:38,138 [nnabla]: epoch 89 of 100 cost=1.526000  time=(4.3s /4.8s) 
2024-01-28 22:25:38,225 [nnabla]: epoch 90 of 100 cost=1.515230  {train_error=1.513297, valid_error=1.510297} time=(4.3s /4.8s) 
2024-01-28 22:25:38,265 [nnabla]: epoch 91 of 100 cost=1.504824  time=(4.4s /4.8s) 
2024-01-28 22:25:38,305 [nnabla]: epoch 92 of 100 cost=1.494720  time=(4.4s /4.8s) 
2024-01-28 22:25:38,343 [nnabla]: epoch 93 of 100 cost=1.484922  time=(4.5s /4.8s) 
2024-01-28 22:25:38,382 [nnabla]: epoch 94 of 100 cost=1.475416  time=(4.5s /4.8s) 
2024-01-28 22:25:38,421 [nnabla]: epoch 95 of 100 cost=1.466209  time=(4.6s /4.8s) 
2024-01-28 22:25:38,460 [nnabla]: epoch 96 of 100 cost=1.457272  time=(4.6s /4.8s) 
2024-01-28 22:25:38,500 [nnabla]: epoch 97 of 100 cost=1.448601  time=(4.6s /4.8s) 
2024-01-28 22:25:38,539 [nnabla]: epoch 98 of 100 cost=1.440199  time=(4.7s /4.8s) 
2024-01-28 22:25:38,579 [nnabla]: epoch 99 of 100 cost=1.432028  time=(4.7s /4.8s) 
2024-01-28 22:25:38,681 [nnabla]: epoch 100 of 100 cost=1.424106  {train_error=1.476801, valid_error=1.458656} time=(4.7s /4.7s) 
2024-01-28 22:25:38,697 [nnabla]: Training Completed.
NNabla command line interface (Version:1.33.1, Build:230206070804, Callback:NNabla SSH callback module.)

2024-01-28 22:21:58,281 Training process is started.
python "C:\Users\yamas\Desktop\tools\neural_network_console\libs\Python\Lib\site-packages\nnabla\utils\cli\cli.py" train
	-c "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_222158\net.nntxt"
	-o "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_222158"
2024-01-28 22:21:58,818 [nnabla]: [CALLBACK]: Exec train on local
2024-01-28 22:21:58,823 [nnabla]: Using context "Context(backend=['cpu:float'], array_class='CpuCachedArray', device_id='')"
2024-01-28 22:21:58,823 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_test_3class_onsen.csv"
2024-01-28 22:21:59,668 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_valid_3class_onsen.csv"
2024-01-28 22:22:00,050 [nnabla]: Train with contexts ['cpu']
2024-01-28 22:22:00,078 [nnabla]: Training epoch 1 of 100 begin
2024-01-28 22:22:00,078 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 22:22:00,079 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 22:22:00,285 [nnabla]: epoch 1 of 100 cost=4.690133  {train_error=3.921281, valid_error=3.916678} time=(0.1s /9.5s) 
2024-01-28 22:22:00,381 [nnabla]: epoch 2 of 100 cost=3.886476  {train_error=3.338983, valid_error=3.328730} time=(0.3s /12.7s) 
2024-01-28 22:22:00,477 [nnabla]: epoch 3 of 100 cost=3.450404  {train_error=3.187639, valid_error=3.175507} time=(0.4s /11.7s) 
2024-01-28 22:22:00,572 [nnabla]: epoch 4 of 100 cost=3.248672  {train_error=3.039201, valid_error=3.044065} time=(0.4s /11.1s) 
2024-01-28 22:22:00,678 [nnabla]: epoch 5 of 100 cost=3.092333  {train_error=2.945777, valid_error=2.944872} time=(0.5s /10.8s) 
2024-01-28 22:22:00,726 [nnabla]: epoch 6 of 100 cost=2.980413  time=(0.6s /10.8s) 
2024-01-28 22:22:00,776 [nnabla]: epoch 7 of 100 cost=2.868827  time=(0.7s /9.9s) 
2024-01-28 22:22:00,824 [nnabla]: epoch 8 of 100 cost=2.776526  time=(0.7s /9.3s) 
2024-01-28 22:22:00,871 [nnabla]: epoch 9 of 100 cost=2.676222  time=(0.8s /8.8s) 
2024-01-28 22:22:00,974 [nnabla]: epoch 10 of 100 cost=2.578896  {train_error=2.509413, valid_error=2.524622} time=(0.8s /8.4s) 
2024-01-28 22:22:01,022 [nnabla]: epoch 11 of 100 cost=2.495529  time=(0.9s /8.6s) 
2024-01-28 22:22:01,077 [nnabla]: epoch 12 of 100 cost=2.400511  time=(1.0s /8.2s) 
2024-01-28 22:22:01,127 [nnabla]: epoch 13 of 100 cost=2.320753  time=(1.0s /8.1s) 
2024-01-28 22:22:01,175 [nnabla]: epoch 14 of 100 cost=2.235498  time=(1.1s /7.8s) 
2024-01-28 22:22:01,222 [nnabla]: epoch 15 of 100 cost=2.158588  time=(1.1s /7.6s) 
2024-01-28 22:22:01,269 [nnabla]: epoch 16 of 100 cost=2.087934  time=(1.2s /7.4s) 
2024-01-28 22:22:01,317 [nnabla]: epoch 17 of 100 cost=1.994111  time=(1.2s /7.3s) 
2024-01-28 22:22:01,367 [nnabla]: epoch 18 of 100 cost=1.932210  time=(1.3s /7.1s) 
2024-01-28 22:22:01,415 [nnabla]: epoch 19 of 100 cost=1.844699  time=(1.3s /7.0s) 
2024-01-28 22:22:01,516 [nnabla]: epoch 20 of 100 cost=1.792916  {train_error=1.717508, valid_error=1.751498} time=(1.4s /6.9s) 
2024-01-28 22:22:01,564 [nnabla]: epoch 21 of 100 cost=1.709111  time=(1.5s /7.1s) 
2024-01-28 22:22:01,612 [nnabla]: epoch 22 of 100 cost=1.645211  time=(1.5s /7.0s) 
2024-01-28 22:22:01,669 [nnabla]: epoch 23 of 100 cost=1.577386  time=(1.6s /6.9s) 
2024-01-28 22:22:01,719 [nnabla]: epoch 24 of 100 cost=1.511292  time=(1.6s /6.8s) 
2024-01-28 22:22:01,768 [nnabla]: epoch 25 of 100 cost=1.457022  time=(1.7s /6.7s) 
2024-01-28 22:22:01,816 [nnabla]: epoch 26 of 100 cost=1.385274  time=(1.7s /6.7s) 
2024-01-28 22:22:01,865 [nnabla]: epoch 27 of 100 cost=1.338541  time=(1.8s /6.6s) 
2024-01-28 22:22:01,912 [nnabla]: epoch 28 of 100 cost=1.285713  time=(1.8s /6.5s) 
2024-01-28 22:22:01,960 [nnabla]: epoch 29 of 100 cost=1.230302  time=(1.9s /6.5s) 
2024-01-28 22:22:02,065 [nnabla]: epoch 30 of 100 cost=1.170318  {train_error=1.112170, valid_error=1.138722} time=(1.9s /6.4s) 
2024-01-28 22:22:02,113 [nnabla]: epoch 31 of 100 cost=1.127367  time=(2.0s /6.6s) 
2024-01-28 22:22:02,162 [nnabla]: epoch 32 of 100 cost=1.074395  time=(2.1s /6.5s) 
2024-01-28 22:22:02,210 [nnabla]: epoch 33 of 100 cost=1.032649  time=(2.1s /6.5s) 
2024-01-28 22:22:02,265 [nnabla]: epoch 34 of 100 cost=0.993372  time=(2.2s /6.4s) 
2024-01-28 22:22:02,315 [nnabla]: epoch 35 of 100 cost=0.953077  time=(2.2s /6.4s) 
2024-01-28 22:22:02,364 [nnabla]: epoch 36 of 100 cost=0.906018  time=(2.3s /6.3s) 
2024-01-28 22:22:02,412 [nnabla]: epoch 37 of 100 cost=0.882490  time=(2.3s /6.3s) 
2024-01-28 22:22:02,460 [nnabla]: epoch 38 of 100 cost=0.851517  time=(2.4s /6.3s) 
2024-01-28 22:22:02,506 [nnabla]: epoch 39 of 100 cost=0.809360  time=(2.4s /6.2s) 
2024-01-28 22:22:02,613 [nnabla]: epoch 40 of 100 cost=0.784130  {train_error=0.725324, valid_error=0.740779} time=(2.5s /6.2s) 
2024-01-28 22:22:02,662 [nnabla]: epoch 41 of 100 cost=0.740196  time=(2.6s /6.3s) 
2024-01-28 22:22:02,710 [nnabla]: epoch 42 of 100 cost=0.716479  time=(2.6s /6.3s) 
2024-01-28 22:22:02,765 [nnabla]: epoch 43 of 100 cost=0.692960  time=(2.7s /6.2s) 
2024-01-28 22:22:02,815 [nnabla]: epoch 44 of 100 cost=0.660708  time=(2.7s /6.2s) 
2024-01-28 22:22:02,876 [nnabla]: epoch 45 of 100 cost=0.632956  time=(2.8s /6.2s) 
2024-01-28 22:22:02,925 [nnabla]: epoch 46 of 100 cost=0.620671  time=(2.8s /6.2s) 
2024-01-28 22:22:02,973 [nnabla]: epoch 47 of 100 cost=0.593946  time=(2.9s /6.2s) 
2024-01-28 22:22:03,021 [nnabla]: epoch 48 of 100 cost=0.568836  time=(2.9s /6.1s) 
2024-01-28 22:22:03,068 [nnabla]: epoch 49 of 100 cost=0.550226  time=(3.0s /6.1s) 
2024-01-28 22:22:03,172 [nnabla]: epoch 50 of 100 cost=0.522503  {train_error=0.466365, valid_error=0.479319} time=(3.0s /6.1s) 
2024-01-28 22:22:03,220 [nnabla]: epoch 51 of 100 cost=0.520066  time=(3.1s /6.2s) 
2024-01-28 22:22:03,268 [nnabla]: epoch 52 of 100 cost=0.499119  time=(3.2s /6.1s) 
2024-01-28 22:22:03,316 [nnabla]: epoch 53 of 100 cost=0.479771  time=(3.2s /6.1s) 
2024-01-28 22:22:03,363 [nnabla]: epoch 54 of 100 cost=0.462447  time=(3.3s /6.1s) 
2024-01-28 22:22:03,412 [nnabla]: epoch 55 of 100 cost=0.442496  time=(3.3s /6.1s) 
2024-01-28 22:22:03,468 [nnabla]: epoch 56 of 100 cost=0.430849  time=(3.4s /6.0s) 
2024-01-28 22:22:03,516 [nnabla]: epoch 57 of 100 cost=0.419289  time=(3.4s /6.0s) 
2024-01-28 22:22:03,563 [nnabla]: epoch 58 of 100 cost=0.400135  time=(3.5s /6.0s) 
2024-01-28 22:22:03,611 [nnabla]: epoch 59 of 100 cost=0.389134  time=(3.5s /6.0s) 
2024-01-28 22:22:03,716 [nnabla]: epoch 60 of 100 cost=0.371159  {train_error=0.313015, valid_error=0.317038} time=(3.6s /6.0s) 
2024-01-28 22:22:03,764 [nnabla]: epoch 61 of 100 cost=0.363784  time=(3.7s /6.0s) 
2024-01-28 22:22:03,811 [nnabla]: epoch 62 of 100 cost=0.360550  time=(3.7s /6.0s) 
2024-01-28 22:22:03,861 [nnabla]: epoch 63 of 100 cost=0.349101  time=(3.8s /6.0s) 
2024-01-28 22:22:03,907 [nnabla]: epoch 64 of 100 cost=0.338026  time=(3.8s /6.0s) 
2024-01-28 22:22:03,955 [nnabla]: epoch 65 of 100 cost=0.322990  time=(3.9s /6.0s) 
2024-01-28 22:22:04,003 [nnabla]: epoch 66 of 100 cost=0.326058  time=(3.9s /5.9s) 
2024-01-28 22:22:04,058 [nnabla]: epoch 67 of 100 cost=0.307004  time=(4.0s /5.9s) 
2024-01-28 22:22:04,106 [nnabla]: epoch 68 of 100 cost=0.295627  time=(4.0s /5.9s) 
2024-01-28 22:22:04,153 [nnabla]: epoch 69 of 100 cost=0.294153  time=(4.1s /5.9s) 
2024-01-28 22:22:04,254 [nnabla]: epoch 70 of 100 cost=0.295742  {train_error=0.220651, valid_error=0.231986} time=(4.1s /5.9s) 
2024-01-28 22:22:04,302 [nnabla]: epoch 71 of 100 cost=0.274723  time=(4.2s /5.9s) 
2024-01-28 22:22:04,351 [nnabla]: epoch 72 of 100 cost=0.270604  time=(4.3s /5.9s) 
2024-01-28 22:22:04,399 [nnabla]: epoch 73 of 100 cost=0.257404  time=(4.3s /5.9s) 
2024-01-28 22:22:04,446 [nnabla]: epoch 74 of 100 cost=0.255983  time=(4.4s /5.9s) 
2024-01-28 22:22:04,494 [nnabla]: epoch 75 of 100 cost=0.249244  time=(4.4s /5.9s) 
2024-01-28 22:22:04,542 [nnabla]: epoch 76 of 100 cost=0.236141  time=(4.5s /5.9s) 
2024-01-28 22:22:04,590 [nnabla]: epoch 77 of 100 cost=0.224235  time=(4.5s /5.9s) 
2024-01-28 22:22:04,644 [nnabla]: epoch 78 of 100 cost=0.229789  time=(4.6s /5.8s) 
2024-01-28 22:22:04,694 [nnabla]: epoch 79 of 100 cost=0.221916  time=(4.6s /5.8s) 
2024-01-28 22:22:04,794 [nnabla]: epoch 80 of 100 cost=0.213616  {train_error=0.161785, valid_error=0.172934} time=(4.7s /5.8s) 
2024-01-28 22:22:04,844 [nnabla]: epoch 81 of 100 cost=0.217585  time=(4.8s /5.9s) 
2024-01-28 22:22:04,893 [nnabla]: epoch 82 of 100 cost=0.211946  time=(4.8s /5.9s) 
2024-01-28 22:22:04,941 [nnabla]: epoch 83 of 100 cost=0.211095  time=(4.9s /5.9s) 
2024-01-28 22:22:04,988 [nnabla]: epoch 84 of 100 cost=0.198647  time=(4.9s /5.8s) 
2024-01-28 22:22:05,036 [nnabla]: epoch 85 of 100 cost=0.186590  time=(5.0s /5.8s) 
2024-01-28 22:22:05,084 [nnabla]: epoch 86 of 100 cost=0.192383  time=(5.0s /5.8s) 
2024-01-28 22:22:05,131 [nnabla]: epoch 87 of 100 cost=0.184395  time=(5.1s /5.8s) 
2024-01-28 22:22:05,178 [nnabla]: epoch 88 of 100 cost=0.188206  time=(5.1s /5.8s) 
2024-01-28 22:22:05,235 [nnabla]: epoch 89 of 100 cost=0.182370  time=(5.1s /5.8s) 
2024-01-28 22:22:05,337 [nnabla]: epoch 90 of 100 cost=0.174157  {train_error=0.119911, valid_error=0.129006} time=(5.2s /5.8s) 
2024-01-28 22:22:05,386 [nnabla]: epoch 91 of 100 cost=0.173832  time=(5.3s /5.8s) 
2024-01-28 22:22:05,434 [nnabla]: epoch 92 of 100 cost=0.162802  time=(5.4s /5.8s) 
2024-01-28 22:22:05,481 [nnabla]: epoch 93 of 100 cost=0.166596  time=(5.4s /5.8s) 
2024-01-28 22:22:05,531 [nnabla]: epoch 94 of 100 cost=0.156482  time=(5.5s /5.8s) 
2024-01-28 22:22:05,578 [nnabla]: epoch 95 of 100 cost=0.162107  time=(5.5s /5.8s) 
2024-01-28 22:22:05,626 [nnabla]: epoch 96 of 100 cost=0.148284  time=(5.5s /5.8s) 
2024-01-28 22:22:05,675 [nnabla]: epoch 97 of 100 cost=0.151380  time=(5.6s /5.8s) 
2024-01-28 22:22:05,723 [nnabla]: epoch 98 of 100 cost=0.142629  time=(5.6s /5.8s) 
2024-01-28 22:22:05,771 [nnabla]: epoch 99 of 100 cost=0.148111  time=(5.7s /5.7s) 
2024-01-28 22:22:05,894 [nnabla]: epoch 100 of 100 cost=0.142003  {train_error=0.100313, valid_error=0.109134} time=(5.7s /5.7s) 
2024-01-28 22:22:05,908 [nnabla]: Training Completed.
NNabla command line interface (Version:1.33.1, Build:230206070804, Callback:NNabla SSH callback module.)

2024-01-28 22:35:22,239 Training process is started.
python "C:\Users\yamas\Desktop\tools\neural_network_console\libs\Python\Lib\site-packages\nnabla\utils\cli\cli.py" train
	-c "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_223522\net.nntxt"
	-o "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_223522"
2024-01-28 22:35:22,785 [nnabla]: [CALLBACK]: Exec train on local
2024-01-28 22:35:22,791 [nnabla]: Using context "Context(backend=['cpu:float'], array_class='CpuCachedArray', device_id='')"
2024-01-28 22:35:22,791 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_test_3class_onsen.csv"
2024-01-28 22:35:23,374 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_valid_3class_onsen.csv"
2024-01-28 22:35:23,752 [nnabla]: Train with contexts ['cpu']
2024-01-28 22:35:23,770 [nnabla]: Training epoch 1 of 100 begin
2024-01-28 22:35:23,770 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 22:35:23,770 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 22:35:23,971 [nnabla]: epoch 1 of 100 cost=4.441790  {train_error=4.386507, valid_error=4.384255} time=(0.1s /9.0s) 
2024-01-28 22:35:24,062 [nnabla]: epoch 2 of 100 cost=4.335125  {train_error=4.280133, valid_error=4.277944} time=(0.2s /12.4s) 
2024-01-28 22:35:24,146 [nnabla]: epoch 3 of 100 cost=4.229488  {train_error=4.174615, valid_error=4.172310} time=(0.3s /11.1s) 
2024-01-28 22:35:24,232 [nnabla]: epoch 4 of 100 cost=4.123716  {train_error=4.069787, valid_error=4.067519} time=(0.4s /10.5s) 
2024-01-28 22:35:24,325 [nnabla]: epoch 5 of 100 cost=4.019478  {train_error=3.965719, valid_error=3.963571} time=(0.5s /10.1s) 
2024-01-28 22:35:24,368 [nnabla]: epoch 6 of 100 cost=3.916484  time=(0.6s /10.0s) 
2024-01-28 22:35:24,413 [nnabla]: epoch 7 of 100 cost=3.813382  time=(0.6s /9.2s) 
2024-01-28 22:35:24,457 [nnabla]: epoch 8 of 100 cost=3.712125  time=(0.7s /8.6s) 
2024-01-28 22:35:24,498 [nnabla]: epoch 9 of 100 cost=3.611984  time=(0.7s /8.1s) 
2024-01-28 22:35:24,587 [nnabla]: epoch 10 of 100 cost=3.513204  {train_error=3.462676, valid_error=3.460356} time=(0.8s /7.7s) 
2024-01-28 22:35:24,630 [nnabla]: epoch 11 of 100 cost=3.416052  time=(0.9s /7.8s) 
2024-01-28 22:35:24,683 [nnabla]: epoch 12 of 100 cost=3.319851  time=(0.9s /7.5s) 
2024-01-28 22:35:24,724 [nnabla]: epoch 13 of 100 cost=3.226664  time=(1.0s /7.3s) 
2024-01-28 22:35:24,767 [nnabla]: epoch 14 of 100 cost=3.134252  time=(1.0s /7.1s) 
2024-01-28 22:35:24,809 [nnabla]: epoch 15 of 100 cost=3.043937  time=(1.0s /6.9s) 
2024-01-28 22:35:24,851 [nnabla]: epoch 16 of 100 cost=2.956386  time=(1.1s /6.8s) 
2024-01-28 22:35:24,893 [nnabla]: epoch 17 of 100 cost=2.870399  time=(1.1s /6.6s) 
2024-01-28 22:35:24,937 [nnabla]: epoch 18 of 100 cost=2.787175  time=(1.2s /6.5s) 
2024-01-28 22:35:24,979 [nnabla]: epoch 19 of 100 cost=2.706248  time=(1.2s /6.4s) 
2024-01-28 22:35:25,070 [nnabla]: epoch 20 of 100 cost=2.628174  {train_error=2.588518, valid_error=2.586277} time=(1.3s /6.3s) 
2024-01-28 22:35:25,113 [nnabla]: epoch 21 of 100 cost=2.552395  time=(1.3s /6.4s) 
2024-01-28 22:35:25,156 [nnabla]: epoch 22 of 100 cost=2.479156  time=(1.4s /6.3s) 
2024-01-28 22:35:25,207 [nnabla]: epoch 23 of 100 cost=2.409788  time=(1.4s /6.2s) 
2024-01-28 22:35:25,250 [nnabla]: epoch 24 of 100 cost=2.342020  time=(1.5s /6.2s) 
2024-01-28 22:35:25,291 [nnabla]: epoch 25 of 100 cost=2.278224  time=(1.5s /6.1s) 
2024-01-28 22:35:25,333 [nnabla]: epoch 26 of 100 cost=2.216640  time=(1.6s /6.0s) 
2024-01-28 22:35:25,374 [nnabla]: epoch 27 of 100 cost=2.157770  time=(1.6s /5.9s) 
2024-01-28 22:35:25,416 [nnabla]: epoch 28 of 100 cost=2.101973  time=(1.6s /5.9s) 
2024-01-28 22:35:25,462 [nnabla]: epoch 29 of 100 cost=2.049348  time=(1.7s /5.8s) 
2024-01-28 22:35:25,551 [nnabla]: epoch 30 of 100 cost=1.999402  {train_error=1.974006, valid_error=1.972393} time=(1.7s /5.8s) 
2024-01-28 22:35:25,595 [nnabla]: epoch 31 of 100 cost=1.951245  time=(1.8s /5.9s) 
2024-01-28 22:35:25,644 [nnabla]: epoch 32 of 100 cost=1.907821  time=(1.9s /5.9s) 
2024-01-28 22:35:25,689 [nnabla]: epoch 33 of 100 cost=1.864290  time=(1.9s /5.8s) 
2024-01-28 22:35:25,738 [nnabla]: epoch 34 of 100 cost=1.824625  time=(2.0s /5.8s) 
2024-01-28 22:35:25,781 [nnabla]: epoch 35 of 100 cost=1.787307  time=(2.0s /5.7s) 
2024-01-28 22:35:25,823 [nnabla]: epoch 36 of 100 cost=1.752159  time=(2.1s /5.7s) 
2024-01-28 22:35:25,864 [nnabla]: epoch 37 of 100 cost=1.718030  time=(2.1s /5.7s) 
2024-01-28 22:35:25,906 [nnabla]: epoch 38 of 100 cost=1.687964  time=(2.1s /5.6s) 
2024-01-28 22:35:25,948 [nnabla]: epoch 39 of 100 cost=1.658164  time=(2.2s /5.6s) 
2024-01-28 22:35:26,039 [nnabla]: epoch 40 of 100 cost=1.630479  {train_error=1.616979, valid_error=1.616658} time=(2.2s /5.5s) 
2024-01-28 22:35:26,083 [nnabla]: epoch 41 of 100 cost=1.604537  time=(2.3s /5.6s) 
2024-01-28 22:35:26,126 [nnabla]: epoch 42 of 100 cost=1.580266  time=(2.4s /5.6s) 
2024-01-28 22:35:26,169 [nnabla]: epoch 43 of 100 cost=1.557266  time=(2.4s /5.6s) 
2024-01-28 22:35:26,213 [nnabla]: epoch 44 of 100 cost=1.535762  time=(2.4s /5.6s) 
2024-01-28 22:35:26,270 [nnabla]: epoch 45 of 100 cost=1.515111  time=(2.5s /5.5s) 
2024-01-28 22:35:26,313 [nnabla]: epoch 46 of 100 cost=1.497008  time=(2.5s /5.5s) 
2024-01-28 22:35:26,354 [nnabla]: epoch 47 of 100 cost=1.478949  time=(2.6s /5.5s) 
2024-01-28 22:35:26,398 [nnabla]: epoch 48 of 100 cost=1.462030  time=(2.6s /5.5s) 
2024-01-28 22:35:26,440 [nnabla]: epoch 49 of 100 cost=1.446150  time=(2.7s /5.4s) 
2024-01-28 22:35:26,534 [nnabla]: epoch 50 of 100 cost=1.431509  {train_error=1.423714, valid_error=1.424274} time=(2.7s /5.4s) 
2024-01-28 22:35:26,577 [nnabla]: epoch 51 of 100 cost=1.416878  time=(2.8s /5.5s) 
2024-01-28 22:35:26,620 [nnabla]: epoch 52 of 100 cost=1.404206  time=(2.8s /5.5s) 
2024-01-28 22:35:26,662 [nnabla]: epoch 53 of 100 cost=1.391487  time=(2.9s /5.5s) 
2024-01-28 22:35:26,705 [nnabla]: epoch 54 of 100 cost=1.379329  time=(2.9s /5.4s) 
2024-01-28 22:35:26,748 [nnabla]: epoch 55 of 100 cost=1.368624  time=(3.0s /5.4s) 
2024-01-28 22:35:26,799 [nnabla]: epoch 56 of 100 cost=1.358052  time=(3.0s /5.4s) 
2024-01-28 22:35:26,842 [nnabla]: epoch 57 of 100 cost=1.347960  time=(3.1s /5.4s) 
2024-01-28 22:35:26,886 [nnabla]: epoch 58 of 100 cost=1.338334  time=(3.1s /5.4s) 
2024-01-28 22:35:26,930 [nnabla]: epoch 59 of 100 cost=1.329639  time=(3.2s /5.4s) 
2024-01-28 22:35:27,020 [nnabla]: epoch 60 of 100 cost=1.320978  {train_error=1.316865, valid_error=1.317039} time=(3.2s /5.3s) 
2024-01-28 22:35:27,063 [nnabla]: epoch 61 of 100 cost=1.313266  time=(3.3s /5.4s) 
2024-01-28 22:35:27,104 [nnabla]: epoch 62 of 100 cost=1.305079  time=(3.3s /5.4s) 
2024-01-28 22:35:27,146 [nnabla]: epoch 63 of 100 cost=1.298278  time=(3.4s /5.4s) 
2024-01-28 22:35:27,188 [nnabla]: epoch 64 of 100 cost=1.291011  time=(3.4s /5.3s) 
2024-01-28 22:35:27,230 [nnabla]: epoch 65 of 100 cost=1.284653  time=(3.5s /5.3s) 
2024-01-28 22:35:27,271 [nnabla]: epoch 66 of 100 cost=1.278214  time=(3.5s /5.3s) 
2024-01-28 22:35:27,320 [nnabla]: epoch 67 of 100 cost=1.272180  time=(3.5s /5.3s) 
2024-01-28 22:35:27,364 [nnabla]: epoch 68 of 100 cost=1.266868  time=(3.6s /5.3s) 
2024-01-28 22:35:27,406 [nnabla]: epoch 69 of 100 cost=1.260956  time=(3.6s /5.3s) 
2024-01-28 22:35:27,497 [nnabla]: epoch 70 of 100 cost=1.256115  {train_error=1.253330, valid_error=1.253476} time=(3.7s /5.3s) 
2024-01-28 22:35:27,539 [nnabla]: epoch 71 of 100 cost=1.251058  time=(3.8s /5.3s) 
2024-01-28 22:35:27,581 [nnabla]: epoch 72 of 100 cost=1.246346  time=(3.8s /5.3s) 
2024-01-28 22:35:27,624 [nnabla]: epoch 73 of 100 cost=1.241742  time=(3.9s /5.3s) 
2024-01-28 22:35:27,666 [nnabla]: epoch 74 of 100 cost=1.237282  time=(3.9s /5.3s) 
2024-01-28 22:35:27,708 [nnabla]: epoch 75 of 100 cost=1.233315  time=(3.9s /5.3s) 
2024-01-28 22:35:27,750 [nnabla]: epoch 76 of 100 cost=1.229421  time=(4.0s /5.2s) 
2024-01-28 22:35:27,791 [nnabla]: epoch 77 of 100 cost=1.225532  time=(4.0s /5.2s) 
2024-01-28 22:35:27,840 [nnabla]: epoch 78 of 100 cost=1.221848  time=(4.1s /5.2s) 
2024-01-28 22:35:27,882 [nnabla]: epoch 79 of 100 cost=1.218362  time=(4.1s /5.2s) 
2024-01-28 22:35:27,975 [nnabla]: epoch 80 of 100 cost=1.214913  {train_error=1.213260, valid_error=1.213363} time=(4.2s /5.2s) 
2024-01-28 22:35:28,017 [nnabla]: epoch 81 of 100 cost=1.211719  time=(4.2s /5.2s) 
2024-01-28 22:35:28,059 [nnabla]: epoch 82 of 100 cost=1.208627  time=(4.3s /5.2s) 
2024-01-28 22:35:28,101 [nnabla]: epoch 83 of 100 cost=1.205576  time=(4.3s /5.2s) 
2024-01-28 22:35:28,143 [nnabla]: epoch 84 of 100 cost=1.202822  time=(4.4s /5.2s) 
2024-01-28 22:35:28,187 [nnabla]: epoch 85 of 100 cost=1.199964  time=(4.4s /5.2s) 
2024-01-28 22:35:28,230 [nnabla]: epoch 86 of 100 cost=1.197357  time=(4.5s /5.2s) 
2024-01-28 22:35:28,269 [nnabla]: epoch 87 of 100 cost=1.194784  time=(4.5s /5.2s) 
2024-01-28 22:35:28,312 [nnabla]: epoch 88 of 100 cost=1.192268  time=(4.5s /5.2s) 
2024-01-28 22:35:28,364 [nnabla]: epoch 89 of 100 cost=1.189950  time=(4.6s /5.2s) 
2024-01-28 22:35:28,461 [nnabla]: epoch 90 of 100 cost=1.187645  {train_error=1.186406, valid_error=1.186439} time=(4.6s /5.2s) 
2024-01-28 22:35:28,503 [nnabla]: epoch 91 of 100 cost=1.185376  time=(4.7s /5.2s) 
2024-01-28 22:35:28,545 [nnabla]: epoch 92 of 100 cost=1.183228  time=(4.8s /5.2s) 
2024-01-28 22:35:28,588 [nnabla]: epoch 93 of 100 cost=1.181227  time=(4.8s /5.2s) 
2024-01-28 22:35:28,630 [nnabla]: epoch 94 of 100 cost=1.179156  time=(4.9s /5.2s) 
2024-01-28 22:35:28,673 [nnabla]: epoch 95 of 100 cost=1.177271  time=(4.9s /5.2s) 
2024-01-28 22:35:28,718 [nnabla]: epoch 96 of 100 cost=1.175415  time=(4.9s /5.2s) 
2024-01-28 22:35:28,759 [nnabla]: epoch 97 of 100 cost=1.173587  time=(5.0s /5.1s) 
2024-01-28 22:35:28,800 [nnabla]: epoch 98 of 100 cost=1.171860  time=(5.0s /5.1s) 
2024-01-28 22:35:28,843 [nnabla]: epoch 99 of 100 cost=1.170132  time=(5.1s /5.1s) 
2024-01-28 22:35:28,952 [nnabla]: epoch 100 of 100 cost=1.168493  {train_error=1.167667, valid_error=1.167602} time=(5.1s /5.1s) 
2024-01-28 22:35:28,968 [nnabla]: Training Completed.
NNabla command line interface (Version:1.33.1, Build:230206070804, Callback:NNabla SSH callback module.)

2024-01-28 21:17:36,818 Training process is started.
python "C:\Users\yamas\Desktop\tools\neural_network_console\libs\Python\Lib\site-packages\nnabla\utils\cli\cli.py" train
	-c "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_211736\net.nntxt"
	-o "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_211736"
2024-01-28 21:17:37,348 [nnabla]: [CALLBACK]: Exec train on local
2024-01-28 21:17:37,353 [nnabla]: Using context "Context(backend=['cpu:float'], array_class='CpuCachedArray', device_id='')"
2024-01-28 21:17:37,354 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_test_3class_onsen.csv"
2024-01-28 21:17:37,949 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_valid_3class_onsen.csv"
2024-01-28 21:17:38,333 [nnabla]: Train with contexts ['cpu']
2024-01-28 21:17:38,352 [nnabla]: Training epoch 1 of 100 begin
2024-01-28 21:17:38,352 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 21:17:38,352 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 21:17:38,551 [nnabla]: epoch 1 of 100 cost=4.279324  {train_error=4.088312, valid_error=4.064538} time=(0.1s /8.9s) 
2024-01-28 21:17:38,646 [nnabla]: epoch 2 of 100 cost=3.796473  {train_error=3.643357, valid_error=3.618912} time=(0.2s /12.1s) 
2024-01-28 21:17:38,733 [nnabla]: epoch 3 of 100 cost=3.502208  {train_error=3.401572, valid_error=3.382746} time=(0.3s /11.2s) 
2024-01-28 21:17:38,821 [nnabla]: epoch 4 of 100 cost=3.297845  {train_error=3.248329, valid_error=3.234428} time=(0.4s /10.6s) 
2024-01-28 21:17:38,918 [nnabla]: epoch 5 of 100 cost=3.127576  {train_error=3.017124, valid_error=3.014013} time=(0.5s /10.3s) 
2024-01-28 21:17:38,966 [nnabla]: epoch 6 of 100 cost=2.996362  time=(0.6s /10.2s) 
2024-01-28 21:17:39,009 [nnabla]: epoch 7 of 100 cost=2.872884  time=(0.7s /9.4s) 
2024-01-28 21:17:39,053 [nnabla]: epoch 8 of 100 cost=2.767408  time=(0.7s /8.7s) 
2024-01-28 21:17:39,099 [nnabla]: epoch 9 of 100 cost=2.661600  time=(0.7s /8.3s) 
2024-01-28 21:17:39,197 [nnabla]: epoch 10 of 100 cost=2.563987  {train_error=2.477494, valid_error=2.487549} time=(0.8s /7.9s) 
2024-01-28 21:17:39,241 [nnabla]: epoch 11 of 100 cost=2.467560  time=(0.9s /8.1s) 
2024-01-28 21:17:39,293 [nnabla]: epoch 12 of 100 cost=2.377395  time=(0.9s /7.8s) 
2024-01-28 21:17:39,338 [nnabla]: epoch 13 of 100 cost=2.297779  time=(1.0s /7.6s) 
2024-01-28 21:17:39,382 [nnabla]: epoch 14 of 100 cost=2.203620  time=(1.0s /7.4s) 
2024-01-28 21:17:39,425 [nnabla]: epoch 15 of 100 cost=2.129421  time=(1.1s /7.2s) 
2024-01-28 21:17:39,470 [nnabla]: epoch 16 of 100 cost=2.054360  time=(1.1s /7.0s) 
2024-01-28 21:17:39,515 [nnabla]: epoch 17 of 100 cost=1.960585  time=(1.2s /6.8s) 
2024-01-28 21:17:39,558 [nnabla]: epoch 18 of 100 cost=1.899523  time=(1.2s /6.7s) 
2024-01-28 21:17:39,601 [nnabla]: epoch 19 of 100 cost=1.798801  time=(1.2s /6.6s) 
2024-01-28 21:17:39,703 [nnabla]: epoch 20 of 100 cost=1.750119  {train_error=1.687534, valid_error=1.698750} time=(1.3s /6.5s) 
2024-01-28 21:17:39,746 [nnabla]: epoch 21 of 100 cost=1.668964  time=(1.4s /6.6s) 
2024-01-28 21:17:39,789 [nnabla]: epoch 22 of 100 cost=1.610622  time=(1.4s /6.5s) 
2024-01-28 21:17:39,841 [nnabla]: epoch 23 of 100 cost=1.550380  time=(1.5s /6.4s) 
2024-01-28 21:17:39,885 [nnabla]: epoch 24 of 100 cost=1.482575  time=(1.5s /6.4s) 
2024-01-28 21:17:39,929 [nnabla]: epoch 25 of 100 cost=1.428824  time=(1.6s /6.3s) 
2024-01-28 21:17:39,974 [nnabla]: epoch 26 of 100 cost=1.354243  time=(1.6s /6.2s) 
2024-01-28 21:17:40,017 [nnabla]: epoch 27 of 100 cost=1.321333  time=(1.7s /6.2s) 
2024-01-28 21:17:40,061 [nnabla]: epoch 28 of 100 cost=1.251344  time=(1.7s /6.1s) 
2024-01-28 21:17:40,105 [nnabla]: epoch 29 of 100 cost=1.202701  time=(1.8s /6.0s) 
2024-01-28 21:17:40,202 [nnabla]: epoch 30 of 100 cost=1.154102  {train_error=1.052184, valid_error=1.063235} time=(1.8s /6.0s) 
2024-01-28 21:17:40,247 [nnabla]: epoch 31 of 100 cost=1.109138  time=(1.9s /6.1s) 
2024-01-28 21:17:40,292 [nnabla]: epoch 32 of 100 cost=1.061090  time=(1.9s /6.1s) 
2024-01-28 21:17:40,336 [nnabla]: epoch 33 of 100 cost=1.010913  time=(2.0s /6.0s) 
2024-01-28 21:17:40,386 [nnabla]: epoch 34 of 100 cost=0.965597  time=(2.0s /6.0s) 
2024-01-28 21:17:40,432 [nnabla]: epoch 35 of 100 cost=0.934225  time=(2.1s /5.9s) 
2024-01-28 21:17:40,476 [nnabla]: epoch 36 of 100 cost=0.891998  time=(2.1s /5.9s) 
2024-01-28 21:17:40,519 [nnabla]: epoch 37 of 100 cost=0.863144  time=(2.2s /5.9s) 
2024-01-28 21:17:40,563 [nnabla]: epoch 38 of 100 cost=0.831460  time=(2.2s /5.8s) 
2024-01-28 21:17:40,607 [nnabla]: epoch 39 of 100 cost=0.775537  time=(2.3s /5.8s) 
2024-01-28 21:17:40,702 [nnabla]: epoch 40 of 100 cost=0.741794  {train_error=0.638296, valid_error=0.644126} time=(2.3s /5.7s) 
2024-01-28 21:17:40,746 [nnabla]: epoch 41 of 100 cost=0.713832  time=(2.4s /5.8s) 
2024-01-28 21:17:40,792 [nnabla]: epoch 42 of 100 cost=0.678440  time=(2.4s /5.8s) 
2024-01-28 21:17:40,837 [nnabla]: epoch 43 of 100 cost=0.655984  time=(2.5s /5.8s) 
2024-01-28 21:17:40,883 [nnabla]: epoch 44 of 100 cost=0.621784  time=(2.5s /5.8s) 
2024-01-28 21:17:40,945 [nnabla]: epoch 45 of 100 cost=0.598331  time=(2.6s /5.7s) 
2024-01-28 21:17:40,989 [nnabla]: epoch 46 of 100 cost=0.584205  time=(2.6s /5.7s) 
2024-01-28 21:17:41,033 [nnabla]: epoch 47 of 100 cost=0.549898  time=(2.7s /5.7s) 
2024-01-28 21:17:41,078 [nnabla]: epoch 48 of 100 cost=0.528119  time=(2.7s /5.7s) 
2024-01-28 21:17:41,124 [nnabla]: epoch 49 of 100 cost=0.512897  time=(2.8s /5.7s) 
2024-01-28 21:17:41,219 [nnabla]: epoch 50 of 100 cost=0.487595  {train_error=0.397228, valid_error=0.408663} time=(2.8s /5.6s) 
2024-01-28 21:17:41,263 [nnabla]: epoch 51 of 100 cost=0.476822  time=(2.9s /5.7s) 
2024-01-28 21:17:41,306 [nnabla]: epoch 52 of 100 cost=0.460895  time=(3.0s /5.7s) 
2024-01-28 21:17:41,351 [nnabla]: epoch 53 of 100 cost=0.437895  time=(3.0s /5.7s) 
2024-01-28 21:17:41,399 [nnabla]: epoch 54 of 100 cost=0.425290  time=(3.0s /5.6s) 
2024-01-28 21:17:41,451 [nnabla]: epoch 55 of 100 cost=0.404788  time=(3.1s /5.6s) 
2024-01-28 21:17:41,505 [nnabla]: epoch 56 of 100 cost=0.387282  time=(3.1s /5.6s) 
2024-01-28 21:17:41,549 [nnabla]: epoch 57 of 100 cost=0.377955  time=(3.2s /5.6s) 
2024-01-28 21:17:41,592 [nnabla]: epoch 58 of 100 cost=0.360229  time=(3.2s /5.6s) 
2024-01-28 21:17:41,638 [nnabla]: epoch 59 of 100 cost=0.348623  time=(3.3s /5.6s) 
2024-01-28 21:17:41,734 [nnabla]: epoch 60 of 100 cost=0.331915  {train_error=0.241364, valid_error=0.245360} time=(3.3s /5.6s) 
2024-01-28 21:17:41,778 [nnabla]: epoch 61 of 100 cost=0.333330  time=(3.4s /5.6s) 
2024-01-28 21:17:41,822 [nnabla]: epoch 62 of 100 cost=0.325843  time=(3.5s /5.6s) 
2024-01-28 21:17:41,867 [nnabla]: epoch 63 of 100 cost=0.313895  time=(3.5s /5.6s) 
2024-01-28 21:17:41,913 [nnabla]: epoch 64 of 100 cost=0.302516  time=(3.6s /5.6s) 
2024-01-28 21:17:41,958 [nnabla]: epoch 65 of 100 cost=0.289965  time=(3.6s /5.5s) 
2024-01-28 21:17:42,003 [nnabla]: epoch 66 of 100 cost=0.291410  time=(3.7s /5.5s) 
2024-01-28 21:17:42,054 [nnabla]: epoch 67 of 100 cost=0.266710  time=(3.7s /5.5s) 
2024-01-28 21:17:42,097 [nnabla]: epoch 68 of 100 cost=0.260859  time=(3.7s /5.5s) 
2024-01-28 21:17:42,141 [nnabla]: epoch 69 of 100 cost=0.252505  time=(3.8s /5.5s) 
2024-01-28 21:17:42,236 [nnabla]: epoch 70 of 100 cost=0.255375  {train_error=0.187337, valid_error=0.193698} time=(3.8s /5.5s) 
2024-01-28 21:17:42,279 [nnabla]: epoch 71 of 100 cost=0.239116  time=(3.9s /5.5s) 
2024-01-28 21:17:42,324 [nnabla]: epoch 72 of 100 cost=0.235545  time=(4.0s /5.5s) 
2024-01-28 21:17:42,369 [nnabla]: epoch 73 of 100 cost=0.230916  time=(4.0s /5.5s) 
2024-01-28 21:17:42,413 [nnabla]: epoch 74 of 100 cost=0.217449  time=(4.1s /5.5s) 
2024-01-28 21:17:42,456 [nnabla]: epoch 75 of 100 cost=0.215160  time=(4.1s /5.5s) 
2024-01-28 21:17:42,498 [nnabla]: epoch 76 of 100 cost=0.207171  time=(4.1s /5.5s) 
2024-01-28 21:17:42,541 [nnabla]: epoch 77 of 100 cost=0.197102  time=(4.2s /5.4s) 
2024-01-28 21:17:42,594 [nnabla]: epoch 78 of 100 cost=0.196192  time=(4.2s /5.4s) 
2024-01-28 21:17:42,637 [nnabla]: epoch 79 of 100 cost=0.189881  time=(4.3s /5.4s) 
2024-01-28 21:17:42,733 [nnabla]: epoch 80 of 100 cost=0.184238  {train_error=0.130426, valid_error=0.136194} time=(4.3s /5.4s) 
2024-01-28 21:17:42,777 [nnabla]: epoch 81 of 100 cost=0.186124  time=(4.4s /5.5s) 
2024-01-28 21:17:42,821 [nnabla]: epoch 82 of 100 cost=0.177454  time=(4.5s /5.5s) 
2024-01-28 21:17:42,863 [nnabla]: epoch 83 of 100 cost=0.173523  time=(4.5s /5.4s) 
2024-01-28 21:17:42,907 [nnabla]: epoch 84 of 100 cost=0.169360  time=(4.6s /5.4s) 
2024-01-28 21:17:42,952 [nnabla]: epoch 85 of 100 cost=0.157801  time=(4.6s /5.4s) 
2024-01-28 21:17:42,995 [nnabla]: epoch 86 of 100 cost=0.165590  time=(4.6s /5.4s) 
2024-01-28 21:17:43,039 [nnabla]: epoch 87 of 100 cost=0.157568  time=(4.7s /5.4s) 
2024-01-28 21:17:43,082 [nnabla]: epoch 88 of 100 cost=0.159814  time=(4.7s /5.4s) 
2024-01-28 21:17:43,133 [nnabla]: epoch 89 of 100 cost=0.154325  time=(4.8s /5.4s) 
2024-01-28 21:17:43,230 [nnabla]: epoch 90 of 100 cost=0.151372  {train_error=0.102383, valid_error=0.107628} time=(4.8s /5.4s) 
2024-01-28 21:17:43,273 [nnabla]: epoch 91 of 100 cost=0.145952  time=(4.9s /5.4s) 
2024-01-28 21:17:43,318 [nnabla]: epoch 92 of 100 cost=0.132471  time=(5.0s /5.4s) 
2024-01-28 21:17:43,362 [nnabla]: epoch 93 of 100 cost=0.139810  time=(5.0s /5.4s) 
2024-01-28 21:17:43,405 [nnabla]: epoch 94 of 100 cost=0.125672  time=(5.1s /5.4s) 
2024-01-28 21:17:43,449 [nnabla]: epoch 95 of 100 cost=0.134878  time=(5.1s /5.4s) 
2024-01-28 21:17:43,493 [nnabla]: epoch 96 of 100 cost=0.120002  time=(5.1s /5.4s) 
2024-01-28 21:17:43,536 [nnabla]: epoch 97 of 100 cost=0.123083  time=(5.2s /5.3s) 
2024-01-28 21:17:43,579 [nnabla]: epoch 98 of 100 cost=0.114673  time=(5.2s /5.3s) 
2024-01-28 21:17:43,623 [nnabla]: epoch 99 of 100 cost=0.119577  time=(5.3s /5.3s) 
2024-01-28 21:17:43,736 [nnabla]: epoch 100 of 100 cost=0.113417  {train_error=0.075177, valid_error=0.078810} time=(5.3s /5.3s) 
2024-01-28 21:17:43,752 [nnabla]: Training Completed.
NNabla command line interface (Version:1.33.1, Build:230206070804, Callback:NNabla SSH callback module.)

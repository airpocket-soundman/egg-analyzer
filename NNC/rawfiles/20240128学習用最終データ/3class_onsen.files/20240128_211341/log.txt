2024-01-28 21:13:41,059 Training process is started.
python "C:\Users\yamas\Desktop\tools\neural_network_console\libs\Python\Lib\site-packages\nnabla\utils\cli\cli.py" train
	-c "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_211341\net.nntxt"
	-o "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_211341"
2024-01-28 21:13:41,584 [nnabla]: [CALLBACK]: Exec train on local
2024-01-28 21:13:41,590 [nnabla]: Using context "Context(backend=['cpu:float'], array_class='CpuCachedArray', device_id='')"
2024-01-28 21:13:41,590 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_test_3class_onsen.csv"
2024-01-28 21:13:42,174 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_valid_3class_onsen.csv"
2024-01-28 21:13:42,559 [nnabla]: Train with contexts ['cpu']
2024-01-28 21:13:42,579 [nnabla]: Training epoch 1 of 100 begin
2024-01-28 21:13:42,579 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 21:13:42,579 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 21:13:42,786 [nnabla]: epoch 1 of 100 cost=4.552643  {train_error=4.492205, valid_error=4.491777} time=(0.1s /9.8s) 
2024-01-28 21:13:42,889 [nnabla]: epoch 2 of 100 cost=4.435841  {train_error=4.375091, valid_error=4.374482} time=(0.3s /12.6s) 
2024-01-28 21:13:42,993 [nnabla]: epoch 3 of 100 cost=4.318137  {train_error=4.256197, valid_error=4.255291} time=(0.4s /12.0s) 
2024-01-28 21:13:43,099 [nnabla]: epoch 4 of 100 cost=4.197546  {train_error=4.134098, valid_error=4.132867} time=(0.5s /11.6s) 
2024-01-28 21:13:43,210 [nnabla]: epoch 5 of 100 cost=4.073473  {train_error=4.007724, valid_error=4.006205} time=(0.6s /11.3s) 
2024-01-28 21:13:43,259 [nnabla]: epoch 6 of 100 cost=3.945705  time=(0.7s /11.3s) 
2024-01-28 21:13:43,306 [nnabla]: epoch 7 of 100 cost=3.813895  time=(0.7s /10.4s) 
2024-01-28 21:13:43,355 [nnabla]: epoch 8 of 100 cost=3.680354  time=(0.8s /9.7s) 
2024-01-28 21:13:43,407 [nnabla]: epoch 9 of 100 cost=3.543565  time=(0.8s /9.2s) 
2024-01-28 21:13:43,521 [nnabla]: epoch 10 of 100 cost=3.402726  {train_error=3.328430, valid_error=3.324691} time=(0.9s /8.8s) 
2024-01-28 21:13:43,570 [nnabla]: epoch 11 of 100 cost=3.258218  time=(1.0s /9.0s) 
2024-01-28 21:13:43,626 [nnabla]: epoch 12 of 100 cost=3.110286  time=(1.0s /8.7s) 
2024-01-28 21:13:43,676 [nnabla]: epoch 13 of 100 cost=2.964515  time=(1.1s /8.4s) 
2024-01-28 21:13:43,723 [nnabla]: epoch 14 of 100 cost=2.818966  time=(1.1s /8.2s) 
2024-01-28 21:13:43,771 [nnabla]: epoch 15 of 100 cost=2.675995  time=(1.2s /7.9s) 
2024-01-28 21:13:43,819 [nnabla]: epoch 16 of 100 cost=2.537388  time=(1.2s /7.7s) 
2024-01-28 21:13:43,865 [nnabla]: epoch 17 of 100 cost=2.405116  time=(1.3s /7.6s) 
2024-01-28 21:13:43,914 [nnabla]: epoch 18 of 100 cost=2.285362  time=(1.3s /7.4s) 
2024-01-28 21:13:43,967 [nnabla]: epoch 19 of 100 cost=2.176498  time=(1.4s /7.3s) 
2024-01-28 21:13:44,079 [nnabla]: epoch 20 of 100 cost=2.077359  {train_error=2.028670, valid_error=2.023902} time=(1.4s /7.2s) 
2024-01-28 21:13:44,126 [nnabla]: epoch 21 of 100 cost=1.985393  time=(1.5s /7.4s) 
2024-01-28 21:13:44,174 [nnabla]: epoch 22 of 100 cost=1.898872  time=(1.6s /7.2s) 
2024-01-28 21:13:44,231 [nnabla]: epoch 23 of 100 cost=1.820265  time=(1.6s /7.1s) 
2024-01-28 21:13:44,279 [nnabla]: epoch 24 of 100 cost=1.746604  time=(1.7s /7.1s) 
2024-01-28 21:13:44,326 [nnabla]: epoch 25 of 100 cost=1.684683  time=(1.7s /7.0s) 
2024-01-28 21:13:44,374 [nnabla]: epoch 26 of 100 cost=1.630492  time=(1.8s /6.9s) 
2024-01-28 21:13:44,422 [nnabla]: epoch 27 of 100 cost=1.583562  time=(1.8s /6.8s) 
2024-01-28 21:13:44,471 [nnabla]: epoch 28 of 100 cost=1.543656  time=(1.9s /6.8s) 
2024-01-28 21:13:44,518 [nnabla]: epoch 29 of 100 cost=1.509746  time=(1.9s /6.7s) 
2024-01-28 21:13:44,632 [nnabla]: epoch 30 of 100 cost=1.479469  {train_error=1.464486, valid_error=1.461808} time=(2.0s /6.6s) 
2024-01-28 21:13:44,682 [nnabla]: epoch 31 of 100 cost=1.451638  time=(2.1s /6.8s) 
2024-01-28 21:13:44,728 [nnabla]: epoch 32 of 100 cost=1.429950  time=(2.1s /6.7s) 
2024-01-28 21:13:44,777 [nnabla]: epoch 33 of 100 cost=1.406841  time=(2.2s /6.7s) 
2024-01-28 21:13:44,833 [nnabla]: epoch 34 of 100 cost=1.387990  time=(2.2s /6.6s) 
2024-01-28 21:13:44,881 [nnabla]: epoch 35 of 100 cost=1.371037  time=(2.3s /6.6s) 
2024-01-28 21:13:44,929 [nnabla]: epoch 36 of 100 cost=1.355554  time=(2.3s /6.5s) 
2024-01-28 21:13:44,976 [nnabla]: epoch 37 of 100 cost=1.340214  time=(2.4s /6.5s) 
2024-01-28 21:13:45,024 [nnabla]: epoch 38 of 100 cost=1.328549  time=(2.4s /6.4s) 
2024-01-28 21:13:45,072 [nnabla]: epoch 39 of 100 cost=1.316027  time=(2.5s /6.4s) 
2024-01-28 21:13:45,182 [nnabla]: epoch 40 of 100 cost=1.304956  {train_error=1.299729, valid_error=1.299369} time=(2.5s /6.4s) 
2024-01-28 21:13:45,230 [nnabla]: epoch 41 of 100 cost=1.294735  time=(2.6s /6.5s) 
2024-01-28 21:13:45,276 [nnabla]: epoch 42 of 100 cost=1.285486  time=(2.7s /6.4s) 
2024-01-28 21:13:45,325 [nnabla]: epoch 43 of 100 cost=1.276678  time=(2.7s /6.4s) 
2024-01-28 21:13:45,374 [nnabla]: epoch 44 of 100 cost=1.268597  time=(2.8s /6.3s) 
2024-01-28 21:13:45,438 [nnabla]: epoch 45 of 100 cost=1.260699  time=(2.8s /6.3s) 
2024-01-28 21:13:45,485 [nnabla]: epoch 46 of 100 cost=1.254485  time=(2.9s /6.3s) 
2024-01-28 21:13:45,533 [nnabla]: epoch 47 of 100 cost=1.247748  time=(3.0s /6.3s) 
2024-01-28 21:13:45,580 [nnabla]: epoch 48 of 100 cost=1.241542  time=(3.0s /6.3s) 
2024-01-28 21:13:45,627 [nnabla]: epoch 49 of 100 cost=1.235779  time=(3.0s /6.2s) 
2024-01-28 21:13:45,740 [nnabla]: epoch 50 of 100 cost=1.230570  {train_error=1.227627, valid_error=1.228010} time=(3.1s /6.2s) 
2024-01-28 21:13:45,788 [nnabla]: epoch 51 of 100 cost=1.225112  time=(3.2s /6.3s) 
2024-01-28 21:13:45,834 [nnabla]: epoch 52 of 100 cost=1.220752  time=(3.3s /6.3s) 
2024-01-28 21:13:45,882 [nnabla]: epoch 53 of 100 cost=1.216116  time=(3.3s /6.2s) 
2024-01-28 21:13:45,931 [nnabla]: epoch 54 of 100 cost=1.211665  time=(3.4s /6.2s) 
2024-01-28 21:13:45,978 [nnabla]: epoch 55 of 100 cost=1.207940  time=(3.4s /6.2s) 
2024-01-28 21:13:46,034 [nnabla]: epoch 56 of 100 cost=1.204134  time=(3.4s /6.2s) 
2024-01-28 21:13:46,082 [nnabla]: epoch 57 of 100 cost=1.200498  time=(3.5s /6.1s) 
2024-01-28 21:13:46,130 [nnabla]: epoch 58 of 100 cost=1.196977  time=(3.6s /6.1s) 
2024-01-28 21:13:46,179 [nnabla]: epoch 59 of 100 cost=1.193886  time=(3.6s /6.1s) 
2024-01-28 21:13:46,290 [nnabla]: epoch 60 of 100 cost=1.190700  {train_error=1.189223, valid_error=1.189317} time=(3.6s /6.1s) 
2024-01-28 21:13:46,339 [nnabla]: epoch 61 of 100 cost=1.187982  time=(3.8s /6.2s) 
2024-01-28 21:13:46,388 [nnabla]: epoch 62 of 100 cost=1.184973  time=(3.8s /6.1s) 
2024-01-28 21:13:46,436 [nnabla]: epoch 63 of 100 cost=1.182520  time=(3.9s /6.1s) 
2024-01-28 21:13:46,484 [nnabla]: epoch 64 of 100 cost=1.179768  time=(3.9s /6.1s) 
2024-01-28 21:13:46,532 [nnabla]: epoch 65 of 100 cost=1.177469  time=(4.0s /6.1s) 
2024-01-28 21:13:46,579 [nnabla]: epoch 66 of 100 cost=1.175132  time=(4.0s /6.1s) 
2024-01-28 21:13:46,635 [nnabla]: epoch 67 of 100 cost=1.172809  time=(4.0s /6.0s) 
2024-01-28 21:13:46,681 [nnabla]: epoch 68 of 100 cost=1.170942  time=(4.1s /6.0s) 
2024-01-28 21:13:46,729 [nnabla]: epoch 69 of 100 cost=1.168667  time=(4.1s /6.0s) 
2024-01-28 21:13:46,840 [nnabla]: epoch 70 of 100 cost=1.166914  {train_error=1.165779, valid_error=1.165860} time=(4.2s /6.0s) 
2024-01-28 21:13:46,892 [nnabla]: epoch 71 of 100 cost=1.164973  time=(4.3s /6.1s) 
2024-01-28 21:13:46,943 [nnabla]: epoch 72 of 100 cost=1.163208  time=(4.4s /6.1s) 
2024-01-28 21:13:46,991 [nnabla]: epoch 73 of 100 cost=1.161466  time=(4.4s /6.0s) 
2024-01-28 21:13:47,038 [nnabla]: epoch 74 of 100 cost=1.159674  time=(4.5s /6.0s) 
2024-01-28 21:13:47,085 [nnabla]: epoch 75 of 100 cost=1.158262  time=(4.5s /6.0s) 
2024-01-28 21:13:47,132 [nnabla]: epoch 76 of 100 cost=1.156787  time=(4.6s /6.0s) 
2024-01-28 21:13:47,185 [nnabla]: epoch 77 of 100 cost=1.155301  time=(4.6s /6.0s) 
2024-01-28 21:13:47,240 [nnabla]: epoch 78 of 100 cost=1.153843  time=(4.7s /6.0s) 
2024-01-28 21:13:47,286 [nnabla]: epoch 79 of 100 cost=1.152461  time=(4.7s /6.0s) 
2024-01-28 21:13:47,400 [nnabla]: epoch 80 of 100 cost=1.151105  {train_error=1.150454, valid_error=1.150569} time=(4.8s /5.9s) 
2024-01-28 21:13:47,447 [nnabla]: epoch 81 of 100 cost=1.149870  time=(4.9s /6.0s) 
2024-01-28 21:13:47,493 [nnabla]: epoch 82 of 100 cost=1.148661  time=(4.9s /6.0s) 
2024-01-28 21:13:47,541 [nnabla]: epoch 83 of 100 cost=1.147413  time=(5.0s /6.0s) 
2024-01-28 21:13:47,587 [nnabla]: epoch 84 of 100 cost=1.146415  time=(5.0s /6.0s) 
2024-01-28 21:13:47,634 [nnabla]: epoch 85 of 100 cost=1.145205  time=(5.1s /5.9s) 
2024-01-28 21:13:47,682 [nnabla]: epoch 86 of 100 cost=1.144216  time=(5.1s /5.9s) 
2024-01-28 21:13:47,730 [nnabla]: epoch 87 of 100 cost=1.143170  time=(5.1s /5.9s) 
2024-01-28 21:13:47,778 [nnabla]: epoch 88 of 100 cost=1.142129  time=(5.2s /5.9s) 
2024-01-28 21:13:47,832 [nnabla]: epoch 89 of 100 cost=1.141274  time=(5.2s /5.9s) 
2024-01-28 21:13:47,945 [nnabla]: epoch 90 of 100 cost=1.140304  {train_error=1.139740, valid_error=1.139776} time=(5.3s /5.9s) 
2024-01-28 21:13:47,992 [nnabla]: epoch 91 of 100 cost=1.139365  time=(5.4s /5.9s) 
2024-01-28 21:13:48,039 [nnabla]: epoch 92 of 100 cost=1.138459  time=(5.5s /5.9s) 
2024-01-28 21:13:48,087 [nnabla]: epoch 93 of 100 cost=1.137709  time=(5.5s /5.9s) 
2024-01-28 21:13:48,134 [nnabla]: epoch 94 of 100 cost=1.136773  time=(5.6s /5.9s) 
2024-01-28 21:13:48,181 [nnabla]: epoch 95 of 100 cost=1.136049  time=(5.6s /5.9s) 
2024-01-28 21:13:48,231 [nnabla]: epoch 96 of 100 cost=1.135288  time=(5.7s /5.9s) 
2024-01-28 21:13:48,279 [nnabla]: epoch 97 of 100 cost=1.134502  time=(5.7s /5.9s) 
2024-01-28 21:13:48,327 [nnabla]: epoch 98 of 100 cost=1.133801  time=(5.7s /5.9s) 
2024-01-28 21:13:48,376 [nnabla]: epoch 99 of 100 cost=1.133036  time=(5.8s /5.9s) 
2024-01-28 21:13:48,504 [nnabla]: epoch 100 of 100 cost=1.132343  {train_error=1.131998, valid_error=1.131908} time=(5.8s /5.8s) 
2024-01-28 21:13:48,520 [nnabla]: Training Completed.
NNabla command line interface (Version:1.33.1, Build:230206070804, Callback:NNabla SSH callback module.)

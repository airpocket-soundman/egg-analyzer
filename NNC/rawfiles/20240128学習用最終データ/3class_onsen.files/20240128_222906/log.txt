2024-01-28 22:29:06,547 Training process is started.
python "C:\Users\yamas\Desktop\tools\neural_network_console\libs\Python\Lib\site-packages\nnabla\utils\cli\cli.py" train
	-c "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_222906\net.nntxt"
	-o "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_222906"
2024-01-28 22:29:07,093 [nnabla]: [CALLBACK]: Exec train on local
2024-01-28 22:29:07,101 [nnabla]: Using context "Context(backend=['cpu:float'], array_class='CpuCachedArray', device_id='')"
2024-01-28 22:29:07,101 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_test_3class_onsen.csv"
2024-01-28 22:29:07,687 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_valid_3class_onsen.csv"
2024-01-28 22:29:08,074 [nnabla]: Train with contexts ['cpu']
2024-01-28 22:29:08,098 [nnabla]: Training epoch 1 of 100 begin
2024-01-28 22:29:08,098 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 22:29:08,098 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 22:29:08,296 [nnabla]: epoch 1 of 100 cost=4.592916  {train_error=3.759047, valid_error=3.732829} time=(0.1s /8.6s) 
2024-01-28 22:29:08,376 [nnabla]: epoch 2 of 100 cost=3.986469  {train_error=3.672146, valid_error=3.641616} time=(0.2s /11.8s) 
2024-01-28 22:29:08,461 [nnabla]: epoch 3 of 100 cost=3.742002  {train_error=3.596823, valid_error=3.567422} time=(0.3s /10.7s) 
2024-01-28 22:29:08,543 [nnabla]: epoch 4 of 100 cost=3.573540  {train_error=3.463498, valid_error=3.439982} time=(0.4s /10.1s) 
2024-01-28 22:29:08,633 [nnabla]: epoch 5 of 100 cost=3.438501  {train_error=3.321931, valid_error=3.310914} time=(0.5s /9.7s) 
2024-01-28 22:29:08,674 [nnabla]: epoch 6 of 100 cost=3.354052  time=(0.6s /9.6s) 
2024-01-28 22:29:08,714 [nnabla]: epoch 7 of 100 cost=3.257426  time=(0.6s /8.8s) 
2024-01-28 22:29:08,753 [nnabla]: epoch 8 of 100 cost=3.167351  time=(0.7s /8.2s) 
2024-01-28 22:29:08,792 [nnabla]: epoch 9 of 100 cost=3.089373  time=(0.7s /7.7s) 
2024-01-28 22:29:08,882 [nnabla]: epoch 10 of 100 cost=3.020763  {train_error=2.860467, valid_error=2.851408} time=(0.7s /7.3s) 
2024-01-28 22:29:08,922 [nnabla]: epoch 11 of 100 cost=2.933493  time=(0.8s /7.5s) 
2024-01-28 22:29:08,972 [nnabla]: epoch 12 of 100 cost=2.857913  time=(0.9s /7.2s) 
2024-01-28 22:29:09,013 [nnabla]: epoch 13 of 100 cost=2.782704  time=(0.9s /7.0s) 
2024-01-28 22:29:09,053 [nnabla]: epoch 14 of 100 cost=2.713367  time=(1.0s /6.8s) 
2024-01-28 22:29:09,093 [nnabla]: epoch 15 of 100 cost=2.636339  time=(1.0s /6.6s) 
2024-01-28 22:29:09,134 [nnabla]: epoch 16 of 100 cost=2.572492  time=(1.0s /6.5s) 
2024-01-28 22:29:09,176 [nnabla]: epoch 17 of 100 cost=2.500300  time=(1.1s /6.3s) 
2024-01-28 22:29:09,217 [nnabla]: epoch 18 of 100 cost=2.432395  time=(1.1s /6.2s) 
2024-01-28 22:29:09,257 [nnabla]: epoch 19 of 100 cost=2.369553  time=(1.2s /6.1s) 
2024-01-28 22:29:09,346 [nnabla]: epoch 20 of 100 cost=2.315732  {train_error=2.214121, valid_error=2.214508} time=(1.2s /6.0s) 
2024-01-28 22:29:09,387 [nnabla]: epoch 21 of 100 cost=2.237583  time=(1.3s /6.1s) 
2024-01-28 22:29:09,429 [nnabla]: epoch 22 of 100 cost=2.175669  time=(1.3s /6.1s) 
2024-01-28 22:29:09,477 [nnabla]: epoch 23 of 100 cost=2.121835  time=(1.4s /6.0s) 
2024-01-28 22:29:09,515 [nnabla]: epoch 24 of 100 cost=2.053263  time=(1.4s /5.9s) 
2024-01-28 22:29:09,555 [nnabla]: epoch 25 of 100 cost=2.015014  time=(1.5s /5.8s) 
2024-01-28 22:29:09,594 [nnabla]: epoch 26 of 100 cost=1.950689  time=(1.5s /5.8s) 
2024-01-28 22:29:09,634 [nnabla]: epoch 27 of 100 cost=1.885437  time=(1.5s /5.7s) 
2024-01-28 22:29:09,673 [nnabla]: epoch 28 of 100 cost=1.834277  time=(1.6s /5.6s) 
2024-01-28 22:29:09,714 [nnabla]: epoch 29 of 100 cost=1.804696  time=(1.6s /5.6s) 
2024-01-28 22:29:09,804 [nnabla]: epoch 30 of 100 cost=1.730066  {train_error=1.650563, valid_error=1.655179} time=(1.7s /5.5s) 
2024-01-28 22:29:09,845 [nnabla]: epoch 31 of 100 cost=1.696342  time=(1.7s /5.6s) 
2024-01-28 22:29:09,884 [nnabla]: epoch 32 of 100 cost=1.647963  time=(1.8s /5.6s) 
2024-01-28 22:29:09,923 [nnabla]: epoch 33 of 100 cost=1.592758  time=(1.8s /5.5s) 
2024-01-28 22:29:09,975 [nnabla]: epoch 34 of 100 cost=1.559319  time=(1.9s /5.5s) 
2024-01-28 22:29:10,016 [nnabla]: epoch 35 of 100 cost=1.523721  time=(1.9s /5.5s) 
2024-01-28 22:29:10,055 [nnabla]: epoch 36 of 100 cost=1.473079  time=(2.0s /5.4s) 
2024-01-28 22:29:10,095 [nnabla]: epoch 37 of 100 cost=1.433851  time=(2.0s /5.4s) 
2024-01-28 22:29:10,133 [nnabla]: epoch 38 of 100 cost=1.407480  time=(2.0s /5.4s) 
2024-01-28 22:29:10,172 [nnabla]: epoch 39 of 100 cost=1.354119  time=(2.1s /5.3s) 
2024-01-28 22:29:10,266 [nnabla]: epoch 40 of 100 cost=1.351488  {train_error=1.254947, valid_error=1.251165} time=(2.1s /5.3s) 
2024-01-28 22:29:10,305 [nnabla]: epoch 41 of 100 cost=1.286744  time=(2.2s /5.4s) 
2024-01-28 22:29:10,344 [nnabla]: epoch 42 of 100 cost=1.275876  time=(2.2s /5.3s) 
2024-01-28 22:29:10,383 [nnabla]: epoch 43 of 100 cost=1.242982  time=(2.3s /5.3s) 
2024-01-28 22:29:10,423 [nnabla]: epoch 44 of 100 cost=1.211823  time=(2.3s /5.3s) 
2024-01-28 22:29:10,484 [nnabla]: epoch 45 of 100 cost=1.161094  time=(2.4s /5.3s) 
2024-01-28 22:29:10,526 [nnabla]: epoch 46 of 100 cost=1.167636  time=(2.4s /5.3s) 
2024-01-28 22:29:10,565 [nnabla]: epoch 47 of 100 cost=1.122424  time=(2.5s /5.2s) 
2024-01-28 22:29:10,604 [nnabla]: epoch 48 of 100 cost=1.102604  time=(2.5s /5.2s) 
2024-01-28 22:29:10,643 [nnabla]: epoch 49 of 100 cost=1.087915  time=(2.5s /5.2s) 
2024-01-28 22:29:10,739 [nnabla]: epoch 50 of 100 cost=1.056421  {train_error=1.001932, valid_error=1.001175} time=(2.6s /5.2s) 
2024-01-28 22:29:10,778 [nnabla]: epoch 51 of 100 cost=1.022614  time=(2.7s /5.3s) 
2024-01-28 22:29:10,817 [nnabla]: epoch 52 of 100 cost=1.025331  time=(2.7s /5.2s) 
2024-01-28 22:29:10,856 [nnabla]: epoch 53 of 100 cost=1.016995  time=(2.8s /5.2s) 
2024-01-28 22:29:10,894 [nnabla]: epoch 54 of 100 cost=0.976467  time=(2.8s /5.2s) 
2024-01-28 22:29:10,934 [nnabla]: epoch 55 of 100 cost=0.962201  time=(2.8s /5.2s) 
2024-01-28 22:29:10,983 [nnabla]: epoch 56 of 100 cost=0.941088  time=(2.9s /5.1s) 
2024-01-28 22:29:11,023 [nnabla]: epoch 57 of 100 cost=0.921083  time=(2.9s /5.1s) 
2024-01-28 22:29:11,063 [nnabla]: epoch 58 of 100 cost=0.912887  time=(3.0s /5.1s) 
2024-01-28 22:29:11,103 [nnabla]: epoch 59 of 100 cost=0.883320  time=(3.0s /5.1s) 
2024-01-28 22:29:11,193 [nnabla]: epoch 60 of 100 cost=0.876460  {train_error=0.833339, valid_error=0.830924} time=(3.0s /5.1s) 
2024-01-28 22:29:11,232 [nnabla]: epoch 61 of 100 cost=0.886702  time=(3.1s /5.1s) 
2024-01-28 22:29:11,273 [nnabla]: epoch 62 of 100 cost=0.842211  time=(3.2s /5.1s) 
2024-01-28 22:29:11,312 [nnabla]: epoch 63 of 100 cost=0.856201  time=(3.2s /5.1s) 
2024-01-28 22:29:11,351 [nnabla]: epoch 64 of 100 cost=0.837362  time=(3.3s /5.1s) 
2024-01-28 22:29:11,392 [nnabla]: epoch 65 of 100 cost=0.814915  time=(3.3s /5.1s) 
2024-01-28 22:29:11,432 [nnabla]: epoch 66 of 100 cost=0.823617  time=(3.3s /5.0s) 
2024-01-28 22:29:11,480 [nnabla]: epoch 67 of 100 cost=0.800662  time=(3.4s /5.0s) 
2024-01-28 22:29:11,521 [nnabla]: epoch 68 of 100 cost=0.796160  time=(3.4s /5.0s) 
2024-01-28 22:29:11,560 [nnabla]: epoch 69 of 100 cost=0.757344  time=(3.5s /5.0s) 
2024-01-28 22:29:11,650 [nnabla]: epoch 70 of 100 cost=0.788738  {train_error=0.712352, valid_error=0.702451} time=(3.5s /5.0s) 
2024-01-28 22:29:11,690 [nnabla]: epoch 71 of 100 cost=0.766165  time=(3.6s /5.1s) 
2024-01-28 22:29:11,730 [nnabla]: epoch 72 of 100 cost=0.757087  time=(3.6s /5.0s) 
2024-01-28 22:29:11,770 [nnabla]: epoch 73 of 100 cost=0.745293  time=(3.7s /5.0s) 
2024-01-28 22:29:11,809 [nnabla]: epoch 74 of 100 cost=0.732823  time=(3.7s /5.0s) 
2024-01-28 22:29:11,847 [nnabla]: epoch 75 of 100 cost=0.715264  time=(3.7s /5.0s) 
2024-01-28 22:29:11,887 [nnabla]: epoch 76 of 100 cost=0.742637  time=(3.8s /5.0s) 
2024-01-28 22:29:11,928 [nnabla]: epoch 77 of 100 cost=0.698806  time=(3.8s /5.0s) 
2024-01-28 22:29:11,977 [nnabla]: epoch 78 of 100 cost=0.710368  time=(3.9s /5.0s) 
2024-01-28 22:29:12,018 [nnabla]: epoch 79 of 100 cost=0.701130  time=(3.9s /5.0s) 
2024-01-28 22:29:12,107 [nnabla]: epoch 80 of 100 cost=0.690701  {train_error=0.652276, valid_error=0.645139} time=(4.0s /4.9s) 
2024-01-28 22:29:12,147 [nnabla]: epoch 81 of 100 cost=0.678119  time=(4.0s /5.0s) 
2024-01-28 22:29:12,187 [nnabla]: epoch 82 of 100 cost=0.700111  time=(4.1s /5.0s) 
2024-01-28 22:29:12,229 [nnabla]: epoch 83 of 100 cost=0.677330  time=(4.1s /5.0s) 
2024-01-28 22:29:12,267 [nnabla]: epoch 84 of 100 cost=0.654974  time=(4.2s /5.0s) 
2024-01-28 22:29:12,308 [nnabla]: epoch 85 of 100 cost=0.657753  time=(4.2s /5.0s) 
2024-01-28 22:29:12,347 [nnabla]: epoch 86 of 100 cost=0.684484  time=(4.2s /4.9s) 
2024-01-28 22:29:12,387 [nnabla]: epoch 87 of 100 cost=0.655052  time=(4.3s /4.9s) 
2024-01-28 22:29:12,426 [nnabla]: epoch 88 of 100 cost=0.657225  time=(4.3s /4.9s) 
2024-01-28 22:29:12,476 [nnabla]: epoch 89 of 100 cost=0.642722  time=(4.4s /4.9s) 
2024-01-28 22:29:12,567 [nnabla]: epoch 90 of 100 cost=0.651199  {train_error=0.604471, valid_error=0.597042} time=(4.4s /4.9s) 
2024-01-28 22:29:12,606 [nnabla]: epoch 91 of 100 cost=0.628182  time=(4.5s /5.0s) 
2024-01-28 22:29:12,646 [nnabla]: epoch 92 of 100 cost=0.633613  time=(4.5s /4.9s) 
2024-01-28 22:29:12,686 [nnabla]: epoch 93 of 100 cost=0.617546  time=(4.6s /4.9s) 
2024-01-28 22:29:12,726 [nnabla]: epoch 94 of 100 cost=0.629783  time=(4.6s /4.9s) 
2024-01-28 22:29:12,765 [nnabla]: epoch 95 of 100 cost=0.624149  time=(4.7s /4.9s) 
2024-01-28 22:29:12,805 [nnabla]: epoch 96 of 100 cost=0.609888  time=(4.7s /4.9s) 
2024-01-28 22:29:12,845 [nnabla]: epoch 97 of 100 cost=0.616202  time=(4.7s /4.9s) 
2024-01-28 22:29:12,885 [nnabla]: epoch 98 of 100 cost=0.608418  time=(4.8s /4.9s) 
2024-01-28 22:29:12,924 [nnabla]: epoch 99 of 100 cost=0.611506  time=(4.8s /4.9s) 
2024-01-28 22:29:13,033 [nnabla]: epoch 100 of 100 cost=0.600649  {train_error=0.582140, valid_error=0.570864} time=(4.9s /4.9s) 
2024-01-28 22:29:13,052 [nnabla]: Training Completed.
NNabla command line interface (Version:1.33.1, Build:230206070804, Callback:NNabla SSH callback module.)

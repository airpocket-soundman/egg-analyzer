2024-01-28 22:33:38,568 Training process is started.
python "C:\Users\yamas\Desktop\tools\neural_network_console\libs\Python\Lib\site-packages\nnabla\utils\cli\cli.py" train
	-c "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_223338\net.nntxt"
	-o "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_223338"
2024-01-28 22:33:39,105 [nnabla]: [CALLBACK]: Exec train on local
2024-01-28 22:33:39,111 [nnabla]: Using context "Context(backend=['cpu:float'], array_class='CpuCachedArray', device_id='')"
2024-01-28 22:33:39,112 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_test_3class_onsen.csv"
2024-01-28 22:33:39,694 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_valid_3class_onsen.csv"
2024-01-28 22:33:40,073 [nnabla]: Train with contexts ['cpu']
2024-01-28 22:33:40,096 [nnabla]: Training epoch 1 of 100 begin
2024-01-28 22:33:40,096 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 22:33:40,096 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 22:33:40,299 [nnabla]: epoch 1 of 100 cost=4.554833  {train_error=4.240460, valid_error=4.253824} time=(0.1s /9.4s) 
2024-01-28 22:33:40,376 [nnabla]: epoch 2 of 100 cost=4.378629  {train_error=3.940480, valid_error=3.934829} time=(0.2s /11.6s) 
2024-01-28 22:33:40,457 [nnabla]: epoch 3 of 100 cost=4.118868  {train_error=3.894588, valid_error=3.873436} time=(0.3s /10.4s) 
2024-01-28 22:33:40,532 [nnabla]: epoch 4 of 100 cost=3.846109  {train_error=3.672985, valid_error=3.645433} time=(0.4s /9.8s) 
2024-01-28 22:33:40,616 [nnabla]: epoch 5 of 100 cost=3.638416  {train_error=3.591997, valid_error=3.566101} time=(0.5s /9.3s) 
2024-01-28 22:33:40,644 [nnabla]: epoch 6 of 100 cost=3.497529  time=(0.5s /9.1s) 
2024-01-28 22:33:40,675 [nnabla]: epoch 7 of 100 cost=3.361498  time=(0.6s /8.3s) 
2024-01-28 22:33:40,705 [nnabla]: epoch 8 of 100 cost=3.251355  time=(0.6s /7.6s) 
2024-01-28 22:33:40,734 [nnabla]: epoch 9 of 100 cost=3.147618  time=(0.6s /7.1s) 
2024-01-28 22:33:40,815 [nnabla]: epoch 10 of 100 cost=3.041271  {train_error=2.915393, valid_error=2.886922} time=(0.7s /6.7s) 
2024-01-28 22:33:40,846 [nnabla]: epoch 11 of 100 cost=2.947481  time=(0.7s /6.8s) 
2024-01-28 22:33:40,884 [nnabla]: epoch 12 of 100 cost=2.820994  time=(0.8s /6.5s) 
2024-01-28 22:33:40,914 [nnabla]: epoch 13 of 100 cost=2.694625  time=(0.8s /6.3s) 
2024-01-28 22:33:40,944 [nnabla]: epoch 14 of 100 cost=2.513994  time=(0.8s /6.1s) 
2024-01-28 22:33:40,974 [nnabla]: epoch 15 of 100 cost=2.318283  time=(0.9s /5.9s) 
2024-01-28 22:33:41,004 [nnabla]: epoch 16 of 100 cost=2.154985  time=(0.9s /5.7s) 
2024-01-28 22:33:41,033 [nnabla]: epoch 17 of 100 cost=2.003274  time=(0.9s /5.5s) 
2024-01-28 22:33:41,063 [nnabla]: epoch 18 of 100 cost=1.881141  time=(1.0s /5.4s) 
2024-01-28 22:33:41,093 [nnabla]: epoch 19 of 100 cost=1.753541  time=(1.0s /5.2s) 
2024-01-28 22:33:41,178 [nnabla]: epoch 20 of 100 cost=1.659374  {train_error=1.673465, valid_error=1.685171} time=(1.0s /5.1s) 
2024-01-28 22:33:41,208 [nnabla]: epoch 21 of 100 cost=1.554317  time=(1.1s /5.3s) 
2024-01-28 22:33:41,242 [nnabla]: epoch 22 of 100 cost=1.477757  time=(1.1s /5.2s) 
2024-01-28 22:33:41,280 [nnabla]: epoch 23 of 100 cost=1.394090  time=(1.2s /5.1s) 
2024-01-28 22:33:41,309 [nnabla]: epoch 24 of 100 cost=1.318962  time=(1.2s /5.1s) 
2024-01-28 22:33:41,338 [nnabla]: epoch 25 of 100 cost=1.265168  time=(1.2s /5.0s) 
2024-01-28 22:33:41,369 [nnabla]: epoch 26 of 100 cost=1.189409  time=(1.3s /4.9s) 
2024-01-28 22:33:41,399 [nnabla]: epoch 27 of 100 cost=1.149561  time=(1.3s /4.8s) 
2024-01-28 22:33:41,429 [nnabla]: epoch 28 of 100 cost=1.086710  time=(1.3s /4.8s) 
2024-01-28 22:33:41,457 [nnabla]: epoch 29 of 100 cost=1.036168  time=(1.4s /4.7s) 
2024-01-28 22:33:41,544 [nnabla]: epoch 30 of 100 cost=0.978860  {train_error=0.918516, valid_error=0.919320} time=(1.4s /4.6s) 
2024-01-28 22:33:41,574 [nnabla]: epoch 31 of 100 cost=0.934204  time=(1.5s /4.8s) 
2024-01-28 22:33:41,603 [nnabla]: epoch 32 of 100 cost=0.889419  time=(1.5s /4.7s) 
2024-01-28 22:33:41,632 [nnabla]: epoch 33 of 100 cost=0.844264  time=(1.5s /4.7s) 
2024-01-28 22:33:41,670 [nnabla]: epoch 34 of 100 cost=0.809149  time=(1.6s /4.6s) 
2024-01-28 22:33:41,702 [nnabla]: epoch 35 of 100 cost=0.768773  time=(1.6s /4.6s) 
2024-01-28 22:33:41,730 [nnabla]: epoch 36 of 100 cost=0.732143  time=(1.6s /4.5s) 
2024-01-28 22:33:41,761 [nnabla]: epoch 37 of 100 cost=0.714280  time=(1.7s /4.5s) 
2024-01-28 22:33:41,793 [nnabla]: epoch 38 of 100 cost=0.681639  time=(1.7s /4.5s) 
2024-01-28 22:33:41,821 [nnabla]: epoch 39 of 100 cost=0.636911  time=(1.7s /4.4s) 
2024-01-28 22:33:41,903 [nnabla]: epoch 40 of 100 cost=0.615943  {train_error=0.593114, valid_error=0.591421} time=(1.8s /4.4s) 
2024-01-28 22:33:41,932 [nnabla]: epoch 41 of 100 cost=0.583106  time=(1.8s /4.5s) 
2024-01-28 22:33:41,960 [nnabla]: epoch 42 of 100 cost=0.564604  time=(1.9s /4.4s) 
2024-01-28 22:33:41,989 [nnabla]: epoch 43 of 100 cost=0.542202  time=(1.9s /4.4s) 
2024-01-28 22:33:42,019 [nnabla]: epoch 44 of 100 cost=0.511627  time=(1.9s /4.4s) 
2024-01-28 22:33:42,064 [nnabla]: epoch 45 of 100 cost=0.490442  time=(2.0s /4.3s) 
2024-01-28 22:33:42,094 [nnabla]: epoch 46 of 100 cost=0.478150  time=(2.0s /4.3s) 
2024-01-28 22:33:42,125 [nnabla]: epoch 47 of 100 cost=0.454194  time=(2.0s /4.3s) 
2024-01-28 22:33:42,154 [nnabla]: epoch 48 of 100 cost=0.436236  time=(2.1s /4.3s) 
2024-01-28 22:33:42,183 [nnabla]: epoch 49 of 100 cost=0.419584  time=(2.1s /4.3s) 
2024-01-28 22:33:42,265 [nnabla]: epoch 50 of 100 cost=0.397805  {train_error=0.372989, valid_error=0.376745} time=(2.1s /4.2s) 
2024-01-28 22:33:42,296 [nnabla]: epoch 51 of 100 cost=0.394382  time=(2.2s /4.3s) 
2024-01-28 22:33:42,325 [nnabla]: epoch 52 of 100 cost=0.376329  time=(2.2s /4.3s) 
2024-01-28 22:33:42,354 [nnabla]: epoch 53 of 100 cost=0.363816  time=(2.3s /4.3s) 
2024-01-28 22:33:42,383 [nnabla]: epoch 54 of 100 cost=0.347782  time=(2.3s /4.2s) 
2024-01-28 22:33:42,413 [nnabla]: epoch 55 of 100 cost=0.336280  time=(2.3s /4.2s) 
2024-01-28 22:33:42,450 [nnabla]: epoch 56 of 100 cost=0.317761  time=(2.3s /4.2s) 
2024-01-28 22:33:42,482 [nnabla]: epoch 57 of 100 cost=0.313614  time=(2.4s /4.2s) 
2024-01-28 22:33:42,515 [nnabla]: epoch 58 of 100 cost=0.295650  time=(2.4s /4.2s) 
2024-01-28 22:33:42,546 [nnabla]: epoch 59 of 100 cost=0.286600  time=(2.5s /4.2s) 
2024-01-28 22:33:42,628 [nnabla]: epoch 60 of 100 cost=0.274758  {train_error=0.256872, valid_error=0.253051} time=(2.5s /4.1s) 
2024-01-28 22:33:42,658 [nnabla]: epoch 61 of 100 cost=0.270112  time=(2.6s /4.2s) 
2024-01-28 22:33:42,686 [nnabla]: epoch 62 of 100 cost=0.268054  time=(2.6s /4.2s) 
2024-01-28 22:33:42,716 [nnabla]: epoch 63 of 100 cost=0.253052  time=(2.6s /4.2s) 
2024-01-28 22:33:42,749 [nnabla]: epoch 64 of 100 cost=0.249504  time=(2.7s /4.1s) 
2024-01-28 22:33:42,783 [nnabla]: epoch 65 of 100 cost=0.236350  time=(2.7s /4.1s) 
2024-01-28 22:33:42,812 [nnabla]: epoch 66 of 100 cost=0.234752  time=(2.7s /4.1s) 
2024-01-28 22:33:42,849 [nnabla]: epoch 67 of 100 cost=0.222128  time=(2.7s /4.1s) 
2024-01-28 22:33:42,880 [nnabla]: epoch 68 of 100 cost=0.211490  time=(2.8s /4.1s) 
2024-01-28 22:33:42,909 [nnabla]: epoch 69 of 100 cost=0.207671  time=(2.8s /4.1s) 
2024-01-28 22:33:42,992 [nnabla]: epoch 70 of 100 cost=0.209993  {train_error=0.177464, valid_error=0.175386} time=(2.8s /4.1s) 
2024-01-28 22:33:43,023 [nnabla]: epoch 71 of 100 cost=0.196521  time=(2.9s /4.1s) 
2024-01-28 22:33:43,055 [nnabla]: epoch 72 of 100 cost=0.191805  time=(3.0s /4.1s) 
2024-01-28 22:33:43,085 [nnabla]: epoch 73 of 100 cost=0.187053  time=(3.0s /4.1s) 
2024-01-28 22:33:43,115 [nnabla]: epoch 74 of 100 cost=0.179763  time=(3.0s /4.1s) 
2024-01-28 22:33:43,143 [nnabla]: epoch 75 of 100 cost=0.173219  time=(3.0s /4.1s) 
2024-01-28 22:33:43,173 [nnabla]: epoch 76 of 100 cost=0.169520  time=(3.1s /4.0s) 
2024-01-28 22:33:43,202 [nnabla]: epoch 77 of 100 cost=0.160293  time=(3.1s /4.0s) 
2024-01-28 22:33:43,238 [nnabla]: epoch 78 of 100 cost=0.162015  time=(3.1s /4.0s) 
2024-01-28 22:33:43,269 [nnabla]: epoch 79 of 100 cost=0.153644  time=(3.2s /4.0s) 
2024-01-28 22:33:43,355 [nnabla]: epoch 80 of 100 cost=0.151999  {train_error=0.130868, valid_error=0.132103} time=(3.2s /4.0s) 
2024-01-28 22:33:43,387 [nnabla]: epoch 81 of 100 cost=0.149813  time=(3.3s /4.1s) 
2024-01-28 22:33:43,420 [nnabla]: epoch 82 of 100 cost=0.146955  time=(3.3s /4.1s) 
2024-01-28 22:33:43,451 [nnabla]: epoch 83 of 100 cost=0.141621  time=(3.4s /4.0s) 
2024-01-28 22:33:43,482 [nnabla]: epoch 84 of 100 cost=0.135147  time=(3.4s /4.0s) 
2024-01-28 22:33:43,511 [nnabla]: epoch 85 of 100 cost=0.128914  time=(3.4s /4.0s) 
2024-01-28 22:33:43,540 [nnabla]: epoch 86 of 100 cost=0.131491  time=(3.4s /4.0s) 
2024-01-28 22:33:43,569 [nnabla]: epoch 87 of 100 cost=0.126152  time=(3.5s /4.0s) 
2024-01-28 22:33:43,599 [nnabla]: epoch 88 of 100 cost=0.129262  time=(3.5s /4.0s) 
2024-01-28 22:33:43,636 [nnabla]: epoch 89 of 100 cost=0.123276  time=(3.5s /4.0s) 
2024-01-28 22:33:43,718 [nnabla]: epoch 90 of 100 cost=0.118398  {train_error=0.099215, valid_error=0.099429} time=(3.6s /4.0s) 
2024-01-28 22:33:43,747 [nnabla]: epoch 91 of 100 cost=0.117332  time=(3.7s /4.0s) 
2024-01-28 22:33:43,776 [nnabla]: epoch 92 of 100 cost=0.107707  time=(3.7s /4.0s) 
2024-01-28 22:33:43,807 [nnabla]: epoch 93 of 100 cost=0.112867  time=(3.7s /4.0s) 
2024-01-28 22:33:43,835 [nnabla]: epoch 94 of 100 cost=0.103033  time=(3.7s /4.0s) 
2024-01-28 22:33:43,865 [nnabla]: epoch 95 of 100 cost=0.108635  time=(3.8s /4.0s) 
2024-01-28 22:33:43,894 [nnabla]: epoch 96 of 100 cost=0.097386  time=(3.8s /4.0s) 
2024-01-28 22:33:43,924 [nnabla]: epoch 97 of 100 cost=0.098638  time=(3.8s /3.9s) 
2024-01-28 22:33:43,953 [nnabla]: epoch 98 of 100 cost=0.093584  time=(3.9s /3.9s) 
2024-01-28 22:33:43,981 [nnabla]: epoch 99 of 100 cost=0.096037  time=(3.9s /3.9s) 
2024-01-28 22:33:44,083 [nnabla]: epoch 100 of 100 cost=0.091138  {train_error=0.079110, valid_error=0.079982} time=(3.9s /3.9s) 
2024-01-28 22:33:44,098 [nnabla]: Training Completed.
NNabla command line interface (Version:1.33.1, Build:230206070804, Callback:NNabla SSH callback module.)

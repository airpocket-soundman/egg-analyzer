2024-01-28 22:28:07,274 Training process is started.
python "C:\Users\yamas\Desktop\tools\neural_network_console\libs\Python\Lib\site-packages\nnabla\utils\cli\cli.py" train
	-c "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_222807\net.nntxt"
	-o "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_222807"
2024-01-28 22:28:07,824 [nnabla]: [CALLBACK]: Exec train on local
2024-01-28 22:28:07,830 [nnabla]: Using context "Context(backend=['cpu:float'], array_class='CpuCachedArray', device_id='')"
2024-01-28 22:28:07,830 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_test_3class_onsen.csv"
2024-01-28 22:28:08,418 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_valid_3class_onsen.csv"
2024-01-28 22:28:08,804 [nnabla]: Train with contexts ['cpu']
2024-01-28 22:28:08,826 [nnabla]: Training epoch 1 of 100 begin
2024-01-28 22:28:08,826 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 22:28:08,826 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 22:28:09,026 [nnabla]: epoch 1 of 100 cost=4.328513  {train_error=3.991896, valid_error=3.968373} time=(0.1s /9.3s) 
2024-01-28 22:28:09,109 [nnabla]: epoch 2 of 100 cost=3.855404  {train_error=3.541375, valid_error=3.513649} time=(0.2s /12.1s) 
2024-01-28 22:28:09,199 [nnabla]: epoch 3 of 100 cost=3.510228  {train_error=3.217413, valid_error=3.200110} time=(0.3s /10.8s) 
2024-01-28 22:28:09,283 [nnabla]: epoch 4 of 100 cost=3.277100  {train_error=3.211491, valid_error=3.197724} time=(0.4s /10.4s) 
2024-01-28 22:28:09,376 [nnabla]: epoch 5 of 100 cost=3.092979  {train_error=2.989293, valid_error=2.984658} time=(0.5s /10.0s) 
2024-01-28 22:28:09,420 [nnabla]: epoch 6 of 100 cost=2.952417  time=(0.6s /9.9s) 
2024-01-28 22:28:09,461 [nnabla]: epoch 7 of 100 cost=2.837940  time=(0.6s /9.1s) 
2024-01-28 22:28:09,503 [nnabla]: epoch 8 of 100 cost=2.726836  time=(0.7s /8.4s) 
2024-01-28 22:28:09,545 [nnabla]: epoch 9 of 100 cost=2.623990  time=(0.7s /8.0s) 
2024-01-28 22:28:09,638 [nnabla]: epoch 10 of 100 cost=2.522948  {train_error=2.430234, valid_error=2.436543} time=(0.8s /7.6s) 
2024-01-28 22:28:09,679 [nnabla]: epoch 11 of 100 cost=2.421538  time=(0.9s /7.8s) 
2024-01-28 22:28:09,729 [nnabla]: epoch 12 of 100 cost=2.336150  time=(0.9s /7.4s) 
2024-01-28 22:28:09,772 [nnabla]: epoch 13 of 100 cost=2.250796  time=(0.9s /7.3s) 
2024-01-28 22:28:09,813 [nnabla]: epoch 14 of 100 cost=2.164857  time=(1.0s /7.0s) 
2024-01-28 22:28:09,855 [nnabla]: epoch 15 of 100 cost=2.075874  time=(1.0s /6.9s) 
2024-01-28 22:28:09,896 [nnabla]: epoch 16 of 100 cost=1.994095  time=(1.1s /6.7s) 
2024-01-28 22:28:09,937 [nnabla]: epoch 17 of 100 cost=1.919281  time=(1.1s /6.5s) 
2024-01-28 22:28:09,980 [nnabla]: epoch 18 of 100 cost=1.845757  time=(1.2s /6.4s) 
2024-01-28 22:28:10,020 [nnabla]: epoch 19 of 100 cost=1.765112  time=(1.2s /6.3s) 
2024-01-28 22:28:10,115 [nnabla]: epoch 20 of 100 cost=1.707653  {train_error=1.580245, valid_error=1.590610} time=(1.2s /6.2s) 
2024-01-28 22:28:10,157 [nnabla]: epoch 21 of 100 cost=1.622319  time=(1.3s /6.3s) 
2024-01-28 22:28:10,199 [nnabla]: epoch 22 of 100 cost=1.574466  time=(1.4s /6.2s) 
2024-01-28 22:28:10,247 [nnabla]: epoch 23 of 100 cost=1.495934  time=(1.4s /6.1s) 
2024-01-28 22:28:10,290 [nnabla]: epoch 24 of 100 cost=1.433901  time=(1.5s /6.1s) 
2024-01-28 22:28:10,332 [nnabla]: epoch 25 of 100 cost=1.379079  time=(1.5s /6.0s) 
2024-01-28 22:28:10,374 [nnabla]: epoch 26 of 100 cost=1.310905  time=(1.5s /5.9s) 
2024-01-28 22:28:10,414 [nnabla]: epoch 27 of 100 cost=1.268257  time=(1.6s /5.9s) 
2024-01-28 22:28:10,457 [nnabla]: epoch 28 of 100 cost=1.212066  time=(1.6s /5.8s) 
2024-01-28 22:28:10,498 [nnabla]: epoch 29 of 100 cost=1.162334  time=(1.7s /5.8s) 
2024-01-28 22:28:10,589 [nnabla]: epoch 30 of 100 cost=1.109446  {train_error=1.034952, valid_error=1.044131} time=(1.7s /5.7s) 
2024-01-28 22:28:10,630 [nnabla]: epoch 31 of 100 cost=1.067106  time=(1.8s /5.8s) 
2024-01-28 22:28:10,671 [nnabla]: epoch 32 of 100 cost=1.014534  time=(1.8s /5.8s) 
2024-01-28 22:28:10,712 [nnabla]: epoch 33 of 100 cost=0.967128  time=(1.9s /5.7s) 
2024-01-28 22:28:10,762 [nnabla]: epoch 34 of 100 cost=0.924812  time=(1.9s /5.7s) 
2024-01-28 22:28:10,806 [nnabla]: epoch 35 of 100 cost=0.886743  time=(2.0s /5.7s) 
2024-01-28 22:28:10,850 [nnabla]: epoch 36 of 100 cost=0.848409  time=(2.0s /5.6s) 
2024-01-28 22:28:10,897 [nnabla]: epoch 37 of 100 cost=0.826469  time=(2.1s /5.6s) 
2024-01-28 22:28:10,939 [nnabla]: epoch 38 of 100 cost=0.790621  time=(2.1s /5.6s) 
2024-01-28 22:28:10,979 [nnabla]: epoch 39 of 100 cost=0.737205  time=(2.2s /5.5s) 
2024-01-28 22:28:11,070 [nnabla]: epoch 40 of 100 cost=0.715887  {train_error=0.616644, valid_error=0.622333} time=(2.2s /5.5s) 
2024-01-28 22:28:11,112 [nnabla]: epoch 41 of 100 cost=0.678174  time=(2.3s /5.6s) 
2024-01-28 22:28:11,153 [nnabla]: epoch 42 of 100 cost=0.655787  time=(2.3s /5.5s) 
2024-01-28 22:28:11,195 [nnabla]: epoch 43 of 100 cost=0.628386  time=(2.4s /5.5s) 
2024-01-28 22:28:11,235 [nnabla]: epoch 44 of 100 cost=0.595687  time=(2.4s /5.5s) 
2024-01-28 22:28:11,292 [nnabla]: epoch 45 of 100 cost=0.569604  time=(2.5s /5.4s) 
2024-01-28 22:28:11,335 [nnabla]: epoch 46 of 100 cost=0.554846  time=(2.5s /5.5s) 
2024-01-28 22:28:11,378 [nnabla]: epoch 47 of 100 cost=0.526477  time=(2.6s /5.4s) 
2024-01-28 22:28:11,419 [nnabla]: epoch 48 of 100 cost=0.509042  time=(2.6s /5.4s) 
2024-01-28 22:28:11,461 [nnabla]: epoch 49 of 100 cost=0.485279  time=(2.6s /5.4s) 
2024-01-28 22:28:11,559 [nnabla]: epoch 50 of 100 cost=0.461750  {train_error=0.395561, valid_error=0.403735} time=(2.7s /5.4s) 
2024-01-28 22:28:11,601 [nnabla]: epoch 51 of 100 cost=0.453405  time=(2.8s /5.4s) 
2024-01-28 22:28:11,641 [nnabla]: epoch 52 of 100 cost=0.435737  time=(2.8s /5.4s) 
2024-01-28 22:28:11,682 [nnabla]: epoch 53 of 100 cost=0.421291  time=(2.9s /5.4s) 
2024-01-28 22:28:11,723 [nnabla]: epoch 54 of 100 cost=0.401398  time=(2.9s /5.4s) 
2024-01-28 22:28:11,769 [nnabla]: epoch 55 of 100 cost=0.384103  time=(2.9s /5.4s) 
2024-01-28 22:28:11,818 [nnabla]: epoch 56 of 100 cost=0.368582  time=(3.0s /5.3s) 
2024-01-28 22:28:11,860 [nnabla]: epoch 57 of 100 cost=0.368093  time=(3.0s /5.3s) 
2024-01-28 22:28:11,902 [nnabla]: epoch 58 of 100 cost=0.340470  time=(3.1s /5.3s) 
2024-01-28 22:28:11,942 [nnabla]: epoch 59 of 100 cost=0.331907  time=(3.1s /5.3s) 
2024-01-28 22:28:12,036 [nnabla]: epoch 60 of 100 cost=0.321288  {train_error=0.246551, valid_error=0.248446} time=(3.2s /5.3s) 
2024-01-28 22:28:12,079 [nnabla]: epoch 61 of 100 cost=0.312587  time=(3.3s /5.3s) 
2024-01-28 22:28:12,120 [nnabla]: epoch 62 of 100 cost=0.308940  time=(3.3s /5.3s) 
2024-01-28 22:28:12,161 [nnabla]: epoch 63 of 100 cost=0.288449  time=(3.3s /5.3s) 
2024-01-28 22:28:12,203 [nnabla]: epoch 64 of 100 cost=0.287354  time=(3.4s /5.3s) 
2024-01-28 22:28:12,244 [nnabla]: epoch 65 of 100 cost=0.268629  time=(3.4s /5.3s) 
2024-01-28 22:28:12,287 [nnabla]: epoch 66 of 100 cost=0.269442  time=(3.5s /5.2s) 
2024-01-28 22:28:12,336 [nnabla]: epoch 67 of 100 cost=0.253443  time=(3.5s /5.2s) 
2024-01-28 22:28:12,377 [nnabla]: epoch 68 of 100 cost=0.240446  time=(3.6s /5.2s) 
2024-01-28 22:28:12,419 [nnabla]: epoch 69 of 100 cost=0.237706  time=(3.6s /5.2s) 
2024-01-28 22:28:12,513 [nnabla]: epoch 70 of 100 cost=0.239697  {train_error=0.179512, valid_error=0.183944} time=(3.6s /5.2s) 
2024-01-28 22:28:12,554 [nnabla]: epoch 71 of 100 cost=0.225242  time=(3.7s /5.3s) 
2024-01-28 22:28:12,596 [nnabla]: epoch 72 of 100 cost=0.221472  time=(3.8s /5.2s) 
2024-01-28 22:28:12,639 [nnabla]: epoch 73 of 100 cost=0.217257  time=(3.8s /5.2s) 
2024-01-28 22:28:12,680 [nnabla]: epoch 74 of 100 cost=0.209053  time=(3.9s /5.2s) 
2024-01-28 22:28:12,720 [nnabla]: epoch 75 of 100 cost=0.194772  time=(3.9s /5.2s) 
2024-01-28 22:28:12,762 [nnabla]: epoch 76 of 100 cost=0.193631  time=(3.9s /5.2s) 
2024-01-28 22:28:12,803 [nnabla]: epoch 77 of 100 cost=0.185248  time=(4.0s /5.2s) 
2024-01-28 22:28:12,852 [nnabla]: epoch 78 of 100 cost=0.188750  time=(4.0s /5.2s) 
2024-01-28 22:28:12,894 [nnabla]: epoch 79 of 100 cost=0.177342  time=(4.1s /5.1s) 
2024-01-28 22:28:12,984 [nnabla]: epoch 80 of 100 cost=0.175189  {train_error=0.129726, valid_error=0.134118} time=(4.1s /5.1s) 
2024-01-28 22:28:13,026 [nnabla]: epoch 81 of 100 cost=0.171527  time=(4.2s /5.2s) 
2024-01-28 22:28:13,066 [nnabla]: epoch 82 of 100 cost=0.168009  time=(4.2s /5.2s) 
2024-01-28 22:28:13,110 [nnabla]: epoch 83 of 100 cost=0.159683  time=(4.3s /5.2s) 
2024-01-28 22:28:13,151 [nnabla]: epoch 84 of 100 cost=0.155389  time=(4.3s /5.1s) 
2024-01-28 22:28:13,192 [nnabla]: epoch 85 of 100 cost=0.148392  time=(4.4s /5.1s) 
2024-01-28 22:28:13,233 [nnabla]: epoch 86 of 100 cost=0.148897  time=(4.4s /5.1s) 
2024-01-28 22:28:13,276 [nnabla]: epoch 87 of 100 cost=0.145109  time=(4.4s /5.1s) 
2024-01-28 22:28:13,316 [nnabla]: epoch 88 of 100 cost=0.148686  time=(4.5s /5.1s) 
2024-01-28 22:28:13,365 [nnabla]: epoch 89 of 100 cost=0.140196  time=(4.5s /5.1s) 
2024-01-28 22:28:13,456 [nnabla]: epoch 90 of 100 cost=0.135397  {train_error=0.099305, valid_error=0.103093} time=(4.6s /5.1s) 
2024-01-28 22:28:13,507 [nnabla]: epoch 91 of 100 cost=0.135218  time=(4.7s /5.1s) 
2024-01-28 22:28:13,549 [nnabla]: epoch 92 of 100 cost=0.124915  time=(4.7s /5.1s) 
2024-01-28 22:28:13,589 [nnabla]: epoch 93 of 100 cost=0.132816  time=(4.8s /5.1s) 
2024-01-28 22:28:13,631 [nnabla]: epoch 94 of 100 cost=0.115799  time=(4.8s /5.1s) 
2024-01-28 22:28:13,674 [nnabla]: epoch 95 of 100 cost=0.125626  time=(4.8s /5.1s) 
2024-01-28 22:28:13,715 [nnabla]: epoch 96 of 100 cost=0.113437  time=(4.9s /5.1s) 
2024-01-28 22:28:13,757 [nnabla]: epoch 97 of 100 cost=0.112024  time=(4.9s /5.1s) 
2024-01-28 22:28:13,798 [nnabla]: epoch 98 of 100 cost=0.106486  time=(5.0s /5.1s) 
2024-01-28 22:28:13,839 [nnabla]: epoch 99 of 100 cost=0.111809  time=(5.0s /5.1s) 
2024-01-28 22:28:13,949 [nnabla]: epoch 100 of 100 cost=0.102971  {train_error=0.073825, valid_error=0.076656} time=(5.1s /5.1s) 
2024-01-28 22:28:13,965 [nnabla]: Training Completed.
NNabla command line interface (Version:1.33.1, Build:230206070804, Callback:NNabla SSH callback module.)

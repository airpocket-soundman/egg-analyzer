2024-01-28 21:18:37,155 Training process is started.
python "C:\Users\yamas\Desktop\tools\neural_network_console\libs\Python\Lib\site-packages\nnabla\utils\cli\cli.py" train
	-c "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_211837\net.nntxt"
	-o "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_211837"
2024-01-28 21:18:37,697 [nnabla]: [CALLBACK]: Exec train on local
2024-01-28 21:18:37,703 [nnabla]: Using context "Context(backend=['cpu:float'], array_class='CpuCachedArray', device_id='')"
2024-01-28 21:18:37,703 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_test_3class_onsen.csv"
2024-01-28 21:18:38,303 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_valid_3class_onsen.csv"
2024-01-28 21:18:38,686 [nnabla]: Train with contexts ['cpu']
2024-01-28 21:18:38,707 [nnabla]: Training epoch 1 of 100 begin
2024-01-28 21:18:38,707 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 21:18:38,707 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 21:18:38,915 [nnabla]: epoch 1 of 100 cost=4.459195  {train_error=4.411881, valid_error=4.406289} time=(0.1s /9.6s) 
2024-01-28 21:18:38,999 [nnabla]: epoch 2 of 100 cost=4.069261  {train_error=3.934773, valid_error=3.910577} time=(0.2s /12.4s) 
2024-01-28 21:18:39,087 [nnabla]: epoch 3 of 100 cost=3.779593  {train_error=3.604399, valid_error=3.579430} time=(0.3s /11.1s) 
2024-01-28 21:18:39,175 [nnabla]: epoch 4 of 100 cost=3.560016  {train_error=3.442973, valid_error=3.420161} time=(0.4s /10.6s) 
2024-01-28 21:18:39,271 [nnabla]: epoch 5 of 100 cost=3.356695  {train_error=3.203268, valid_error=3.188245} time=(0.5s /10.2s) 
2024-01-28 21:18:39,315 [nnabla]: epoch 6 of 100 cost=3.183501  time=(0.6s /10.1s) 
2024-01-28 21:18:39,355 [nnabla]: epoch 7 of 100 cost=3.012597  time=(0.6s /9.2s) 
2024-01-28 21:18:39,396 [nnabla]: epoch 8 of 100 cost=2.866698  time=(0.7s /8.6s) 
2024-01-28 21:18:39,437 [nnabla]: epoch 9 of 100 cost=2.741878  time=(0.7s /8.1s) 
2024-01-28 21:18:39,530 [nnabla]: epoch 10 of 100 cost=2.625700  {train_error=2.530949, valid_error=2.528417} time=(0.8s /7.7s) 
2024-01-28 21:18:39,572 [nnabla]: epoch 11 of 100 cost=2.514785  time=(0.9s /7.9s) 
2024-01-28 21:18:39,621 [nnabla]: epoch 12 of 100 cost=2.399648  time=(0.9s /7.6s) 
2024-01-28 21:18:39,664 [nnabla]: epoch 13 of 100 cost=2.313741  time=(1.0s /7.4s) 
2024-01-28 21:18:39,707 [nnabla]: epoch 14 of 100 cost=2.224368  time=(1.0s /7.1s) 
2024-01-28 21:18:39,748 [nnabla]: epoch 15 of 100 cost=2.138602  time=(1.0s /6.9s) 
2024-01-28 21:18:39,790 [nnabla]: epoch 16 of 100 cost=2.057997  time=(1.1s /6.8s) 
2024-01-28 21:18:39,831 [nnabla]: epoch 17 of 100 cost=1.978675  time=(1.1s /6.6s) 
2024-01-28 21:18:39,873 [nnabla]: epoch 18 of 100 cost=1.907234  time=(1.2s /6.5s) 
2024-01-28 21:18:39,915 [nnabla]: epoch 19 of 100 cost=1.813549  time=(1.2s /6.4s) 
2024-01-28 21:18:40,009 [nnabla]: epoch 20 of 100 cost=1.749862  {train_error=1.599908, valid_error=1.610940} time=(1.2s /6.2s) 
2024-01-28 21:18:40,050 [nnabla]: epoch 21 of 100 cost=1.672945  time=(1.3s /6.4s) 
2024-01-28 21:18:40,092 [nnabla]: epoch 22 of 100 cost=1.615479  time=(1.4s /6.3s) 
2024-01-28 21:18:40,141 [nnabla]: epoch 23 of 100 cost=1.547752  time=(1.4s /6.2s) 
2024-01-28 21:18:40,183 [nnabla]: epoch 24 of 100 cost=1.482988  time=(1.5s /6.2s) 
2024-01-28 21:18:40,225 [nnabla]: epoch 25 of 100 cost=1.434877  time=(1.5s /6.1s) 
2024-01-28 21:18:40,268 [nnabla]: epoch 26 of 100 cost=1.349647  time=(1.6s /6.0s) 
2024-01-28 21:18:40,310 [nnabla]: epoch 27 of 100 cost=1.312389  time=(1.6s /5.9s) 
2024-01-28 21:18:40,351 [nnabla]: epoch 28 of 100 cost=1.266343  time=(1.6s /5.9s) 
2024-01-28 21:18:40,395 [nnabla]: epoch 29 of 100 cost=1.208219  time=(1.7s /5.8s) 
2024-01-28 21:18:40,489 [nnabla]: epoch 30 of 100 cost=1.169502  {train_error=1.030931, valid_error=1.039657} time=(1.7s /5.8s) 
2024-01-28 21:18:40,532 [nnabla]: epoch 31 of 100 cost=1.119156  time=(1.8s /5.9s) 
2024-01-28 21:18:40,574 [nnabla]: epoch 32 of 100 cost=1.068525  time=(1.9s /5.8s) 
2024-01-28 21:18:40,616 [nnabla]: epoch 33 of 100 cost=1.016074  time=(1.9s /5.8s) 
2024-01-28 21:18:40,664 [nnabla]: epoch 34 of 100 cost=0.983828  time=(1.9s /5.7s) 
2024-01-28 21:18:40,706 [nnabla]: epoch 35 of 100 cost=0.945667  time=(2.0s /5.7s) 
2024-01-28 21:18:40,749 [nnabla]: epoch 36 of 100 cost=0.903208  time=(2.0s /5.7s) 
2024-01-28 21:18:40,791 [nnabla]: epoch 37 of 100 cost=0.891799  time=(2.1s /5.6s) 
2024-01-28 21:18:40,833 [nnabla]: epoch 38 of 100 cost=0.850193  time=(2.1s /5.6s) 
2024-01-28 21:18:40,875 [nnabla]: epoch 39 of 100 cost=0.804228  time=(2.2s /5.6s) 
2024-01-28 21:18:40,969 [nnabla]: epoch 40 of 100 cost=0.776008  {train_error=0.690499, valid_error=0.695062} time=(2.2s /5.5s) 
2024-01-28 21:18:41,011 [nnabla]: epoch 41 of 100 cost=0.747073  time=(2.3s /5.6s) 
2024-01-28 21:18:41,052 [nnabla]: epoch 42 of 100 cost=0.723701  time=(2.3s /5.6s) 
2024-01-28 21:18:41,094 [nnabla]: epoch 43 of 100 cost=0.693262  time=(2.4s /5.6s) 
2024-01-28 21:18:41,138 [nnabla]: epoch 44 of 100 cost=0.657945  time=(2.4s /5.5s) 
2024-01-28 21:18:41,202 [nnabla]: epoch 45 of 100 cost=0.645878  time=(2.5s /5.5s) 
2024-01-28 21:18:41,244 [nnabla]: epoch 46 of 100 cost=0.617025  time=(2.5s /5.5s) 
2024-01-28 21:18:41,284 [nnabla]: epoch 47 of 100 cost=0.596083  time=(2.6s /5.5s) 
2024-01-28 21:18:41,325 [nnabla]: epoch 48 of 100 cost=0.574714  time=(2.6s /5.5s) 
2024-01-28 21:18:41,367 [nnabla]: epoch 49 of 100 cost=0.554535  time=(2.7s /5.4s) 
2024-01-28 21:18:41,466 [nnabla]: epoch 50 of 100 cost=0.536067  {train_error=0.463286, valid_error=0.469339} time=(2.7s /5.4s) 
2024-01-28 21:18:41,509 [nnabla]: epoch 51 of 100 cost=0.527462  time=(2.8s /5.5s) 
2024-01-28 21:18:41,550 [nnabla]: epoch 52 of 100 cost=0.499227  time=(2.8s /5.5s) 
2024-01-28 21:18:41,592 [nnabla]: epoch 53 of 100 cost=0.485104  time=(2.9s /5.4s) 
2024-01-28 21:18:41,634 [nnabla]: epoch 54 of 100 cost=0.476653  time=(2.9s /5.4s) 
2024-01-28 21:18:41,677 [nnabla]: epoch 55 of 100 cost=0.449374  time=(3.0s /5.4s) 
2024-01-28 21:18:41,732 [nnabla]: epoch 56 of 100 cost=0.432428  time=(3.0s /5.4s) 
2024-01-28 21:18:41,779 [nnabla]: epoch 57 of 100 cost=0.428554  time=(3.1s /5.4s) 
2024-01-28 21:18:41,820 [nnabla]: epoch 58 of 100 cost=0.405567  time=(3.1s /5.4s) 
2024-01-28 21:18:41,861 [nnabla]: epoch 59 of 100 cost=0.387451  time=(3.2s /5.3s) 
2024-01-28 21:18:41,955 [nnabla]: epoch 60 of 100 cost=0.374049  {train_error=0.307058, valid_error=0.307862} time=(3.2s /5.3s) 
2024-01-28 21:18:41,999 [nnabla]: epoch 61 of 100 cost=0.366252  time=(3.3s /5.4s) 
2024-01-28 21:18:42,041 [nnabla]: epoch 62 of 100 cost=0.370810  time=(3.3s /5.4s) 
2024-01-28 21:18:42,084 [nnabla]: epoch 63 of 100 cost=0.347753  time=(3.4s /5.4s) 
2024-01-28 21:18:42,124 [nnabla]: epoch 64 of 100 cost=0.341331  time=(3.4s /5.3s) 
2024-01-28 21:18:42,166 [nnabla]: epoch 65 of 100 cost=0.325451  time=(3.5s /5.3s) 
2024-01-28 21:18:42,208 [nnabla]: epoch 66 of 100 cost=0.315058  time=(3.5s /5.3s) 
2024-01-28 21:18:42,260 [nnabla]: epoch 67 of 100 cost=0.308145  time=(3.5s /5.3s) 
2024-01-28 21:18:42,302 [nnabla]: epoch 68 of 100 cost=0.290737  time=(3.6s /5.3s) 
2024-01-28 21:18:42,344 [nnabla]: epoch 69 of 100 cost=0.290984  time=(3.6s /5.3s) 
2024-01-28 21:18:42,439 [nnabla]: epoch 70 of 100 cost=0.285624  {train_error=0.202557, valid_error=0.204427} time=(3.7s /5.3s) 
2024-01-28 21:18:42,481 [nnabla]: epoch 71 of 100 cost=0.270861  time=(3.8s /5.3s) 
2024-01-28 21:18:42,524 [nnabla]: epoch 72 of 100 cost=0.271923  time=(3.8s /5.3s) 
2024-01-28 21:18:42,565 [nnabla]: epoch 73 of 100 cost=0.260597  time=(3.9s /5.3s) 
2024-01-28 21:18:42,608 [nnabla]: epoch 74 of 100 cost=0.247285  time=(3.9s /5.3s) 
2024-01-28 21:18:42,650 [nnabla]: epoch 75 of 100 cost=0.239637  time=(3.9s /5.3s) 
2024-01-28 21:18:42,692 [nnabla]: epoch 76 of 100 cost=0.240807  time=(4.0s /5.2s) 
2024-01-28 21:18:42,734 [nnabla]: epoch 77 of 100 cost=0.221481  time=(4.0s /5.2s) 
2024-01-28 21:18:42,786 [nnabla]: epoch 78 of 100 cost=0.226337  time=(4.1s /5.2s) 
2024-01-28 21:18:42,827 [nnabla]: epoch 79 of 100 cost=0.215356  time=(4.1s /5.2s) 
2024-01-28 21:18:42,921 [nnabla]: epoch 80 of 100 cost=0.208010  {train_error=0.141826, valid_error=0.145491} time=(4.2s /5.2s) 
2024-01-28 21:18:42,962 [nnabla]: epoch 81 of 100 cost=0.217875  time=(4.3s /5.3s) 
2024-01-28 21:18:43,002 [nnabla]: epoch 82 of 100 cost=0.201996  time=(4.3s /5.2s) 
2024-01-28 21:18:43,044 [nnabla]: epoch 83 of 100 cost=0.196145  time=(4.3s /5.2s) 
2024-01-28 21:18:43,086 [nnabla]: epoch 84 of 100 cost=0.194514  time=(4.4s /5.2s) 
2024-01-28 21:18:43,129 [nnabla]: epoch 85 of 100 cost=0.179711  time=(4.4s /5.2s) 
2024-01-28 21:18:43,170 [nnabla]: epoch 86 of 100 cost=0.185095  time=(4.5s /5.2s) 
2024-01-28 21:18:43,212 [nnabla]: epoch 87 of 100 cost=0.179402  time=(4.5s /5.2s) 
2024-01-28 21:18:43,253 [nnabla]: epoch 88 of 100 cost=0.182300  time=(4.5s /5.2s) 
2024-01-28 21:18:43,303 [nnabla]: epoch 89 of 100 cost=0.167924  time=(4.6s /5.2s) 
2024-01-28 21:18:43,399 [nnabla]: epoch 90 of 100 cost=0.165232  {train_error=0.113756, valid_error=0.116774} time=(4.6s /5.2s) 
2024-01-28 21:18:43,442 [nnabla]: epoch 91 of 100 cost=0.169179  time=(4.7s /5.2s) 
2024-01-28 21:18:43,484 [nnabla]: epoch 92 of 100 cost=0.152998  time=(4.8s /5.2s) 
2024-01-28 21:18:43,525 [nnabla]: epoch 93 of 100 cost=0.165971  time=(4.8s /5.2s) 
2024-01-28 21:18:43,568 [nnabla]: epoch 94 of 100 cost=0.148429  time=(4.9s /5.2s) 
2024-01-28 21:18:43,610 [nnabla]: epoch 95 of 100 cost=0.156936  time=(4.9s /5.2s) 
2024-01-28 21:18:43,650 [nnabla]: epoch 96 of 100 cost=0.139627  time=(4.9s /5.1s) 
2024-01-28 21:18:43,693 [nnabla]: epoch 97 of 100 cost=0.141634  time=(5.0s /5.1s) 
2024-01-28 21:18:43,734 [nnabla]: epoch 98 of 100 cost=0.130807  time=(5.0s /5.1s) 
2024-01-28 21:18:43,775 [nnabla]: epoch 99 of 100 cost=0.138537  time=(5.1s /5.1s) 
2024-01-28 21:18:43,885 [nnabla]: epoch 100 of 100 cost=0.130342  {train_error=0.082578, valid_error=0.085120} time=(5.1s /5.1s) 
2024-01-28 21:18:43,900 [nnabla]: Training Completed.
NNabla command line interface (Version:1.33.1, Build:230206070804, Callback:NNabla SSH callback module.)

2024-01-28 22:32:04,125 Training process is started.
python "C:\Users\yamas\Desktop\tools\neural_network_console\libs\Python\Lib\site-packages\nnabla\utils\cli\cli.py" train
	-c "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_223204\net.nntxt"
	-o "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_223204"
2024-01-28 22:32:04,656 [nnabla]: [CALLBACK]: Exec train on local
2024-01-28 22:32:04,662 [nnabla]: Using context "Context(backend=['cpu:float'], array_class='CpuCachedArray', device_id='')"
2024-01-28 22:32:04,663 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_test_3class_onsen.csv"
2024-01-28 22:32:05,249 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_valid_3class_onsen.csv"
2024-01-28 22:32:05,633 [nnabla]: Train with contexts ['cpu']
2024-01-28 22:32:05,655 [nnabla]: Training epoch 1 of 100 begin
2024-01-28 22:32:05,656 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 22:32:05,656 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 22:32:05,863 [nnabla]: epoch 1 of 100 cost=4.665300  {train_error=4.938815, valid_error=4.936391} time=(0.1s /9.5s) 
2024-01-28 22:32:05,950 [nnabla]: epoch 2 of 100 cost=4.418523  {train_error=4.260545, valid_error=4.249880} time=(0.2s /12.4s) 
2024-01-28 22:32:06,039 [nnabla]: epoch 3 of 100 cost=4.154989  {train_error=3.958835, valid_error=3.945047} time=(0.3s /11.2s) 
2024-01-28 22:32:06,127 [nnabla]: epoch 4 of 100 cost=3.850854  {train_error=3.717890, valid_error=3.703360} time=(0.4s /10.6s) 
2024-01-28 22:32:06,222 [nnabla]: epoch 5 of 100 cost=3.607632  {train_error=3.630447, valid_error=3.609891} time=(0.5s /10.2s) 
2024-01-28 22:32:06,265 [nnabla]: epoch 6 of 100 cost=3.472932  time=(0.6s /10.1s) 
2024-01-28 22:32:06,306 [nnabla]: epoch 7 of 100 cost=3.353155  time=(0.6s /9.3s) 
2024-01-28 22:32:06,348 [nnabla]: epoch 8 of 100 cost=3.259598  time=(0.7s /8.6s) 
2024-01-28 22:32:06,394 [nnabla]: epoch 9 of 100 cost=3.172082  time=(0.7s /8.2s) 
2024-01-28 22:32:06,490 [nnabla]: epoch 10 of 100 cost=3.080686  {train_error=3.158160, valid_error=3.139990} time=(0.8s /7.8s) 
2024-01-28 22:32:06,531 [nnabla]: epoch 11 of 100 cost=3.008384  time=(0.9s /8.0s) 
2024-01-28 22:32:06,581 [nnabla]: epoch 12 of 100 cost=2.913734  time=(0.9s /7.7s) 
2024-01-28 22:32:06,624 [nnabla]: epoch 13 of 100 cost=2.853842  time=(1.0s /7.4s) 
2024-01-28 22:32:06,666 [nnabla]: epoch 14 of 100 cost=2.768851  time=(1.0s /7.2s) 
2024-01-28 22:32:06,709 [nnabla]: epoch 15 of 100 cost=2.688994  time=(1.1s /7.0s) 
2024-01-28 22:32:06,754 [nnabla]: epoch 16 of 100 cost=2.620748  time=(1.1s /6.9s) 
2024-01-28 22:32:06,795 [nnabla]: epoch 17 of 100 cost=2.537757  time=(1.1s /6.7s) 
2024-01-28 22:32:06,837 [nnabla]: epoch 18 of 100 cost=2.471993  time=(1.2s /6.6s) 
2024-01-28 22:32:06,882 [nnabla]: epoch 19 of 100 cost=2.399744  time=(1.2s /6.4s) 
2024-01-28 22:32:06,976 [nnabla]: epoch 20 of 100 cost=2.342021  {train_error=2.386368, valid_error=2.380909} time=(1.3s /6.3s) 
2024-01-28 22:32:07,019 [nnabla]: epoch 21 of 100 cost=2.271266  time=(1.4s /6.5s) 
2024-01-28 22:32:07,061 [nnabla]: epoch 22 of 100 cost=2.207031  time=(1.4s /6.4s) 
2024-01-28 22:32:07,111 [nnabla]: epoch 23 of 100 cost=2.143549  time=(1.4s /6.3s) 
2024-01-28 22:32:07,153 [nnabla]: epoch 24 of 100 cost=2.080431  time=(1.5s /6.2s) 
2024-01-28 22:32:07,195 [nnabla]: epoch 25 of 100 cost=2.031146  time=(1.5s /6.2s) 
2024-01-28 22:32:07,240 [nnabla]: epoch 26 of 100 cost=1.960878  time=(1.6s /6.1s) 
2024-01-28 22:32:07,281 [nnabla]: epoch 27 of 100 cost=1.921901  time=(1.6s /6.0s) 
2024-01-28 22:32:07,323 [nnabla]: epoch 28 of 100 cost=1.863928  time=(1.7s /5.9s) 
2024-01-28 22:32:07,364 [nnabla]: epoch 29 of 100 cost=1.791374  time=(1.7s /5.9s) 
2024-01-28 22:32:07,465 [nnabla]: epoch 30 of 100 cost=1.774900  {train_error=1.778092, valid_error=1.777052} time=(1.7s /5.8s) 
2024-01-28 22:32:07,509 [nnabla]: epoch 31 of 100 cost=1.705993  time=(1.9s /6.0s) 
2024-01-28 22:32:07,549 [nnabla]: epoch 32 of 100 cost=1.678406  time=(1.9s /5.9s) 
2024-01-28 22:32:07,591 [nnabla]: epoch 33 of 100 cost=1.608979  time=(1.9s /5.9s) 
2024-01-28 22:32:07,641 [nnabla]: epoch 34 of 100 cost=1.574795  time=(2.0s /5.8s) 
2024-01-28 22:32:07,683 [nnabla]: epoch 35 of 100 cost=1.529304  time=(2.0s /5.8s) 
2024-01-28 22:32:07,725 [nnabla]: epoch 36 of 100 cost=1.497976  time=(2.1s /5.7s) 
2024-01-28 22:32:07,770 [nnabla]: epoch 37 of 100 cost=1.460923  time=(2.1s /5.7s) 
2024-01-28 22:32:07,813 [nnabla]: epoch 38 of 100 cost=1.440828  time=(2.2s /5.7s) 
2024-01-28 22:32:07,854 [nnabla]: epoch 39 of 100 cost=1.390754  time=(2.2s /5.6s) 
2024-01-28 22:32:07,957 [nnabla]: epoch 40 of 100 cost=1.335704  {train_error=1.303855, valid_error=1.313575} time=(2.2s /5.6s) 
2024-01-28 22:32:08,000 [nnabla]: epoch 41 of 100 cost=1.324484  time=(2.3s /5.7s) 
2024-01-28 22:32:08,044 [nnabla]: epoch 42 of 100 cost=1.274422  time=(2.4s /5.7s) 
2024-01-28 22:32:08,084 [nnabla]: epoch 43 of 100 cost=1.249129  time=(2.4s /5.6s) 
2024-01-28 22:32:08,125 [nnabla]: epoch 44 of 100 cost=1.210660  time=(2.5s /5.6s) 
2024-01-28 22:32:08,181 [nnabla]: epoch 45 of 100 cost=1.195351  time=(2.5s /5.6s) 
2024-01-28 22:32:08,225 [nnabla]: epoch 46 of 100 cost=1.167046  time=(2.6s /5.6s) 
2024-01-28 22:32:08,267 [nnabla]: epoch 47 of 100 cost=1.144177  time=(2.6s /5.6s) 
2024-01-28 22:32:08,309 [nnabla]: epoch 48 of 100 cost=1.114899  time=(2.7s /5.5s) 
2024-01-28 22:32:08,351 [nnabla]: epoch 49 of 100 cost=1.089293  time=(2.7s /5.5s) 
2024-01-28 22:32:08,445 [nnabla]: epoch 50 of 100 cost=1.068960  {train_error=1.030965, valid_error=1.048273} time=(2.7s /5.5s) 
2024-01-28 22:32:08,486 [nnabla]: epoch 51 of 100 cost=1.061722  time=(2.8s /5.5s) 
2024-01-28 22:32:08,528 [nnabla]: epoch 52 of 100 cost=1.035373  time=(2.9s /5.5s) 
2024-01-28 22:32:08,569 [nnabla]: epoch 53 of 100 cost=1.001904  time=(2.9s /5.5s) 
2024-01-28 22:32:08,610 [nnabla]: epoch 54 of 100 cost=0.979692  time=(3.0s /5.5s) 
2024-01-28 22:32:08,651 [nnabla]: epoch 55 of 100 cost=0.972983  time=(3.0s /5.4s) 
2024-01-28 22:32:08,700 [nnabla]: epoch 56 of 100 cost=0.953118  time=(3.0s /5.4s) 
2024-01-28 22:32:08,741 [nnabla]: epoch 57 of 100 cost=0.951199  time=(3.1s /5.4s) 
2024-01-28 22:32:08,783 [nnabla]: epoch 58 of 100 cost=0.905297  time=(3.1s /5.4s) 
2024-01-28 22:32:08,825 [nnabla]: epoch 59 of 100 cost=0.918569  time=(3.2s /5.4s) 
2024-01-28 22:32:08,919 [nnabla]: epoch 60 of 100 cost=0.884694  {train_error=0.851063, valid_error=0.857037} time=(3.2s /5.4s) 
2024-01-28 22:32:08,962 [nnabla]: epoch 61 of 100 cost=0.875191  time=(3.3s /5.4s) 
2024-01-28 22:32:09,003 [nnabla]: epoch 62 of 100 cost=0.873144  time=(3.3s /5.4s) 
2024-01-28 22:32:09,045 [nnabla]: epoch 63 of 100 cost=0.854989  time=(3.4s /5.4s) 
2024-01-28 22:32:09,087 [nnabla]: epoch 64 of 100 cost=0.848672  time=(3.4s /5.4s) 
2024-01-28 22:32:09,129 [nnabla]: epoch 65 of 100 cost=0.841792  time=(3.5s /5.3s) 
2024-01-28 22:32:09,170 [nnabla]: epoch 66 of 100 cost=0.816814  time=(3.5s /5.3s) 
2024-01-28 22:32:09,218 [nnabla]: epoch 67 of 100 cost=0.799501  time=(3.6s /5.3s) 
2024-01-28 22:32:09,259 [nnabla]: epoch 68 of 100 cost=0.795265  time=(3.6s /5.3s) 
2024-01-28 22:32:09,300 [nnabla]: epoch 69 of 100 cost=0.788544  time=(3.6s /5.3s) 
2024-01-28 22:32:09,396 [nnabla]: epoch 70 of 100 cost=0.779791  {train_error=0.728826, valid_error=0.744382} time=(3.7s /5.3s) 
2024-01-28 22:32:09,439 [nnabla]: epoch 71 of 100 cost=0.760857  time=(3.8s /5.3s) 
2024-01-28 22:32:09,480 [nnabla]: epoch 72 of 100 cost=0.764739  time=(3.8s /5.3s) 
2024-01-28 22:32:09,521 [nnabla]: epoch 73 of 100 cost=0.743312  time=(3.9s /5.3s) 
2024-01-28 22:32:09,563 [nnabla]: epoch 74 of 100 cost=0.727388  time=(3.9s /5.3s) 
2024-01-28 22:32:09,604 [nnabla]: epoch 75 of 100 cost=0.746707  time=(3.9s /5.3s) 
2024-01-28 22:32:09,644 [nnabla]: epoch 76 of 100 cost=0.710327  time=(4.0s /5.2s) 
2024-01-28 22:32:09,686 [nnabla]: epoch 77 of 100 cost=0.732326  time=(4.0s /5.2s) 
2024-01-28 22:32:09,743 [nnabla]: epoch 78 of 100 cost=0.704727  time=(4.1s /5.2s) 
2024-01-28 22:32:09,785 [nnabla]: epoch 79 of 100 cost=0.698875  time=(4.1s /5.2s) 
2024-01-28 22:32:09,880 [nnabla]: epoch 80 of 100 cost=0.691255  {train_error=0.662839, valid_error=0.678469} time=(4.2s /5.2s) 
2024-01-28 22:32:09,922 [nnabla]: epoch 81 of 100 cost=0.704235  time=(4.3s /5.3s) 
2024-01-28 22:32:09,964 [nnabla]: epoch 82 of 100 cost=0.680663  time=(4.3s /5.3s) 
2024-01-28 22:32:10,006 [nnabla]: epoch 83 of 100 cost=0.673741  time=(4.3s /5.2s) 
2024-01-28 22:32:10,047 [nnabla]: epoch 84 of 100 cost=0.686626  time=(4.4s /5.2s) 
2024-01-28 22:32:10,092 [nnabla]: epoch 85 of 100 cost=0.660343  time=(4.4s /5.2s) 
2024-01-28 22:32:10,133 [nnabla]: epoch 86 of 100 cost=0.660266  time=(4.5s /5.2s) 
2024-01-28 22:32:10,175 [nnabla]: epoch 87 of 100 cost=0.668580  time=(4.5s /5.2s) 
2024-01-28 22:32:10,216 [nnabla]: epoch 88 of 100 cost=0.661027  time=(4.6s /5.2s) 
2024-01-28 22:32:10,266 [nnabla]: epoch 89 of 100 cost=0.646968  time=(4.6s /5.2s) 
2024-01-28 22:32:10,359 [nnabla]: epoch 90 of 100 cost=0.646923  {train_error=0.607090, valid_error=0.623890} time=(4.7s /5.2s) 
2024-01-28 22:32:10,401 [nnabla]: epoch 91 of 100 cost=0.643302  time=(4.7s /5.2s) 
2024-01-28 22:32:10,443 [nnabla]: epoch 92 of 100 cost=0.623252  time=(4.8s /5.2s) 
2024-01-28 22:32:10,484 [nnabla]: epoch 93 of 100 cost=0.647818  time=(4.8s /5.2s) 
2024-01-28 22:32:10,527 [nnabla]: epoch 94 of 100 cost=0.610228  time=(4.9s /5.2s) 
2024-01-28 22:32:10,570 [nnabla]: epoch 95 of 100 cost=0.628256  time=(4.9s /5.2s) 
2024-01-28 22:32:10,611 [nnabla]: epoch 96 of 100 cost=0.624008  time=(5.0s /5.2s) 
2024-01-28 22:32:10,652 [nnabla]: epoch 97 of 100 cost=0.618853  time=(5.0s /5.2s) 
2024-01-28 22:32:10,706 [nnabla]: epoch 98 of 100 cost=0.603387  time=(5.0s /5.2s) 
2024-01-28 22:32:10,752 [nnabla]: epoch 99 of 100 cost=0.609429  time=(5.1s /5.1s) 
2024-01-28 22:32:10,873 [nnabla]: epoch 100 of 100 cost=0.607947  {train_error=0.571531, valid_error=0.592534} time=(5.1s /5.1s) 
2024-01-28 22:32:10,889 [nnabla]: Training Completed.
NNabla command line interface (Version:1.33.1, Build:230206070804, Callback:NNabla SSH callback module.)

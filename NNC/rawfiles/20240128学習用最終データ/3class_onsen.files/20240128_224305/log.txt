2024-01-28 22:43:05,065 Training process is started.
python "C:\Users\yamas\Desktop\tools\neural_network_console\libs\Python\Lib\site-packages\nnabla\utils\cli\cli.py" train
	-c "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_224305\net.nntxt"
	-o "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_224305"
2024-01-28 22:43:05,609 [nnabla]: [CALLBACK]: Exec train on local
2024-01-28 22:43:05,615 [nnabla]: Using context "Context(backend=['cpu:float'], array_class='CpuCachedArray', device_id='')"
2024-01-28 22:43:05,616 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_test_3class_onsen.csv"
2024-01-28 22:43:06,203 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_valid_3class_onsen.csv"
2024-01-28 22:43:06,583 [nnabla]: Train with contexts ['cpu']
2024-01-28 22:43:06,602 [nnabla]: Training epoch 1 of 200 begin
2024-01-28 22:43:06,602 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 22:43:06,602 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 22:43:06,800 [nnabla]: epoch 1 of 200 cost=4.441790  {train_error=4.386507, valid_error=4.384255} time=(0.1s /17.6s) 
2024-01-28 22:43:06,882 [nnabla]: epoch 2 of 200 cost=4.335125  {train_error=4.280133, valid_error=4.277944} time=(0.2s /23.8s) 
2024-01-28 22:43:06,970 [nnabla]: epoch 3 of 200 cost=4.229488  {train_error=4.174615, valid_error=4.172310} time=(0.3s /21.6s) 
2024-01-28 22:43:07,056 [nnabla]: epoch 4 of 200 cost=4.123716  {train_error=4.069787, valid_error=4.067519} time=(0.4s /20.5s) 
2024-01-28 22:43:07,146 [nnabla]: epoch 5 of 200 cost=4.019478  {train_error=3.965719, valid_error=3.963571} time=(0.5s /19.8s) 
2024-01-28 22:43:07,190 [nnabla]: epoch 6 of 200 cost=3.916484  time=(0.6s /19.6s) 
2024-01-28 22:43:07,232 [nnabla]: epoch 7 of 200 cost=3.813382  time=(0.6s /18.0s) 
2024-01-28 22:43:07,276 [nnabla]: epoch 8 of 200 cost=3.712125  time=(0.7s /16.8s) 
2024-01-28 22:43:07,317 [nnabla]: epoch 9 of 200 cost=3.611984  time=(0.7s /15.9s) 
2024-01-28 22:43:07,410 [nnabla]: epoch 10 of 200 cost=3.513204  {train_error=3.462676, valid_error=3.460356} time=(0.8s /15.1s) 
2024-01-28 22:43:07,454 [nnabla]: epoch 11 of 200 cost=3.416052  time=(0.9s /15.5s) 
2024-01-28 22:43:07,506 [nnabla]: epoch 12 of 200 cost=3.319851  time=(0.9s /14.9s) 
2024-01-28 22:43:07,548 [nnabla]: epoch 13 of 200 cost=3.226664  time=(0.9s /14.5s) 
2024-01-28 22:43:07,589 [nnabla]: epoch 14 of 200 cost=3.134252  time=(1.0s /14.1s) 
2024-01-28 22:43:07,630 [nnabla]: epoch 15 of 200 cost=3.043937  time=(1.0s /13.7s) 
2024-01-28 22:43:07,675 [nnabla]: epoch 16 of 200 cost=2.956386  time=(1.1s /13.4s) 
2024-01-28 22:43:07,720 [nnabla]: epoch 17 of 200 cost=2.870399  time=(1.1s /13.1s) 
2024-01-28 22:43:07,761 [nnabla]: epoch 18 of 200 cost=2.787175  time=(1.2s /12.9s) 
2024-01-28 22:43:07,803 [nnabla]: epoch 19 of 200 cost=2.706248  time=(1.2s /12.6s) 
2024-01-28 22:43:07,895 [nnabla]: epoch 20 of 200 cost=2.628174  {train_error=2.588518, valid_error=2.586277} time=(1.2s /12.4s) 
2024-01-28 22:43:07,940 [nnabla]: epoch 21 of 200 cost=2.552395  time=(1.3s /12.7s) 
2024-01-28 22:43:07,985 [nnabla]: epoch 22 of 200 cost=2.479156  time=(1.4s /12.6s) 
2024-01-28 22:43:08,036 [nnabla]: epoch 23 of 200 cost=2.409788  time=(1.4s /12.4s) 
2024-01-28 22:43:08,079 [nnabla]: epoch 24 of 200 cost=2.342020  time=(1.5s /12.3s) 
2024-01-28 22:43:08,122 [nnabla]: epoch 25 of 200 cost=2.278224  time=(1.5s /12.2s) 
2024-01-28 22:43:08,164 [nnabla]: epoch 26 of 200 cost=2.216640  time=(1.6s /12.0s) 
2024-01-28 22:43:08,206 [nnabla]: epoch 27 of 200 cost=2.157770  time=(1.6s /11.9s) 
2024-01-28 22:43:08,247 [nnabla]: epoch 28 of 200 cost=2.101973  time=(1.6s /11.7s) 
2024-01-28 22:43:08,289 [nnabla]: epoch 29 of 200 cost=2.049348  time=(1.7s /11.6s) 
2024-01-28 22:43:08,380 [nnabla]: epoch 30 of 200 cost=1.999402  {train_error=1.974006, valid_error=1.972393} time=(1.7s /11.5s) 
2024-01-28 22:43:08,423 [nnabla]: epoch 31 of 200 cost=1.951245  time=(1.8s /11.7s) 
2024-01-28 22:43:08,465 [nnabla]: epoch 32 of 200 cost=1.907821  time=(1.9s /11.6s) 
2024-01-28 22:43:08,506 [nnabla]: epoch 33 of 200 cost=1.864290  time=(1.9s /11.5s) 
2024-01-28 22:43:08,558 [nnabla]: epoch 34 of 200 cost=1.824625  time=(1.9s /11.5s) 
2024-01-28 22:43:08,602 [nnabla]: epoch 35 of 200 cost=1.787307  time=(2.0s /11.4s) 
2024-01-28 22:43:08,642 [nnabla]: epoch 36 of 200 cost=1.752159  time=(2.0s /11.3s) 
2024-01-28 22:43:08,686 [nnabla]: epoch 37 of 200 cost=1.718030  time=(2.1s /11.3s) 
2024-01-28 22:43:08,727 [nnabla]: epoch 38 of 200 cost=1.687964  time=(2.1s /11.2s) 
2024-01-28 22:43:08,770 [nnabla]: epoch 39 of 200 cost=1.658164  time=(2.2s /11.1s) 
2024-01-28 22:43:08,862 [nnabla]: epoch 40 of 200 cost=1.630479  {train_error=1.616979, valid_error=1.616658} time=(2.2s /11.0s) 
2024-01-28 22:43:08,903 [nnabla]: epoch 41 of 200 cost=1.604537  time=(2.3s /11.2s) 
2024-01-28 22:43:08,944 [nnabla]: epoch 42 of 200 cost=1.580266  time=(2.3s /11.2s) 
2024-01-28 22:43:08,986 [nnabla]: epoch 43 of 200 cost=1.557266  time=(2.4s /11.1s) 
2024-01-28 22:43:09,028 [nnabla]: epoch 44 of 200 cost=1.535762  time=(2.4s /11.0s) 
2024-01-28 22:43:09,088 [nnabla]: epoch 45 of 200 cost=1.515111  time=(2.5s /11.0s) 
2024-01-28 22:43:09,129 [nnabla]: epoch 46 of 200 cost=1.497008  time=(2.5s /11.0s) 
2024-01-28 22:43:09,171 [nnabla]: epoch 47 of 200 cost=1.478949  time=(2.6s /10.9s) 
2024-01-28 22:43:09,216 [nnabla]: epoch 48 of 200 cost=1.462030  time=(2.6s /10.9s) 
2024-01-28 22:43:09,258 [nnabla]: epoch 49 of 200 cost=1.446150  time=(2.7s /10.8s) 
2024-01-28 22:43:09,351 [nnabla]: epoch 50 of 200 cost=1.431509  {train_error=1.423714, valid_error=1.424274} time=(2.7s /10.8s) 
2024-01-28 22:43:09,393 [nnabla]: epoch 51 of 200 cost=1.416878  time=(2.8s /10.9s) 
2024-01-28 22:43:09,436 [nnabla]: epoch 52 of 200 cost=1.404206  time=(2.8s /10.9s) 
2024-01-28 22:43:09,480 [nnabla]: epoch 53 of 200 cost=1.391487  time=(2.9s /10.9s) 
2024-01-28 22:43:09,522 [nnabla]: epoch 54 of 200 cost=1.379329  time=(2.9s /10.8s) 
2024-01-28 22:43:09,566 [nnabla]: epoch 55 of 200 cost=1.368624  time=(3.0s /10.8s) 
2024-01-28 22:43:09,616 [nnabla]: epoch 56 of 200 cost=1.358052  time=(3.0s /10.7s) 
2024-01-28 22:43:09,660 [nnabla]: epoch 57 of 200 cost=1.347960  time=(3.1s /10.7s) 
2024-01-28 22:43:09,701 [nnabla]: epoch 58 of 200 cost=1.338334  time=(3.1s /10.7s) 
2024-01-28 22:43:09,745 [nnabla]: epoch 59 of 200 cost=1.329639  time=(3.1s /10.7s) 
2024-01-28 22:43:09,838 [nnabla]: epoch 60 of 200 cost=1.320978  {train_error=1.316865, valid_error=1.317039} time=(3.2s /10.6s) 
2024-01-28 22:43:09,880 [nnabla]: epoch 61 of 200 cost=1.313266  time=(3.3s /10.7s) 
2024-01-28 22:43:09,923 [nnabla]: epoch 62 of 200 cost=1.305079  time=(3.3s /10.7s) 
2024-01-28 22:43:09,965 [nnabla]: epoch 63 of 200 cost=1.298278  time=(3.4s /10.7s) 
2024-01-28 22:43:10,008 [nnabla]: epoch 64 of 200 cost=1.291011  time=(3.4s /10.6s) 
2024-01-28 22:43:10,050 [nnabla]: epoch 65 of 200 cost=1.284653  time=(3.4s /10.6s) 
2024-01-28 22:43:10,091 [nnabla]: epoch 66 of 200 cost=1.278214  time=(3.5s /10.6s) 
2024-01-28 22:43:10,140 [nnabla]: epoch 67 of 200 cost=1.272180  time=(3.5s /10.5s) 
2024-01-28 22:43:10,183 [nnabla]: epoch 68 of 200 cost=1.266868  time=(3.6s /10.5s) 
2024-01-28 22:43:10,226 [nnabla]: epoch 69 of 200 cost=1.260956  time=(3.6s /10.5s) 
2024-01-28 22:43:10,320 [nnabla]: epoch 70 of 200 cost=1.256115  {train_error=1.253330, valid_error=1.253476} time=(3.7s /10.5s) 
2024-01-28 22:43:10,363 [nnabla]: epoch 71 of 200 cost=1.251058  time=(3.8s /10.6s) 
2024-01-28 22:43:10,406 [nnabla]: epoch 72 of 200 cost=1.246346  time=(3.8s /10.6s) 
2024-01-28 22:43:10,447 [nnabla]: epoch 73 of 200 cost=1.241742  time=(3.8s /10.5s) 
2024-01-28 22:43:10,490 [nnabla]: epoch 74 of 200 cost=1.237282  time=(3.9s /10.5s) 
2024-01-28 22:43:10,533 [nnabla]: epoch 75 of 200 cost=1.233315  time=(3.9s /10.5s) 
2024-01-28 22:43:10,577 [nnabla]: epoch 76 of 200 cost=1.229421  time=(4.0s /10.5s) 
2024-01-28 22:43:10,619 [nnabla]: epoch 77 of 200 cost=1.225532  time=(4.0s /10.4s) 
2024-01-28 22:43:10,670 [nnabla]: epoch 78 of 200 cost=1.221848  time=(4.1s /10.4s) 
2024-01-28 22:43:10,715 [nnabla]: epoch 79 of 200 cost=1.218362  time=(4.1s /10.4s) 
2024-01-28 22:43:10,804 [nnabla]: epoch 80 of 200 cost=1.214913  {train_error=1.213260, valid_error=1.213363} time=(4.2s /10.4s) 
2024-01-28 22:43:10,847 [nnabla]: epoch 81 of 200 cost=1.211719  time=(4.2s /10.5s) 
2024-01-28 22:43:10,891 [nnabla]: epoch 82 of 200 cost=1.208627  time=(4.3s /10.5s) 
2024-01-28 22:43:10,936 [nnabla]: epoch 83 of 200 cost=1.205576  time=(4.3s /10.4s) 
2024-01-28 22:43:10,979 [nnabla]: epoch 84 of 200 cost=1.202822  time=(4.4s /10.4s) 
2024-01-28 22:43:11,021 [nnabla]: epoch 85 of 200 cost=1.199964  time=(4.4s /10.4s) 
2024-01-28 22:43:11,065 [nnabla]: epoch 86 of 200 cost=1.197357  time=(4.5s /10.4s) 
2024-01-28 22:43:11,107 [nnabla]: epoch 87 of 200 cost=1.194784  time=(4.5s /10.4s) 
2024-01-28 22:43:11,148 [nnabla]: epoch 88 of 200 cost=1.192268  time=(4.5s /10.3s) 
2024-01-28 22:43:11,198 [nnabla]: epoch 89 of 200 cost=1.189950  time=(4.6s /10.3s) 
2024-01-28 22:43:11,290 [nnabla]: epoch 90 of 200 cost=1.187645  {train_error=1.186406, valid_error=1.186439} time=(4.6s /10.3s) 
2024-01-28 22:43:11,333 [nnabla]: epoch 91 of 200 cost=1.185376  time=(4.7s /10.4s) 
2024-01-28 22:43:11,376 [nnabla]: epoch 92 of 200 cost=1.183228  time=(4.8s /10.4s) 
2024-01-28 22:43:11,419 [nnabla]: epoch 93 of 200 cost=1.181227  time=(4.8s /10.4s) 
2024-01-28 22:43:11,466 [nnabla]: epoch 94 of 200 cost=1.179156  time=(4.9s /10.3s) 
2024-01-28 22:43:11,508 [nnabla]: epoch 95 of 200 cost=1.177271  time=(4.9s /10.3s) 
2024-01-28 22:43:11,551 [nnabla]: epoch 96 of 200 cost=1.175415  time=(4.9s /10.3s) 
2024-01-28 22:43:11,594 [nnabla]: epoch 97 of 200 cost=1.173587  time=(5.0s /10.3s) 
2024-01-28 22:43:11,636 [nnabla]: epoch 98 of 200 cost=1.171860  time=(5.0s /10.3s) 
2024-01-28 22:43:11,677 [nnabla]: epoch 99 of 200 cost=1.170132  time=(5.1s /10.3s) 
2024-01-28 22:43:11,785 [nnabla]: epoch 100 of 200 cost=1.168493  {train_error=1.167667, valid_error=1.167602} time=(5.1s /10.2s) 
2024-01-28 22:43:11,827 [nnabla]: epoch 101 of 200 cost=1.166938  time=(5.2s /10.3s) 
2024-01-28 22:43:11,870 [nnabla]: epoch 102 of 200 cost=1.165429  time=(5.3s /10.3s) 
2024-01-28 22:43:11,911 [nnabla]: epoch 103 of 200 cost=1.163925  time=(5.3s /10.3s) 
2024-01-28 22:43:11,955 [nnabla]: epoch 104 of 200 cost=1.162428  time=(5.4s /10.3s) 
2024-01-28 22:43:11,997 [nnabla]: epoch 105 of 200 cost=1.161048  time=(5.4s /10.3s) 
2024-01-28 22:43:12,041 [nnabla]: epoch 106 of 200 cost=1.159681  time=(5.4s /10.3s) 
2024-01-28 22:43:12,084 [nnabla]: epoch 107 of 200 cost=1.158411  time=(5.5s /10.2s) 
2024-01-28 22:43:12,125 [nnabla]: epoch 108 of 200 cost=1.157157  time=(5.5s /10.2s) 
2024-01-28 22:43:12,168 [nnabla]: epoch 109 of 200 cost=1.155857  time=(5.6s /10.2s) 
2024-01-28 22:43:12,262 [nnabla]: epoch 110 of 200 cost=1.154703  {train_error=1.154020, valid_error=1.154004} time=(5.6s /10.2s) 
2024-01-28 22:43:12,311 [nnabla]: epoch 111 of 200 cost=1.153490  time=(5.7s /10.3s) 
2024-01-28 22:43:12,355 [nnabla]: epoch 112 of 200 cost=1.152469  time=(5.8s /10.3s) 
2024-01-28 22:43:12,397 [nnabla]: epoch 113 of 200 cost=1.151259  time=(5.8s /10.3s) 
2024-01-28 22:43:12,438 [nnabla]: epoch 114 of 200 cost=1.150257  time=(5.8s /10.2s) 
2024-01-28 22:43:12,480 [nnabla]: epoch 115 of 200 cost=1.149107  time=(5.9s /10.2s) 
2024-01-28 22:43:12,522 [nnabla]: epoch 116 of 200 cost=1.148207  time=(5.9s /10.2s) 
2024-01-28 22:43:12,566 [nnabla]: epoch 117 of 200 cost=1.147198  time=(6.0s /10.2s) 
2024-01-28 22:43:12,607 [nnabla]: epoch 118 of 200 cost=1.146163  time=(6.0s /10.2s) 
2024-01-28 22:43:12,648 [nnabla]: epoch 119 of 200 cost=1.145243  time=(6.0s /10.2s) 
2024-01-28 22:43:12,740 [nnabla]: epoch 120 of 200 cost=1.144326  {train_error=1.143867, valid_error=1.143906} time=(6.1s /10.1s) 
2024-01-28 22:43:12,783 [nnabla]: epoch 121 of 200 cost=1.143505  time=(6.2s /10.2s) 
2024-01-28 22:43:12,834 [nnabla]: epoch 122 of 200 cost=1.142662  time=(6.2s /10.2s) 
2024-01-28 22:43:12,875 [nnabla]: epoch 123 of 200 cost=1.141792  time=(6.3s /10.2s) 
2024-01-28 22:43:12,917 [nnabla]: epoch 124 of 200 cost=1.140930  time=(6.3s /10.2s) 
2024-01-28 22:43:12,958 [nnabla]: epoch 125 of 200 cost=1.140199  time=(6.4s /10.2s) 
2024-01-28 22:43:13,001 [nnabla]: epoch 126 of 200 cost=1.139365  time=(6.4s /10.2s) 
2024-01-28 22:43:13,043 [nnabla]: epoch 127 of 200 cost=1.138607  time=(6.4s /10.1s) 
2024-01-28 22:43:13,084 [nnabla]: epoch 128 of 200 cost=1.137939  time=(6.5s /10.1s) 
2024-01-28 22:43:13,125 [nnabla]: epoch 129 of 200 cost=1.137170  time=(6.5s /10.1s) 
2024-01-28 22:43:13,218 [nnabla]: epoch 130 of 200 cost=1.136480  {train_error=1.136032, valid_error=1.136181} time=(6.6s /10.1s) 
2024-01-28 22:43:13,261 [nnabla]: epoch 131 of 200 cost=1.135812  time=(6.7s /10.2s) 
2024-01-28 22:43:13,304 [nnabla]: epoch 132 of 200 cost=1.135133  time=(6.7s /10.2s) 
2024-01-28 22:43:13,353 [nnabla]: epoch 133 of 200 cost=1.134516  time=(6.7s /10.1s) 
2024-01-28 22:43:13,395 [nnabla]: epoch 134 of 200 cost=1.133827  time=(6.8s /10.1s) 
2024-01-28 22:43:13,439 [nnabla]: epoch 135 of 200 cost=1.133223  time=(6.8s /10.1s) 
2024-01-28 22:43:13,479 [nnabla]: epoch 136 of 200 cost=1.132597  time=(6.9s /10.1s) 
2024-01-28 22:43:13,523 [nnabla]: epoch 137 of 200 cost=1.132018  time=(6.9s /10.1s) 
2024-01-28 22:43:13,565 [nnabla]: epoch 138 of 200 cost=1.131476  time=(7.0s /10.1s) 
2024-01-28 22:43:13,606 [nnabla]: epoch 139 of 200 cost=1.130898  time=(7.0s /10.1s) 
2024-01-28 22:43:13,699 [nnabla]: epoch 140 of 200 cost=1.130354  {train_error=1.129980, valid_error=1.130074} time=(7.0s /10.1s) 
2024-01-28 22:43:13,741 [nnabla]: epoch 141 of 200 cost=1.129812  time=(7.1s /10.1s) 
2024-01-28 22:43:13,783 [nnabla]: epoch 142 of 200 cost=1.129261  time=(7.2s /10.1s) 
2024-01-28 22:43:13,825 [nnabla]: epoch 143 of 200 cost=1.128734  time=(7.2s /10.1s) 
2024-01-28 22:43:13,875 [nnabla]: epoch 144 of 200 cost=1.128279  time=(7.3s /10.1s) 
2024-01-28 22:43:13,917 [nnabla]: epoch 145 of 200 cost=1.127783  time=(7.3s /10.1s) 
2024-01-28 22:43:13,960 [nnabla]: epoch 146 of 200 cost=1.127254  time=(7.4s /10.1s) 
2024-01-28 22:43:14,002 [nnabla]: epoch 147 of 200 cost=1.126824  time=(7.4s /10.1s) 
2024-01-28 22:43:14,044 [nnabla]: epoch 148 of 200 cost=1.126345  time=(7.4s /10.1s) 
2024-01-28 22:43:14,086 [nnabla]: epoch 149 of 200 cost=1.125953  time=(7.5s /10.0s) 
2024-01-28 22:43:14,175 [nnabla]: epoch 150 of 200 cost=1.125413  {train_error=1.125140, valid_error=1.125114} time=(7.5s /10.0s) 
2024-01-28 22:43:14,220 [nnabla]: epoch 151 of 200 cost=1.125031  time=(7.6s /10.1s) 
2024-01-28 22:43:14,263 [nnabla]: epoch 152 of 200 cost=1.124636  time=(7.7s /10.1s) 
2024-01-28 22:43:14,306 [nnabla]: epoch 153 of 200 cost=1.124253  time=(7.7s /10.1s) 
2024-01-28 22:43:14,349 [nnabla]: epoch 154 of 200 cost=1.123928  time=(7.7s /10.1s) 
2024-01-28 22:43:14,407 [nnabla]: epoch 155 of 200 cost=1.123397  time=(7.8s /10.1s) 
2024-01-28 22:43:14,452 [nnabla]: epoch 156 of 200 cost=1.122901  time=(7.8s /10.1s) 
2024-01-28 22:43:14,495 [nnabla]: epoch 157 of 200 cost=1.122750  time=(7.9s /10.1s) 
2024-01-28 22:43:14,537 [nnabla]: epoch 158 of 200 cost=1.122291  time=(7.9s /10.0s) 
2024-01-28 22:43:14,578 [nnabla]: epoch 159 of 200 cost=1.121918  time=(8.0s /10.0s) 
2024-01-28 22:43:14,670 [nnabla]: epoch 160 of 200 cost=1.121442  {train_error=1.121281, valid_error=1.121294} time=(8.0s /10.0s) 
2024-01-28 22:43:14,712 [nnabla]: epoch 161 of 200 cost=1.121248  time=(8.1s /10.1s) 
2024-01-28 22:43:14,757 [nnabla]: epoch 162 of 200 cost=1.120830  time=(8.2s /10.1s) 
2024-01-28 22:43:14,798 [nnabla]: epoch 163 of 200 cost=1.120480  time=(8.2s /10.1s) 
2024-01-28 22:43:14,841 [nnabla]: epoch 164 of 200 cost=1.120213  time=(8.2s /10.0s) 
2024-01-28 22:43:14,884 [nnabla]: epoch 165 of 200 cost=1.119882  time=(8.3s /10.0s) 
2024-01-28 22:43:14,936 [nnabla]: epoch 166 of 200 cost=1.119571  time=(8.3s /10.0s) 
2024-01-28 22:43:14,980 [nnabla]: epoch 167 of 200 cost=1.119217  time=(8.4s /10.0s) 
2024-01-28 22:43:15,025 [nnabla]: epoch 168 of 200 cost=1.118881  time=(8.4s /10.0s) 
2024-01-28 22:43:15,068 [nnabla]: epoch 169 of 200 cost=1.118634  time=(8.5s /10.0s) 
2024-01-28 22:43:15,161 [nnabla]: epoch 170 of 200 cost=1.118312  {train_error=1.118105, valid_error=1.118037} time=(8.5s /10.0s) 
2024-01-28 22:43:15,204 [nnabla]: epoch 171 of 200 cost=1.118031  time=(8.6s /10.1s) 
2024-01-28 22:43:15,246 [nnabla]: epoch 172 of 200 cost=1.117790  time=(8.6s /10.1s) 
2024-01-28 22:43:15,288 [nnabla]: epoch 173 of 200 cost=1.117573  time=(8.7s /10.0s) 
2024-01-28 22:43:15,331 [nnabla]: epoch 174 of 200 cost=1.117226  time=(8.7s /10.0s) 
2024-01-28 22:43:15,373 [nnabla]: epoch 175 of 200 cost=1.116933  time=(8.8s /10.0s) 
2024-01-28 22:43:15,415 [nnabla]: epoch 176 of 200 cost=1.116747  time=(8.8s /10.0s) 
2024-01-28 22:43:15,468 [nnabla]: epoch 177 of 200 cost=1.116426  time=(8.9s /10.0s) 
2024-01-28 22:43:15,510 [nnabla]: epoch 178 of 200 cost=1.116185  time=(8.9s /10.0s) 
2024-01-28 22:43:15,553 [nnabla]: epoch 179 of 200 cost=1.115915  time=(8.9s /10.0s) 
2024-01-28 22:43:15,641 [nnabla]: epoch 180 of 200 cost=1.115699  {train_error=1.115488, valid_error=1.115551} time=(9.0s /10.0s) 
2024-01-28 22:43:15,683 [nnabla]: epoch 181 of 200 cost=1.115444  time=(9.1s /10.0s) 
2024-01-28 22:43:15,724 [nnabla]: epoch 182 of 200 cost=1.115174  time=(9.1s /10.0s) 
2024-01-28 22:43:15,767 [nnabla]: epoch 183 of 200 cost=1.115005  time=(9.2s /10.0s) 
2024-01-28 22:43:15,810 [nnabla]: epoch 184 of 200 cost=1.114705  time=(9.2s /10.0s) 
2024-01-28 22:43:15,853 [nnabla]: epoch 185 of 200 cost=1.114505  time=(9.2s /10.0s) 
2024-01-28 22:43:15,894 [nnabla]: epoch 186 of 200 cost=1.114377  time=(9.3s /10.0s) 
2024-01-28 22:43:15,937 [nnabla]: epoch 187 of 200 cost=1.114061  time=(9.3s /10.0s) 
2024-01-28 22:43:15,987 [nnabla]: epoch 188 of 200 cost=1.113990  time=(9.4s /10.0s) 
2024-01-28 22:43:16,031 [nnabla]: epoch 189 of 200 cost=1.113685  time=(9.4s /10.0s) 
2024-01-28 22:43:16,123 [nnabla]: epoch 190 of 200 cost=1.113456  {train_error=1.113286, valid_error=1.113283} time=(9.5s /10.0s) 
2024-01-28 22:43:16,164 [nnabla]: epoch 191 of 200 cost=1.113234  time=(9.6s /10.0s) 
2024-01-28 22:43:16,206 [nnabla]: epoch 192 of 200 cost=1.113022  time=(9.6s /10.0s) 
2024-01-28 22:43:16,249 [nnabla]: epoch 193 of 200 cost=1.112884  time=(9.6s /10.0s) 
2024-01-28 22:43:16,291 [nnabla]: epoch 194 of 200 cost=1.112701  time=(9.7s /10.0s) 
2024-01-28 22:43:16,333 [nnabla]: epoch 195 of 200 cost=1.112467  time=(9.7s /10.0s) 
2024-01-28 22:43:16,375 [nnabla]: epoch 196 of 200 cost=1.112375  time=(9.8s /10.0s) 
2024-01-28 22:43:16,418 [nnabla]: epoch 197 of 200 cost=1.112124  time=(9.8s /10.0s) 
2024-01-28 22:43:16,460 [nnabla]: epoch 198 of 200 cost=1.111921  time=(9.9s /10.0s) 
2024-01-28 22:43:16,511 [nnabla]: epoch 199 of 200 cost=1.111829  time=(9.9s /10.0s) 
2024-01-28 22:43:16,606 [nnabla]: epoch 200 of 200 cost=1.111700  {train_error=1.111384, valid_error=1.111574} time=(10.0s /10.0s) 
2024-01-28 22:43:16,621 [nnabla]: Training Completed.
NNabla command line interface (Version:1.33.1, Build:230206070804, Callback:NNabla SSH callback module.)

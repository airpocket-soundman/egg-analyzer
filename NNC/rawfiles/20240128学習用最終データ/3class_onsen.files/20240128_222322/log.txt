2024-01-28 22:23:22,508 Training process is started.
python "C:\Users\yamas\Desktop\tools\neural_network_console\libs\Python\Lib\site-packages\nnabla\utils\cli\cli.py" train
	-c "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_222322\net.nntxt"
	-o "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_222322"
2024-01-28 22:23:23,040 [nnabla]: [CALLBACK]: Exec train on local
2024-01-28 22:23:23,046 [nnabla]: Using context "Context(backend=['cpu:float'], array_class='CpuCachedArray', device_id='')"
2024-01-28 22:23:23,046 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_test_3class_onsen.csv"
2024-01-28 22:23:23,631 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_valid_3class_onsen.csv"
2024-01-28 22:23:24,010 [nnabla]: Train with contexts ['cpu']
2024-01-28 22:23:24,035 [nnabla]: Training epoch 1 of 100 begin
2024-01-28 22:23:24,035 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 22:23:24,035 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 22:23:24,238 [nnabla]: epoch 1 of 100 cost=4.345782  {train_error=4.036403, valid_error=4.011711} time=(0.1s /9.3s) 
2024-01-28 22:23:24,328 [nnabla]: epoch 2 of 100 cost=3.867844  {train_error=3.581999, valid_error=3.555904} time=(0.2s /12.2s) 
2024-01-28 22:23:24,411 [nnabla]: epoch 3 of 100 cost=3.530910  {train_error=3.376988, valid_error=3.354552} time=(0.3s /11.1s) 
2024-01-28 22:23:24,493 [nnabla]: epoch 4 of 100 cost=3.307394  {train_error=3.194995, valid_error=3.182739} time=(0.4s /10.4s) 
2024-01-28 22:23:24,584 [nnabla]: epoch 5 of 100 cost=3.125993  {train_error=3.001234, valid_error=2.995116} time=(0.5s /10.0s) 
2024-01-28 22:23:24,625 [nnabla]: epoch 6 of 100 cost=2.980672  time=(0.6s /9.8s) 
2024-01-28 22:23:24,668 [nnabla]: epoch 7 of 100 cost=2.841383  time=(0.6s /9.0s) 
2024-01-28 22:23:24,710 [nnabla]: epoch 8 of 100 cost=2.740446  time=(0.7s /8.4s) 
2024-01-28 22:23:24,750 [nnabla]: epoch 9 of 100 cost=2.642978  time=(0.7s /7.9s) 
2024-01-28 22:23:24,841 [nnabla]: epoch 10 of 100 cost=2.541437  {train_error=2.379009, valid_error=2.386198} time=(0.8s /7.6s) 
2024-01-28 22:23:24,885 [nnabla]: epoch 11 of 100 cost=2.446959  time=(0.8s /7.7s) 
2024-01-28 22:23:24,934 [nnabla]: epoch 12 of 100 cost=2.345267  time=(0.9s /7.4s) 
2024-01-28 22:23:24,977 [nnabla]: epoch 13 of 100 cost=2.268844  time=(0.9s /7.2s) 
2024-01-28 22:23:25,018 [nnabla]: epoch 14 of 100 cost=2.180252  time=(1.0s /7.0s) 
2024-01-28 22:23:25,059 [nnabla]: epoch 15 of 100 cost=2.098920  time=(1.0s /6.8s) 
2024-01-28 22:23:25,101 [nnabla]: epoch 16 of 100 cost=2.011093  time=(1.1s /6.7s) 
2024-01-28 22:23:25,141 [nnabla]: epoch 17 of 100 cost=1.937374  time=(1.1s /6.5s) 
2024-01-28 22:23:25,184 [nnabla]: epoch 18 of 100 cost=1.866592  time=(1.1s /6.4s) 
2024-01-28 22:23:25,225 [nnabla]: epoch 19 of 100 cost=1.782896  time=(1.2s /6.3s) 
2024-01-28 22:23:25,324 [nnabla]: epoch 20 of 100 cost=1.721747  {train_error=1.638570, valid_error=1.651911} time=(1.2s /6.1s) 
2024-01-28 22:23:25,366 [nnabla]: epoch 21 of 100 cost=1.638226  time=(1.3s /6.3s) 
2024-01-28 22:23:25,409 [nnabla]: epoch 22 of 100 cost=1.584563  time=(1.4s /6.2s) 
2024-01-28 22:23:25,458 [nnabla]: epoch 23 of 100 cost=1.512357  time=(1.4s /6.2s) 
2024-01-28 22:23:25,500 [nnabla]: epoch 24 of 100 cost=1.444074  time=(1.5s /6.1s) 
2024-01-28 22:23:25,541 [nnabla]: epoch 25 of 100 cost=1.398638  time=(1.5s /6.0s) 
2024-01-28 22:23:25,581 [nnabla]: epoch 26 of 100 cost=1.328913  time=(1.5s /5.9s) 
2024-01-28 22:23:25,622 [nnabla]: epoch 27 of 100 cost=1.284780  time=(1.6s /5.9s) 
2024-01-28 22:23:25,666 [nnabla]: epoch 28 of 100 cost=1.229187  time=(1.6s /5.8s) 
2024-01-28 22:23:25,706 [nnabla]: epoch 29 of 100 cost=1.180033  time=(1.7s /5.8s) 
2024-01-28 22:23:25,797 [nnabla]: epoch 30 of 100 cost=1.123105  {train_error=0.995925, valid_error=1.004640} time=(1.7s /5.7s) 
2024-01-28 22:23:25,840 [nnabla]: epoch 31 of 100 cost=1.076816  time=(1.8s /5.8s) 
2024-01-28 22:23:25,881 [nnabla]: epoch 32 of 100 cost=1.021709  time=(1.8s /5.8s) 
2024-01-28 22:23:25,923 [nnabla]: epoch 33 of 100 cost=0.982214  time=(1.9s /5.7s) 
2024-01-28 22:23:25,974 [nnabla]: epoch 34 of 100 cost=0.943558  time=(1.9s /5.7s) 
2024-01-28 22:23:26,016 [nnabla]: epoch 35 of 100 cost=0.901934  time=(2.0s /5.7s) 
2024-01-28 22:23:26,057 [nnabla]: epoch 36 of 100 cost=0.860660  time=(2.0s /5.6s) 
2024-01-28 22:23:26,098 [nnabla]: epoch 37 of 100 cost=0.835713  time=(2.1s /5.6s) 
2024-01-28 22:23:26,140 [nnabla]: epoch 38 of 100 cost=0.802033  time=(2.1s /5.5s) 
2024-01-28 22:23:26,182 [nnabla]: epoch 39 of 100 cost=0.750214  time=(2.1s /5.5s) 
2024-01-28 22:23:26,273 [nnabla]: epoch 40 of 100 cost=0.721969  {train_error=0.615323, valid_error=0.620135} time=(2.2s /5.5s) 
2024-01-28 22:23:26,316 [nnabla]: epoch 41 of 100 cost=0.685308  time=(2.3s /5.6s) 
2024-01-28 22:23:26,359 [nnabla]: epoch 42 of 100 cost=0.666993  time=(2.3s /5.5s) 
2024-01-28 22:23:26,400 [nnabla]: epoch 43 of 100 cost=0.636411  time=(2.4s /5.5s) 
2024-01-28 22:23:26,445 [nnabla]: epoch 44 of 100 cost=0.605325  time=(2.4s /5.5s) 
2024-01-28 22:23:26,503 [nnabla]: epoch 45 of 100 cost=0.582476  time=(2.5s /5.4s) 
2024-01-28 22:23:26,543 [nnabla]: epoch 46 of 100 cost=0.563481  time=(2.5s /5.5s) 
2024-01-28 22:23:26,585 [nnabla]: epoch 47 of 100 cost=0.539707  time=(2.5s /5.4s) 
2024-01-28 22:23:26,626 [nnabla]: epoch 48 of 100 cost=0.515316  time=(2.6s /5.4s) 
2024-01-28 22:23:26,671 [nnabla]: epoch 49 of 100 cost=0.498513  time=(2.6s /5.4s) 
2024-01-28 22:23:26,781 [nnabla]: epoch 50 of 100 cost=0.480595  {train_error=0.391833, valid_error=0.400434} time=(2.7s /5.4s) 
2024-01-28 22:23:26,824 [nnabla]: epoch 51 of 100 cost=0.463740  time=(2.8s /5.5s) 
2024-01-28 22:23:26,867 [nnabla]: epoch 52 of 100 cost=0.445242  time=(2.8s /5.4s) 
2024-01-28 22:23:26,908 [nnabla]: epoch 53 of 100 cost=0.435300  time=(2.9s /5.4s) 
2024-01-28 22:23:26,953 [nnabla]: epoch 54 of 100 cost=0.413478  time=(2.9s /5.4s) 
2024-01-28 22:23:26,994 [nnabla]: epoch 55 of 100 cost=0.400526  time=(3.0s /5.4s) 
2024-01-28 22:23:27,043 [nnabla]: epoch 56 of 100 cost=0.375574  time=(3.0s /5.4s) 
2024-01-28 22:23:27,087 [nnabla]: epoch 57 of 100 cost=0.375234  time=(3.1s /5.4s) 
2024-01-28 22:23:27,128 [nnabla]: epoch 58 of 100 cost=0.352881  time=(3.1s /5.3s) 
2024-01-28 22:23:27,170 [nnabla]: epoch 59 of 100 cost=0.338124  time=(3.1s /5.3s) 
2024-01-28 22:23:27,266 [nnabla]: epoch 60 of 100 cost=0.325440  {train_error=0.254389, valid_error=0.255649} time=(3.2s /5.3s) 
2024-01-28 22:23:27,307 [nnabla]: epoch 61 of 100 cost=0.321083  time=(3.3s /5.4s) 
2024-01-28 22:23:27,348 [nnabla]: epoch 62 of 100 cost=0.317134  time=(3.3s /5.3s) 
2024-01-28 22:23:27,391 [nnabla]: epoch 63 of 100 cost=0.302759  time=(3.4s /5.3s) 
2024-01-28 22:23:27,434 [nnabla]: epoch 64 of 100 cost=0.294193  time=(3.4s /5.3s) 
2024-01-28 22:23:27,481 [nnabla]: epoch 65 of 100 cost=0.278159  time=(3.4s /5.3s) 
2024-01-28 22:23:27,522 [nnabla]: epoch 66 of 100 cost=0.281322  time=(3.5s /5.3s) 
2024-01-28 22:23:27,572 [nnabla]: epoch 67 of 100 cost=0.260915  time=(3.5s /5.3s) 
2024-01-28 22:23:27,613 [nnabla]: epoch 68 of 100 cost=0.251160  time=(3.6s /5.3s) 
2024-01-28 22:23:27,655 [nnabla]: epoch 69 of 100 cost=0.246946  time=(3.6s /5.2s) 
2024-01-28 22:23:27,745 [nnabla]: epoch 70 of 100 cost=0.244766  {train_error=0.174387, valid_error=0.179252} time=(3.7s /5.2s) 
2024-01-28 22:23:27,787 [nnabla]: epoch 71 of 100 cost=0.230687  time=(3.8s /5.3s) 
2024-01-28 22:23:27,828 [nnabla]: epoch 72 of 100 cost=0.221824  time=(3.8s /5.3s) 
2024-01-28 22:23:27,870 [nnabla]: epoch 73 of 100 cost=0.219680  time=(3.8s /5.3s) 
2024-01-28 22:23:27,911 [nnabla]: epoch 74 of 100 cost=0.211812  time=(3.9s /5.2s) 
2024-01-28 22:23:27,953 [nnabla]: epoch 75 of 100 cost=0.202827  time=(3.9s /5.2s) 
2024-01-28 22:23:27,995 [nnabla]: epoch 76 of 100 cost=0.196148  time=(4.0s /5.2s) 
2024-01-28 22:23:28,035 [nnabla]: epoch 77 of 100 cost=0.189759  time=(4.0s /5.2s) 
2024-01-28 22:23:28,085 [nnabla]: epoch 78 of 100 cost=0.190532  time=(4.0s /5.2s) 
2024-01-28 22:23:28,128 [nnabla]: epoch 79 of 100 cost=0.182903  time=(4.1s /5.2s) 
2024-01-28 22:23:28,220 [nnabla]: epoch 80 of 100 cost=0.177184  {train_error=0.126311, valid_error=0.130535} time=(4.1s /5.2s) 
2024-01-28 22:23:28,261 [nnabla]: epoch 81 of 100 cost=0.174759  time=(4.2s /5.2s) 
2024-01-28 22:23:28,302 [nnabla]: epoch 82 of 100 cost=0.170213  time=(4.3s /5.2s) 
2024-01-28 22:23:28,343 [nnabla]: epoch 83 of 100 cost=0.166445  time=(4.3s /5.2s) 
2024-01-28 22:23:28,385 [nnabla]: epoch 84 of 100 cost=0.158445  time=(4.3s /5.2s) 
2024-01-28 22:23:28,426 [nnabla]: epoch 85 of 100 cost=0.151956  time=(4.4s /5.2s) 
2024-01-28 22:23:28,468 [nnabla]: epoch 86 of 100 cost=0.150981  time=(4.4s /5.2s) 
2024-01-28 22:23:28,510 [nnabla]: epoch 87 of 100 cost=0.145962  time=(4.5s /5.1s) 
2024-01-28 22:23:28,552 [nnabla]: epoch 88 of 100 cost=0.149776  time=(4.5s /5.1s) 
2024-01-28 22:23:28,600 [nnabla]: epoch 89 of 100 cost=0.142174  time=(4.6s /5.1s) 
2024-01-28 22:23:28,693 [nnabla]: epoch 90 of 100 cost=0.136043  {train_error=0.092884, valid_error=0.096597} time=(4.6s /5.1s) 
2024-01-28 22:23:28,733 [nnabla]: epoch 91 of 100 cost=0.132754  time=(4.7s /5.2s) 
2024-01-28 22:23:28,777 [nnabla]: epoch 92 of 100 cost=0.122818  time=(4.7s /5.2s) 
2024-01-28 22:23:28,817 [nnabla]: epoch 93 of 100 cost=0.130054  time=(4.8s /5.1s) 
2024-01-28 22:23:28,859 [nnabla]: epoch 94 of 100 cost=0.125636  time=(4.8s /5.1s) 
2024-01-28 22:23:28,901 [nnabla]: epoch 95 of 100 cost=0.125706  time=(4.9s /5.1s) 
2024-01-28 22:23:28,942 [nnabla]: epoch 96 of 100 cost=0.114434  time=(4.9s /5.1s) 
2024-01-28 22:23:28,984 [nnabla]: epoch 97 of 100 cost=0.114878  time=(4.9s /5.1s) 
2024-01-28 22:23:29,025 [nnabla]: epoch 98 of 100 cost=0.108449  time=(5.0s /5.1s) 
2024-01-28 22:23:29,066 [nnabla]: epoch 99 of 100 cost=0.111985  time=(5.0s /5.1s) 
2024-01-28 22:23:29,174 [nnabla]: epoch 100 of 100 cost=0.107534  {train_error=0.070249, valid_error=0.072761} time=(5.1s /5.1s) 
2024-01-28 22:23:29,190 [nnabla]: Training Completed.
NNabla command line interface (Version:1.33.1, Build:230206070804, Callback:NNabla SSH callback module.)

2024-01-28 22:25:54,882 Training process is started.
python "C:\Users\yamas\Desktop\tools\neural_network_console\libs\Python\Lib\site-packages\nnabla\utils\cli\cli.py" train
	-c "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_222554\net.nntxt"
	-o "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_222554"
2024-01-28 22:25:55,427 [nnabla]: [CALLBACK]: Exec train on local
2024-01-28 22:25:55,433 [nnabla]: Using context "Context(backend=['cpu:float'], array_class='CpuCachedArray', device_id='')"
2024-01-28 22:25:55,434 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_test_3class_onsen.csv"
2024-01-28 22:25:56,023 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_valid_3class_onsen.csv"
2024-01-28 22:25:56,414 [nnabla]: Train with contexts ['cpu']
2024-01-28 22:25:56,436 [nnabla]: Training epoch 1 of 100 begin
2024-01-28 22:25:56,436 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 22:25:56,436 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 22:25:56,641 [nnabla]: epoch 1 of 100 cost=4.334233  {train_error=3.957623, valid_error=3.927766} time=(0.1s /9.6s) 
2024-01-28 22:25:56,735 [nnabla]: epoch 2 of 100 cost=3.842261  {train_error=3.428904, valid_error=3.409220} time=(0.3s /12.6s) 
2024-01-28 22:25:56,834 [nnabla]: epoch 3 of 100 cost=3.520044  {train_error=3.302100, valid_error=3.281431} time=(0.3s /11.5s) 
2024-01-28 22:25:56,926 [nnabla]: epoch 4 of 100 cost=3.294575  {train_error=3.160793, valid_error=3.146839} time=(0.4s /11.0s) 
2024-01-28 22:25:57,028 [nnabla]: epoch 5 of 100 cost=3.117041  {train_error=3.005572, valid_error=3.000783} time=(0.5s /10.7s) 
2024-01-28 22:25:57,072 [nnabla]: epoch 6 of 100 cost=2.978038  time=(0.6s /10.6s) 
2024-01-28 22:25:57,117 [nnabla]: epoch 7 of 100 cost=2.849274  time=(0.7s /9.7s) 
2024-01-28 22:25:57,162 [nnabla]: epoch 8 of 100 cost=2.745916  time=(0.7s /9.1s) 
2024-01-28 22:25:57,206 [nnabla]: epoch 9 of 100 cost=2.639351  time=(0.8s /8.6s) 
2024-01-28 22:25:57,307 [nnabla]: epoch 10 of 100 cost=2.530972  {train_error=2.457596, valid_error=2.466689} time=(0.8s /8.2s) 
2024-01-28 22:25:57,352 [nnabla]: epoch 11 of 100 cost=2.437805  time=(0.9s /8.3s) 
2024-01-28 22:25:57,406 [nnabla]: epoch 12 of 100 cost=2.354426  time=(1.0s /8.0s) 
2024-01-28 22:25:57,452 [nnabla]: epoch 13 of 100 cost=2.264469  time=(1.0s /7.8s) 
2024-01-28 22:25:57,497 [nnabla]: epoch 14 of 100 cost=2.181939  time=(1.1s /7.6s) 
2024-01-28 22:25:57,542 [nnabla]: epoch 15 of 100 cost=2.086418  time=(1.1s /7.4s) 
2024-01-28 22:25:57,588 [nnabla]: epoch 16 of 100 cost=2.016096  time=(1.2s /7.2s) 
2024-01-28 22:25:57,632 [nnabla]: epoch 17 of 100 cost=1.927125  time=(1.2s /7.0s) 
2024-01-28 22:25:57,677 [nnabla]: epoch 18 of 100 cost=1.860572  time=(1.2s /6.9s) 
2024-01-28 22:25:57,724 [nnabla]: epoch 19 of 100 cost=1.778080  time=(1.3s /6.8s) 
2024-01-28 22:25:57,825 [nnabla]: epoch 20 of 100 cost=1.716443  {train_error=1.605764, valid_error=1.618295} time=(1.3s /6.7s) 
2024-01-28 22:25:57,870 [nnabla]: epoch 21 of 100 cost=1.643188  time=(1.4s /6.8s) 
2024-01-28 22:25:57,915 [nnabla]: epoch 22 of 100 cost=1.585197  time=(1.5s /6.7s) 
2024-01-28 22:25:57,967 [nnabla]: epoch 23 of 100 cost=1.513248  time=(1.5s /6.6s) 
2024-01-28 22:25:58,012 [nnabla]: epoch 24 of 100 cost=1.442777  time=(1.6s /6.6s) 
2024-01-28 22:25:58,057 [nnabla]: epoch 25 of 100 cost=1.387815  time=(1.6s /6.5s) 
2024-01-28 22:25:58,104 [nnabla]: epoch 26 of 100 cost=1.322203  time=(1.7s /6.4s) 
2024-01-28 22:25:58,149 [nnabla]: epoch 27 of 100 cost=1.295725  time=(1.7s /6.3s) 
2024-01-28 22:25:58,195 [nnabla]: epoch 28 of 100 cost=1.225866  time=(1.8s /6.3s) 
2024-01-28 22:25:58,240 [nnabla]: epoch 29 of 100 cost=1.180397  time=(1.8s /6.2s) 
2024-01-28 22:25:58,341 [nnabla]: epoch 30 of 100 cost=1.120918  {train_error=1.009466, valid_error=1.016829} time=(1.8s /6.2s) 
2024-01-28 22:25:58,388 [nnabla]: epoch 31 of 100 cost=1.077843  time=(2.0s /6.3s) 
2024-01-28 22:25:58,435 [nnabla]: epoch 32 of 100 cost=1.028931  time=(2.0s /6.2s) 
2024-01-28 22:25:58,479 [nnabla]: epoch 33 of 100 cost=0.987887  time=(2.0s /6.2s) 
2024-01-28 22:25:58,532 [nnabla]: epoch 34 of 100 cost=0.941192  time=(2.1s /6.1s) 
2024-01-28 22:25:58,577 [nnabla]: epoch 35 of 100 cost=0.897702  time=(2.1s /6.1s) 
2024-01-28 22:25:58,622 [nnabla]: epoch 36 of 100 cost=0.851260  time=(2.2s /6.1s) 
2024-01-28 22:25:58,667 [nnabla]: epoch 37 of 100 cost=0.840079  time=(2.2s /6.0s) 
2024-01-28 22:25:58,712 [nnabla]: epoch 38 of 100 cost=0.799805  time=(2.3s /6.0s) 
2024-01-28 22:25:58,757 [nnabla]: epoch 39 of 100 cost=0.749226  time=(2.3s /6.0s) 
2024-01-28 22:25:58,859 [nnabla]: epoch 40 of 100 cost=0.733395  {train_error=0.626280, valid_error=0.629774} time=(2.4s /5.9s) 
2024-01-28 22:25:58,905 [nnabla]: epoch 41 of 100 cost=0.690295  time=(2.5s /6.0s) 
2024-01-28 22:25:58,950 [nnabla]: epoch 42 of 100 cost=0.664930  time=(2.5s /6.0s) 
2024-01-28 22:25:58,994 [nnabla]: epoch 43 of 100 cost=0.635854  time=(2.6s /6.0s) 
2024-01-28 22:25:59,052 [nnabla]: epoch 44 of 100 cost=0.609610  time=(2.6s /5.9s) 
2024-01-28 22:25:59,116 [nnabla]: epoch 45 of 100 cost=0.580585  time=(2.7s /5.9s) 
2024-01-28 22:25:59,162 [nnabla]: epoch 46 of 100 cost=0.560339  time=(2.7s /5.9s) 
2024-01-28 22:25:59,206 [nnabla]: epoch 47 of 100 cost=0.534151  time=(2.8s /5.9s) 
2024-01-28 22:25:59,251 [nnabla]: epoch 48 of 100 cost=0.515722  time=(2.8s /5.9s) 
2024-01-28 22:25:59,296 [nnabla]: epoch 49 of 100 cost=0.493013  time=(2.9s /5.8s) 
2024-01-28 22:25:59,404 [nnabla]: epoch 50 of 100 cost=0.467256  {train_error=0.390440, valid_error=0.397240} time=(2.9s /5.8s) 
2024-01-28 22:25:59,448 [nnabla]: epoch 51 of 100 cost=0.461607  time=(3.0s /5.9s) 
2024-01-28 22:25:59,494 [nnabla]: epoch 52 of 100 cost=0.442549  time=(3.1s /5.9s) 
2024-01-28 22:25:59,538 [nnabla]: epoch 53 of 100 cost=0.424337  time=(3.1s /5.9s) 
2024-01-28 22:25:59,584 [nnabla]: epoch 54 of 100 cost=0.406811  time=(3.1s /5.8s) 
2024-01-28 22:25:59,629 [nnabla]: epoch 55 of 100 cost=0.390645  time=(3.2s /5.8s) 
2024-01-28 22:25:59,687 [nnabla]: epoch 56 of 100 cost=0.374518  time=(3.2s /5.8s) 
2024-01-28 22:25:59,732 [nnabla]: epoch 57 of 100 cost=0.370651  time=(3.3s /5.8s) 
2024-01-28 22:25:59,776 [nnabla]: epoch 58 of 100 cost=0.347160  time=(3.3s /5.8s) 
2024-01-28 22:25:59,821 [nnabla]: epoch 59 of 100 cost=0.337175  time=(3.4s /5.7s) 
2024-01-28 22:25:59,926 [nnabla]: epoch 60 of 100 cost=0.320701  {train_error=0.248385, valid_error=0.249997} time=(3.4s /5.7s) 
2024-01-28 22:25:59,970 [nnabla]: epoch 61 of 100 cost=0.316420  time=(3.5s /5.8s) 
2024-01-28 22:26:00,018 [nnabla]: epoch 62 of 100 cost=0.313674  time=(3.6s /5.8s) 
2024-01-28 22:26:00,061 [nnabla]: epoch 63 of 100 cost=0.296653  time=(3.6s /5.8s) 
2024-01-28 22:26:00,106 [nnabla]: epoch 64 of 100 cost=0.289684  time=(3.7s /5.7s) 
2024-01-28 22:26:00,151 [nnabla]: epoch 65 of 100 cost=0.274976  time=(3.7s /5.7s) 
2024-01-28 22:26:00,197 [nnabla]: epoch 66 of 100 cost=0.274488  time=(3.8s /5.7s) 
2024-01-28 22:26:00,249 [nnabla]: epoch 67 of 100 cost=0.259983  time=(3.8s /5.7s) 
2024-01-28 22:26:00,295 [nnabla]: epoch 68 of 100 cost=0.249754  time=(3.9s /5.7s) 
2024-01-28 22:26:00,339 [nnabla]: epoch 69 of 100 cost=0.243086  time=(3.9s /5.7s) 
2024-01-28 22:26:00,442 [nnabla]: epoch 70 of 100 cost=0.243300  {train_error=0.172298, valid_error=0.176561} time=(3.9s /5.6s) 
2024-01-28 22:26:00,488 [nnabla]: epoch 71 of 100 cost=0.229415  time=(4.1s /5.7s) 
2024-01-28 22:26:00,532 [nnabla]: epoch 72 of 100 cost=0.222096  time=(4.1s /5.7s) 
2024-01-28 22:26:00,576 [nnabla]: epoch 73 of 100 cost=0.219055  time=(4.1s /5.7s) 
2024-01-28 22:26:00,620 [nnabla]: epoch 74 of 100 cost=0.211087  time=(4.2s /5.7s) 
2024-01-28 22:26:00,666 [nnabla]: epoch 75 of 100 cost=0.199899  time=(4.2s /5.6s) 
2024-01-28 22:26:00,710 [nnabla]: epoch 76 of 100 cost=0.194495  time=(4.3s /5.6s) 
2024-01-28 22:26:00,756 [nnabla]: epoch 77 of 100 cost=0.189854  time=(4.3s /5.6s) 
2024-01-28 22:26:00,810 [nnabla]: epoch 78 of 100 cost=0.188886  time=(4.4s /5.6s) 
2024-01-28 22:26:00,855 [nnabla]: epoch 79 of 100 cost=0.177919  time=(4.4s /5.6s) 
2024-01-28 22:26:00,956 [nnabla]: epoch 80 of 100 cost=0.175028  {train_error=0.124646, valid_error=0.128549} time=(4.5s /5.6s) 
2024-01-28 22:26:01,001 [nnabla]: epoch 81 of 100 cost=0.177720  time=(4.6s /5.6s) 
2024-01-28 22:26:01,046 [nnabla]: epoch 82 of 100 cost=0.172025  time=(4.6s /5.6s) 
2024-01-28 22:26:01,090 [nnabla]: epoch 83 of 100 cost=0.162256  time=(4.7s /5.6s) 
2024-01-28 22:26:01,136 [nnabla]: epoch 84 of 100 cost=0.157708  time=(4.7s /5.6s) 
2024-01-28 22:26:01,182 [nnabla]: epoch 85 of 100 cost=0.150392  time=(4.7s /5.6s) 
2024-01-28 22:26:01,226 [nnabla]: epoch 86 of 100 cost=0.156641  time=(4.8s /5.6s) 
2024-01-28 22:26:01,272 [nnabla]: epoch 87 of 100 cost=0.149035  time=(4.8s /5.6s) 
2024-01-28 22:26:01,318 [nnabla]: epoch 88 of 100 cost=0.148634  time=(4.9s /5.5s) 
2024-01-28 22:26:01,374 [nnabla]: epoch 89 of 100 cost=0.144423  time=(4.9s /5.5s) 
2024-01-28 22:26:01,476 [nnabla]: epoch 90 of 100 cost=0.138371  {train_error=0.097072, valid_error=0.100995} time=(5.0s /5.5s) 
2024-01-28 22:26:01,522 [nnabla]: epoch 91 of 100 cost=0.138179  time=(5.1s /5.6s) 
2024-01-28 22:26:01,567 [nnabla]: epoch 92 of 100 cost=0.127533  time=(5.1s /5.6s) 
2024-01-28 22:26:01,612 [nnabla]: epoch 93 of 100 cost=0.131559  time=(5.2s /5.6s) 
2024-01-28 22:26:01,656 [nnabla]: epoch 94 of 100 cost=0.123234  time=(5.2s /5.6s) 
2024-01-28 22:26:01,702 [nnabla]: epoch 95 of 100 cost=0.125575  time=(5.3s /5.5s) 
2024-01-28 22:26:01,747 [nnabla]: epoch 96 of 100 cost=0.115610  time=(5.3s /5.5s) 
2024-01-28 22:26:01,791 [nnabla]: epoch 97 of 100 cost=0.116400  time=(5.4s /5.5s) 
2024-01-28 22:26:01,836 [nnabla]: epoch 98 of 100 cost=0.107913  time=(5.4s /5.5s) 
2024-01-28 22:26:01,881 [nnabla]: epoch 99 of 100 cost=0.112440  time=(5.4s /5.5s) 
2024-01-28 22:26:02,000 [nnabla]: epoch 100 of 100 cost=0.105077  {train_error=0.070944, valid_error=0.073660} time=(5.5s /5.5s) 
2024-01-28 22:26:02,016 [nnabla]: Training Completed.
NNabla command line interface (Version:1.33.1, Build:230206070804, Callback:NNabla SSH callback module.)

2024-01-28 22:33:31,061 Training process is started.
python "C:\Users\yamas\Desktop\tools\neural_network_console\libs\Python\Lib\site-packages\nnabla\utils\cli\cli.py" train
	-c "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_223331\net.nntxt"
	-o "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_223331"
2024-01-28 22:33:31,612 [nnabla]: [CALLBACK]: Exec train on local
2024-01-28 22:33:31,619 [nnabla]: Using context "Context(backend=['cpu:float'], array_class='CpuCachedArray', device_id='')"
2024-01-28 22:33:31,619 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_test_3class_onsen.csv"
2024-01-28 22:33:32,209 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_valid_3class_onsen.csv"
2024-01-28 22:33:32,597 [nnabla]: Train with contexts ['cpu']
2024-01-28 22:33:32,621 [nnabla]: Training epoch 1 of 100 begin
2024-01-28 22:33:32,621 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 22:33:32,621 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 22:33:32,803 [nnabla]: epoch 1 of 100 cost=4.552331  {train_error=3.994563, valid_error=3.970888} time=(0.1s /6.8s) 
2024-01-28 22:33:32,889 [nnabla]: epoch 2 of 100 cost=4.129805  {train_error=3.775381, valid_error=3.749225} time=(0.2s /11.1s) 
2024-01-28 22:33:32,971 [nnabla]: epoch 3 of 100 cost=3.853223  {train_error=3.609166, valid_error=3.583048} time=(0.3s /10.3s) 
2024-01-28 22:33:33,053 [nnabla]: epoch 4 of 100 cost=3.608819  {train_error=3.304253, valid_error=3.286053} time=(0.4s /9.7s) 
2024-01-28 22:33:33,143 [nnabla]: epoch 5 of 100 cost=3.340481  {train_error=3.133342, valid_error=3.130059} time=(0.5s /9.4s) 
2024-01-28 22:33:33,183 [nnabla]: epoch 6 of 100 cost=3.138684  time=(0.6s /9.4s) 
2024-01-28 22:33:33,223 [nnabla]: epoch 7 of 100 cost=2.964280  time=(0.6s /8.6s) 
2024-01-28 22:33:33,264 [nnabla]: epoch 8 of 100 cost=2.812708  time=(0.6s /8.0s) 
2024-01-28 22:33:33,303 [nnabla]: epoch 9 of 100 cost=2.699714  time=(0.7s /7.6s) 
2024-01-28 22:33:33,396 [nnabla]: epoch 10 of 100 cost=2.581805  {train_error=2.339059, valid_error=2.345964} time=(0.7s /7.2s) 
2024-01-28 22:33:33,437 [nnabla]: epoch 11 of 100 cost=2.467967  time=(0.8s /7.4s) 
2024-01-28 22:33:33,488 [nnabla]: epoch 12 of 100 cost=2.366386  time=(0.9s /7.1s) 
2024-01-28 22:33:33,528 [nnabla]: epoch 13 of 100 cost=2.262247  time=(0.9s /7.0s) 
2024-01-28 22:33:33,568 [nnabla]: epoch 14 of 100 cost=2.189604  time=(0.9s /6.8s) 
2024-01-28 22:33:33,609 [nnabla]: epoch 15 of 100 cost=2.107276  time=(1.0s /6.6s) 
2024-01-28 22:33:33,652 [nnabla]: epoch 16 of 100 cost=2.023338  time=(1.0s /6.4s) 
2024-01-28 22:33:33,690 [nnabla]: epoch 17 of 100 cost=1.925132  time=(1.1s /6.3s) 
2024-01-28 22:33:33,729 [nnabla]: epoch 18 of 100 cost=1.862410  time=(1.1s /6.2s) 
2024-01-28 22:33:33,770 [nnabla]: epoch 19 of 100 cost=1.776094  time=(1.1s /6.0s) 
2024-01-28 22:33:33,862 [nnabla]: epoch 20 of 100 cost=1.717693  {train_error=1.508590, valid_error=1.526909} time=(1.2s /5.9s) 
2024-01-28 22:33:33,905 [nnabla]: epoch 21 of 100 cost=1.628490  time=(1.3s /6.1s) 
2024-01-28 22:33:33,945 [nnabla]: epoch 22 of 100 cost=1.575471  time=(1.3s /6.0s) 
2024-01-28 22:33:33,995 [nnabla]: epoch 23 of 100 cost=1.498769  time=(1.4s /5.9s) 
2024-01-28 22:33:34,034 [nnabla]: epoch 24 of 100 cost=1.427453  time=(1.4s /5.9s) 
2024-01-28 22:33:34,074 [nnabla]: epoch 25 of 100 cost=1.381343  time=(1.5s /5.8s) 
2024-01-28 22:33:34,113 [nnabla]: epoch 26 of 100 cost=1.309345  time=(1.5s /5.7s) 
2024-01-28 22:33:34,155 [nnabla]: epoch 27 of 100 cost=1.276071  time=(1.5s /5.7s) 
2024-01-28 22:33:34,194 [nnabla]: epoch 28 of 100 cost=1.206549  time=(1.6s /5.6s) 
2024-01-28 22:33:34,235 [nnabla]: epoch 29 of 100 cost=1.153608  time=(1.6s /5.6s) 
2024-01-28 22:33:34,325 [nnabla]: epoch 30 of 100 cost=1.108957  {train_error=0.941122, valid_error=0.953071} time=(1.7s /5.5s) 
2024-01-28 22:33:34,365 [nnabla]: epoch 31 of 100 cost=1.055356  time=(1.7s /5.6s) 
2024-01-28 22:33:34,407 [nnabla]: epoch 32 of 100 cost=1.012600  time=(1.8s /5.6s) 
2024-01-28 22:33:34,446 [nnabla]: epoch 33 of 100 cost=0.944957  time=(1.8s /5.5s) 
2024-01-28 22:33:34,496 [nnabla]: epoch 34 of 100 cost=0.926172  time=(1.9s /5.5s) 
2024-01-28 22:33:34,536 [nnabla]: epoch 35 of 100 cost=0.874500  time=(1.9s /5.5s) 
2024-01-28 22:33:34,579 [nnabla]: epoch 36 of 100 cost=0.834536  time=(2.0s /5.4s) 
2024-01-28 22:33:34,617 [nnabla]: epoch 37 of 100 cost=0.815198  time=(2.0s /5.4s) 
2024-01-28 22:33:34,657 [nnabla]: epoch 38 of 100 cost=0.787294  time=(2.0s /5.4s) 
2024-01-28 22:33:34,696 [nnabla]: epoch 39 of 100 cost=0.737560  time=(2.1s /5.3s) 
2024-01-28 22:33:34,788 [nnabla]: epoch 40 of 100 cost=0.721740  {train_error=0.538874, valid_error=0.544786} time=(2.1s /5.3s) 
2024-01-28 22:33:34,829 [nnabla]: epoch 41 of 100 cost=0.669371  time=(2.2s /5.4s) 
2024-01-28 22:33:34,868 [nnabla]: epoch 42 of 100 cost=0.655387  time=(2.2s /5.3s) 
2024-01-28 22:33:34,907 [nnabla]: epoch 43 of 100 cost=0.630844  time=(2.3s /5.3s) 
2024-01-28 22:33:34,947 [nnabla]: epoch 44 of 100 cost=0.598179  time=(2.3s /5.3s) 
2024-01-28 22:33:35,006 [nnabla]: epoch 45 of 100 cost=0.568203  time=(2.4s /5.3s) 
2024-01-28 22:33:35,050 [nnabla]: epoch 46 of 100 cost=0.560876  time=(2.4s /5.3s) 
2024-01-28 22:33:35,089 [nnabla]: epoch 47 of 100 cost=0.531155  time=(2.5s /5.3s) 
2024-01-28 22:33:35,129 [nnabla]: epoch 48 of 100 cost=0.508223  time=(2.5s /5.2s) 
2024-01-28 22:33:35,169 [nnabla]: epoch 49 of 100 cost=0.489593  time=(2.5s /5.2s) 
2024-01-28 22:33:35,260 [nnabla]: epoch 50 of 100 cost=0.469051  {train_error=0.337427, valid_error=0.343523} time=(2.6s /5.2s) 
2024-01-28 22:33:35,300 [nnabla]: epoch 51 of 100 cost=0.460976  time=(2.7s /5.3s) 
2024-01-28 22:33:35,340 [nnabla]: epoch 52 of 100 cost=0.438647  time=(2.7s /5.2s) 
2024-01-28 22:33:35,379 [nnabla]: epoch 53 of 100 cost=0.421160  time=(2.8s /5.2s) 
2024-01-28 22:33:35,420 [nnabla]: epoch 54 of 100 cost=0.408794  time=(2.8s /5.2s) 
2024-01-28 22:33:35,463 [nnabla]: epoch 55 of 100 cost=0.397996  time=(2.8s /5.2s) 
2024-01-28 22:33:35,515 [nnabla]: epoch 56 of 100 cost=0.377774  time=(2.9s /5.2s) 
2024-01-28 22:33:35,554 [nnabla]: epoch 57 of 100 cost=0.374172  time=(2.9s /5.1s) 
2024-01-28 22:33:35,595 [nnabla]: epoch 58 of 100 cost=0.345822  time=(3.0s /5.1s) 
2024-01-28 22:33:35,635 [nnabla]: epoch 59 of 100 cost=0.340621  time=(3.0s /5.1s) 
2024-01-28 22:33:35,731 [nnabla]: epoch 60 of 100 cost=0.331055  {train_error=0.231738, valid_error=0.234837} time=(3.1s /5.1s) 
2024-01-28 22:33:35,772 [nnabla]: epoch 61 of 100 cost=0.328546  time=(3.2s /5.2s) 
2024-01-28 22:33:35,811 [nnabla]: epoch 62 of 100 cost=0.315415  time=(3.2s /5.1s) 
2024-01-28 22:33:35,851 [nnabla]: epoch 63 of 100 cost=0.306011  time=(3.2s /5.1s) 
2024-01-28 22:33:35,892 [nnabla]: epoch 64 of 100 cost=0.300927  time=(3.3s /5.1s) 
2024-01-28 22:33:35,931 [nnabla]: epoch 65 of 100 cost=0.287834  time=(3.3s /5.1s) 
2024-01-28 22:33:35,973 [nnabla]: epoch 66 of 100 cost=0.286604  time=(3.4s /5.1s) 
2024-01-28 22:33:36,028 [nnabla]: epoch 67 of 100 cost=0.268070  time=(3.4s /5.1s) 
2024-01-28 22:33:36,066 [nnabla]: epoch 68 of 100 cost=0.252155  time=(3.4s /5.1s) 
2024-01-28 22:33:36,105 [nnabla]: epoch 69 of 100 cost=0.255175  time=(3.5s /5.0s) 
2024-01-28 22:33:36,200 [nnabla]: epoch 70 of 100 cost=0.251417  {train_error=0.154477, valid_error=0.156039} time=(3.5s /5.0s) 
2024-01-28 22:33:36,241 [nnabla]: epoch 71 of 100 cost=0.233809  time=(3.6s /5.1s) 
2024-01-28 22:33:36,283 [nnabla]: epoch 72 of 100 cost=0.239406  time=(3.7s /5.1s) 
2024-01-28 22:33:36,323 [nnabla]: epoch 73 of 100 cost=0.234835  time=(3.7s /5.1s) 
2024-01-28 22:33:36,363 [nnabla]: epoch 74 of 100 cost=0.220135  time=(3.7s /5.1s) 
2024-01-28 22:33:36,403 [nnabla]: epoch 75 of 100 cost=0.212153  time=(3.8s /5.0s) 
2024-01-28 22:33:36,444 [nnabla]: epoch 76 of 100 cost=0.213761  time=(3.8s /5.0s) 
2024-01-28 22:33:36,485 [nnabla]: epoch 77 of 100 cost=0.200156  time=(3.9s /5.0s) 
2024-01-28 22:33:36,533 [nnabla]: epoch 78 of 100 cost=0.199266  time=(3.9s /5.0s) 
2024-01-28 22:33:36,573 [nnabla]: epoch 79 of 100 cost=0.192767  time=(4.0s /5.0s) 
2024-01-28 22:33:36,664 [nnabla]: epoch 80 of 100 cost=0.195895  {train_error=0.117141, valid_error=0.118748} time=(4.0s /5.0s) 
2024-01-28 22:33:36,705 [nnabla]: epoch 81 of 100 cost=0.182729  time=(4.1s /5.0s) 
2024-01-28 22:33:36,745 [nnabla]: epoch 82 of 100 cost=0.190404  time=(4.1s /5.0s) 
2024-01-28 22:33:36,785 [nnabla]: epoch 83 of 100 cost=0.180610  time=(4.2s /5.0s) 
2024-01-28 22:33:36,825 [nnabla]: epoch 84 of 100 cost=0.173290  time=(4.2s /5.0s) 
2024-01-28 22:33:36,864 [nnabla]: epoch 85 of 100 cost=0.157862  time=(4.2s /5.0s) 
2024-01-28 22:33:36,905 [nnabla]: epoch 86 of 100 cost=0.168852  time=(4.3s /5.0s) 
2024-01-28 22:33:36,946 [nnabla]: epoch 87 of 100 cost=0.161155  time=(4.3s /5.0s) 
2024-01-28 22:33:36,985 [nnabla]: epoch 88 of 100 cost=0.176785  time=(4.4s /5.0s) 
2024-01-28 22:33:37,036 [nnabla]: epoch 89 of 100 cost=0.153721  time=(4.4s /4.9s) 
2024-01-28 22:33:37,126 [nnabla]: epoch 90 of 100 cost=0.151447  {train_error=0.088998, valid_error=0.090125} time=(4.5s /4.9s) 
2024-01-28 22:33:37,167 [nnabla]: epoch 91 of 100 cost=0.156901  time=(4.5s /5.0s) 
2024-01-28 22:33:37,207 [nnabla]: epoch 92 of 100 cost=0.137988  time=(4.6s /5.0s) 
2024-01-28 22:33:37,247 [nnabla]: epoch 93 of 100 cost=0.149354  time=(4.6s /5.0s) 
2024-01-28 22:33:37,287 [nnabla]: epoch 94 of 100 cost=0.134466  time=(4.7s /5.0s) 
2024-01-28 22:33:37,327 [nnabla]: epoch 95 of 100 cost=0.154780  time=(4.7s /5.0s) 
2024-01-28 22:33:37,366 [nnabla]: epoch 96 of 100 cost=0.124839  time=(4.7s /4.9s) 
2024-01-28 22:33:37,406 [nnabla]: epoch 97 of 100 cost=0.129211  time=(4.8s /4.9s) 
2024-01-28 22:33:37,445 [nnabla]: epoch 98 of 100 cost=0.117871  time=(4.8s /4.9s) 
2024-01-28 22:33:37,486 [nnabla]: epoch 99 of 100 cost=0.134578  time=(4.9s /4.9s) 
2024-01-28 22:33:37,594 [nnabla]: epoch 100 of 100 cost=0.119974  {train_error=0.070430, valid_error=0.071345} time=(4.9s /4.9s) 
2024-01-28 22:33:37,612 [nnabla]: Training Completed.
NNabla command line interface (Version:1.33.1, Build:230206070804, Callback:NNabla SSH callback module.)

2024-01-28 22:32:31,067 Training process is started.
python "C:\Users\yamas\Desktop\tools\neural_network_console\libs\Python\Lib\site-packages\nnabla\utils\cli\cli.py" train
	-c "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_223231\net.nntxt"
	-o "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_223231"
2024-01-28 22:32:31,616 [nnabla]: [CALLBACK]: Exec train on local
2024-01-28 22:32:31,624 [nnabla]: Using context "Context(backend=['cpu:float'], array_class='CpuCachedArray', device_id='')"
2024-01-28 22:32:31,624 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_test_3class_onsen.csv"
2024-01-28 22:32:32,210 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_valid_3class_onsen.csv"
2024-01-28 22:32:32,602 [nnabla]: Train with contexts ['cpu']
2024-01-28 22:32:32,629 [nnabla]: Training epoch 1 of 100 begin
2024-01-28 22:32:32,630 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 22:32:32,630 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 22:32:32,827 [nnabla]: epoch 1 of 100 cost=4.805449  {train_error=4.091901, valid_error=4.087127} time=(0.1s /8.2s) 
2024-01-28 22:32:32,922 [nnabla]: epoch 2 of 100 cost=4.121885  {train_error=3.591679, valid_error=3.579557} time=(0.2s /12.0s) 
2024-01-28 22:32:33,013 [nnabla]: epoch 3 of 100 cost=3.748976  {train_error=3.335429, valid_error=3.322772} time=(0.3s /11.2s) 
2024-01-28 22:32:33,106 [nnabla]: epoch 4 of 100 cost=3.439789  {train_error=3.049085, valid_error=3.034365} time=(0.4s /10.7s) 
2024-01-28 22:32:33,213 [nnabla]: epoch 5 of 100 cost=3.180433  {train_error=2.903456, valid_error=2.898750} time=(0.5s /10.4s) 
2024-01-28 22:32:33,256 [nnabla]: epoch 6 of 100 cost=3.000030  time=(0.6s /10.4s) 
2024-01-28 22:32:33,301 [nnabla]: epoch 7 of 100 cost=2.880382  time=(0.7s /9.6s) 
2024-01-28 22:32:33,344 [nnabla]: epoch 8 of 100 cost=2.762774  time=(0.7s /8.9s) 
2024-01-28 22:32:33,387 [nnabla]: epoch 9 of 100 cost=2.650477  time=(0.8s /8.4s) 
2024-01-28 22:32:33,487 [nnabla]: epoch 10 of 100 cost=2.544155  {train_error=2.296858, valid_error=2.286950} time=(0.8s /8.0s) 
2024-01-28 22:32:33,530 [nnabla]: epoch 11 of 100 cost=2.448745  time=(0.9s /8.2s) 
2024-01-28 22:32:33,582 [nnabla]: epoch 12 of 100 cost=2.345766  time=(0.9s /7.9s) 
2024-01-28 22:32:33,626 [nnabla]: epoch 13 of 100 cost=2.278038  time=(1.0s /7.7s) 
2024-01-28 22:32:33,669 [nnabla]: epoch 14 of 100 cost=2.184163  time=(1.0s /7.4s) 
2024-01-28 22:32:33,712 [nnabla]: epoch 15 of 100 cost=2.094723  time=(1.1s /7.2s) 
2024-01-28 22:32:33,755 [nnabla]: epoch 16 of 100 cost=2.012350  time=(1.1s /7.0s) 
2024-01-28 22:32:33,802 [nnabla]: epoch 17 of 100 cost=1.931268  time=(1.2s /6.9s) 
2024-01-28 22:32:33,846 [nnabla]: epoch 18 of 100 cost=1.866883  time=(1.2s /6.8s) 
2024-01-28 22:32:33,890 [nnabla]: epoch 19 of 100 cost=1.773288  time=(1.3s /6.6s) 
2024-01-28 22:32:33,990 [nnabla]: epoch 20 of 100 cost=1.720660  {train_error=1.485081, valid_error=1.492086} time=(1.3s /6.5s) 
2024-01-28 22:32:34,035 [nnabla]: epoch 21 of 100 cost=1.627017  time=(1.4s /6.7s) 
2024-01-28 22:32:34,079 [nnabla]: epoch 22 of 100 cost=1.562716  time=(1.4s /6.6s) 
2024-01-28 22:32:34,131 [nnabla]: epoch 23 of 100 cost=1.505528  time=(1.5s /6.5s) 
2024-01-28 22:32:34,175 [nnabla]: epoch 24 of 100 cost=1.432066  time=(1.5s /6.4s) 
2024-01-28 22:32:34,218 [nnabla]: epoch 25 of 100 cost=1.386525  time=(1.6s /6.4s) 
2024-01-28 22:32:34,260 [nnabla]: epoch 26 of 100 cost=1.313042  time=(1.6s /6.3s) 
2024-01-28 22:32:34,303 [nnabla]: epoch 27 of 100 cost=1.277437  time=(1.7s /6.2s) 
2024-01-28 22:32:34,346 [nnabla]: epoch 28 of 100 cost=1.218163  time=(1.7s /6.1s) 
2024-01-28 22:32:34,389 [nnabla]: epoch 29 of 100 cost=1.171049  time=(1.8s /6.1s) 
2024-01-28 22:32:34,490 [nnabla]: epoch 30 of 100 cost=1.114498  {train_error=0.910664, valid_error=0.924317} time=(1.8s /6.0s) 
2024-01-28 22:32:34,533 [nnabla]: epoch 31 of 100 cost=1.079909  time=(1.9s /6.1s) 
2024-01-28 22:32:34,577 [nnabla]: epoch 32 of 100 cost=1.021130  time=(1.9s /6.1s) 
2024-01-28 22:32:34,620 [nnabla]: epoch 33 of 100 cost=0.971118  time=(2.0s /6.0s) 
2024-01-28 22:32:34,673 [nnabla]: epoch 34 of 100 cost=0.953445  time=(2.0s /6.0s) 
2024-01-28 22:32:34,716 [nnabla]: epoch 35 of 100 cost=0.896718  time=(2.1s /6.0s) 
2024-01-28 22:32:34,759 [nnabla]: epoch 36 of 100 cost=0.866137  time=(2.1s /5.9s) 
2024-01-28 22:32:34,802 [nnabla]: epoch 37 of 100 cost=0.842634  time=(2.2s /5.9s) 
2024-01-28 22:32:34,846 [nnabla]: epoch 38 of 100 cost=0.804681  time=(2.2s /5.8s) 
2024-01-28 22:32:34,888 [nnabla]: epoch 39 of 100 cost=0.762519  time=(2.3s /5.8s) 
2024-01-28 22:32:34,990 [nnabla]: epoch 40 of 100 cost=0.738475  {train_error=0.559055, valid_error=0.569819} time=(2.3s /5.8s) 
2024-01-28 22:32:35,033 [nnabla]: epoch 41 of 100 cost=0.700466  time=(2.4s /5.9s) 
2024-01-28 22:32:35,076 [nnabla]: epoch 42 of 100 cost=0.673199  time=(2.4s /5.8s) 
2024-01-28 22:32:35,120 [nnabla]: epoch 43 of 100 cost=0.656173  time=(2.5s /5.8s) 
2024-01-28 22:32:35,162 [nnabla]: epoch 44 of 100 cost=0.627294  time=(2.5s /5.8s) 
2024-01-28 22:32:35,224 [nnabla]: epoch 45 of 100 cost=0.592995  time=(2.6s /5.7s) 
2024-01-28 22:32:35,268 [nnabla]: epoch 46 of 100 cost=0.602641  time=(2.6s /5.7s) 
2024-01-28 22:32:35,311 [nnabla]: epoch 47 of 100 cost=0.562671  time=(2.7s /5.7s) 
2024-01-28 22:32:35,354 [nnabla]: epoch 48 of 100 cost=0.537350  time=(2.7s /5.7s) 
2024-01-28 22:32:35,397 [nnabla]: epoch 49 of 100 cost=0.512966  time=(2.8s /5.6s) 
2024-01-28 22:32:35,497 [nnabla]: epoch 50 of 100 cost=0.501643  {train_error=0.353566, valid_error=0.366811} time=(2.8s /5.6s) 
2024-01-28 22:32:35,540 [nnabla]: epoch 51 of 100 cost=0.497683  time=(2.9s /5.7s) 
2024-01-28 22:32:35,582 [nnabla]: epoch 52 of 100 cost=0.474508  time=(3.0s /5.7s) 
2024-01-28 22:32:35,625 [nnabla]: epoch 53 of 100 cost=0.458822  time=(3.0s /5.7s) 
2024-01-28 22:32:35,669 [nnabla]: epoch 54 of 100 cost=0.450833  time=(3.0s /5.6s) 
2024-01-28 22:32:35,711 [nnabla]: epoch 55 of 100 cost=0.431578  time=(3.1s /5.6s) 
2024-01-28 22:32:35,764 [nnabla]: epoch 56 of 100 cost=0.401923  time=(3.1s /5.6s) 
2024-01-28 22:32:35,807 [nnabla]: epoch 57 of 100 cost=0.401835  time=(3.2s /5.6s) 
2024-01-28 22:32:35,850 [nnabla]: epoch 58 of 100 cost=0.383241  time=(3.2s /5.6s) 
2024-01-28 22:32:35,896 [nnabla]: epoch 59 of 100 cost=0.359569  time=(3.3s /5.5s) 
2024-01-28 22:32:36,009 [nnabla]: epoch 60 of 100 cost=0.346378  {train_error=0.227567, valid_error=0.232358} time=(3.3s /5.5s) 
2024-01-28 22:32:36,052 [nnabla]: epoch 61 of 100 cost=0.348251  time=(3.4s /5.6s) 
2024-01-28 22:32:36,097 [nnabla]: epoch 62 of 100 cost=0.350728  time=(3.5s /5.6s) 
2024-01-28 22:32:36,143 [nnabla]: epoch 63 of 100 cost=0.323138  time=(3.5s /5.6s) 
2024-01-28 22:32:36,186 [nnabla]: epoch 64 of 100 cost=0.327725  time=(3.6s /5.6s) 
2024-01-28 22:32:36,229 [nnabla]: epoch 65 of 100 cost=0.312296  time=(3.6s /5.5s) 
2024-01-28 22:32:36,271 [nnabla]: epoch 66 of 100 cost=0.321564  time=(3.6s /5.5s) 
2024-01-28 22:32:36,326 [nnabla]: epoch 67 of 100 cost=0.295653  time=(3.7s /5.5s) 
2024-01-28 22:32:36,371 [nnabla]: epoch 68 of 100 cost=0.280101  time=(3.7s /5.5s) 
2024-01-28 22:32:36,415 [nnabla]: epoch 69 of 100 cost=0.285744  time=(3.8s /5.5s) 
2024-01-28 22:32:36,517 [nnabla]: epoch 70 of 100 cost=0.281258  {train_error=0.160071, valid_error=0.165575} time=(3.8s /5.5s) 
2024-01-28 22:32:36,561 [nnabla]: epoch 71 of 100 cost=0.274992  time=(3.9s /5.5s) 
2024-01-28 22:32:36,604 [nnabla]: epoch 72 of 100 cost=0.249633  time=(4.0s /5.5s) 
2024-01-28 22:32:36,646 [nnabla]: epoch 73 of 100 cost=0.260296  time=(4.0s /5.5s) 
2024-01-28 22:32:36,693 [nnabla]: epoch 74 of 100 cost=0.241679  time=(4.1s /5.5s) 
2024-01-28 22:32:36,735 [nnabla]: epoch 75 of 100 cost=0.238633  time=(4.1s /5.5s) 
2024-01-28 22:32:36,777 [nnabla]: epoch 76 of 100 cost=0.230695  time=(4.1s /5.5s) 
2024-01-28 22:32:36,821 [nnabla]: epoch 77 of 100 cost=0.222341  time=(4.2s /5.4s) 
2024-01-28 22:32:36,872 [nnabla]: epoch 78 of 100 cost=0.220991  time=(4.2s /5.4s) 
2024-01-28 22:32:36,917 [nnabla]: epoch 79 of 100 cost=0.225511  time=(4.3s /5.4s) 
2024-01-28 22:32:37,014 [nnabla]: epoch 80 of 100 cost=0.210683  {train_error=0.112908, valid_error=0.117251} time=(4.3s /5.4s) 
2024-01-28 22:32:37,058 [nnabla]: epoch 81 of 100 cost=0.209326  time=(4.4s /5.5s) 
2024-01-28 22:32:37,102 [nnabla]: epoch 82 of 100 cost=0.208680  time=(4.5s /5.5s) 
2024-01-28 22:32:37,144 [nnabla]: epoch 83 of 100 cost=0.197173  time=(4.5s /5.4s) 
2024-01-28 22:32:37,187 [nnabla]: epoch 84 of 100 cost=0.193574  time=(4.6s /5.4s) 
2024-01-28 22:32:37,230 [nnabla]: epoch 85 of 100 cost=0.178184  time=(4.6s /5.4s) 
2024-01-28 22:32:37,273 [nnabla]: epoch 86 of 100 cost=0.189579  time=(4.6s /5.4s) 
2024-01-28 22:32:37,317 [nnabla]: epoch 87 of 100 cost=0.176554  time=(4.7s /5.4s) 
2024-01-28 22:32:37,361 [nnabla]: epoch 88 of 100 cost=0.205557  time=(4.7s /5.4s) 
2024-01-28 22:32:37,414 [nnabla]: epoch 89 of 100 cost=0.178626  time=(4.8s /5.4s) 
2024-01-28 22:32:37,512 [nnabla]: epoch 90 of 100 cost=0.179466  {train_error=0.089334, valid_error=0.093817} time=(4.8s /5.4s) 
2024-01-28 22:32:37,555 [nnabla]: epoch 91 of 100 cost=0.169477  time=(4.9s /5.4s) 
2024-01-28 22:32:37,598 [nnabla]: epoch 92 of 100 cost=0.162287  time=(5.0s /5.4s) 
2024-01-28 22:32:37,641 [nnabla]: epoch 93 of 100 cost=0.171841  time=(5.0s /5.4s) 
2024-01-28 22:32:37,684 [nnabla]: epoch 94 of 100 cost=0.149363  time=(5.1s /5.4s) 
2024-01-28 22:32:37,726 [nnabla]: epoch 95 of 100 cost=0.168156  time=(5.1s /5.4s) 
2024-01-28 22:32:37,770 [nnabla]: epoch 96 of 100 cost=0.145585  time=(5.1s /5.4s) 
2024-01-28 22:32:37,812 [nnabla]: epoch 97 of 100 cost=0.154608  time=(5.2s /5.3s) 
2024-01-28 22:32:37,856 [nnabla]: epoch 98 of 100 cost=0.138309  time=(5.2s /5.3s) 
2024-01-28 22:32:37,898 [nnabla]: epoch 99 of 100 cost=0.148655  time=(5.3s /5.3s) 
2024-01-28 22:32:38,015 [nnabla]: epoch 100 of 100 cost=0.152271  {train_error=0.070938, valid_error=0.074706} time=(5.3s /5.3s) 
2024-01-28 22:32:38,034 [nnabla]: Training Completed.
NNabla command line interface (Version:1.33.1, Build:230206070804, Callback:NNabla SSH callback module.)

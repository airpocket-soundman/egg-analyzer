2024-01-28 21:15:06,784 Training process is started.
python "C:\Users\yamas\Desktop\tools\neural_network_console\libs\Python\Lib\site-packages\nnabla\utils\cli\cli.py" train
	-c "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_211506\net.nntxt"
	-o "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_211506"
2024-01-28 21:15:07,326 [nnabla]: [CALLBACK]: Exec train on local
2024-01-28 21:15:07,333 [nnabla]: Using context "Context(backend=['cpu:float'], array_class='CpuCachedArray', device_id='')"
2024-01-28 21:15:07,333 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_test_3class_onsen.csv"
2024-01-28 21:15:07,926 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_valid_3class_onsen.csv"
2024-01-28 21:15:08,322 [nnabla]: Train with contexts ['cpu']
2024-01-28 21:15:08,346 [nnabla]: Training epoch 1 of 100 begin
2024-01-28 21:15:08,346 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 21:15:08,346 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 21:15:08,553 [nnabla]: epoch 1 of 100 cost=4.551032  {train_error=4.489400, valid_error=4.489168} time=(0.1s /9.1s) 
2024-01-28 21:15:08,635 [nnabla]: epoch 2 of 100 cost=4.431799  {train_error=4.369644, valid_error=4.369281} time=(0.2s /12.1s) 
2024-01-28 21:15:08,720 [nnabla]: epoch 3 of 100 cost=4.311240  {train_error=4.247862, valid_error=4.247310} time=(0.3s /10.9s) 
2024-01-28 21:15:08,806 [nnabla]: epoch 4 of 100 cost=4.187764  {train_error=4.122576, valid_error=4.121910} time=(0.4s /10.3s) 
2024-01-28 21:15:08,899 [nnabla]: epoch 5 of 100 cost=4.060261  {train_error=3.992428, valid_error=3.991605} time=(0.5s /9.9s) 
2024-01-28 21:15:08,936 [nnabla]: epoch 6 of 100 cost=3.927634  time=(0.6s /9.8s) 
2024-01-28 21:15:08,973 [nnabla]: epoch 7 of 100 cost=3.788594  time=(0.6s /9.0s) 
2024-01-28 21:15:09,009 [nnabla]: epoch 8 of 100 cost=3.644252  time=(0.7s /8.3s) 
2024-01-28 21:15:09,045 [nnabla]: epoch 9 of 100 cost=3.495964  time=(0.7s /7.8s) 
2024-01-28 21:15:09,137 [nnabla]: epoch 10 of 100 cost=3.347299  {train_error=3.270415, valid_error=3.268564} time=(0.7s /7.4s) 
2024-01-28 21:15:09,174 [nnabla]: epoch 11 of 100 cost=3.199456  time=(0.8s /7.5s) 
2024-01-28 21:15:09,218 [nnabla]: epoch 12 of 100 cost=3.053641  time=(0.9s /7.2s) 
2024-01-28 21:15:09,254 [nnabla]: epoch 13 of 100 cost=2.906087  time=(0.9s /7.0s) 
2024-01-28 21:15:09,291 [nnabla]: epoch 14 of 100 cost=2.754609  time=(0.9s /6.8s) 
2024-01-28 21:15:09,328 [nnabla]: epoch 15 of 100 cost=2.601296  time=(1.0s /6.6s) 
2024-01-28 21:15:09,366 [nnabla]: epoch 16 of 100 cost=2.450924  time=(1.0s /6.4s) 
2024-01-28 21:15:09,401 [nnabla]: epoch 17 of 100 cost=2.313294  time=(1.1s /6.2s) 
2024-01-28 21:15:09,437 [nnabla]: epoch 18 of 100 cost=2.194518  time=(1.1s /6.1s) 
2024-01-28 21:15:09,472 [nnabla]: epoch 19 of 100 cost=2.093575  time=(1.1s /5.9s) 
2024-01-28 21:15:09,563 [nnabla]: epoch 20 of 100 cost=2.006376  {train_error=1.965300, valid_error=1.965902} time=(1.2s /5.8s) 
2024-01-28 21:15:09,600 [nnabla]: epoch 21 of 100 cost=1.930280  time=(1.3s /6.0s) 
2024-01-28 21:15:09,637 [nnabla]: epoch 22 of 100 cost=1.863969  time=(1.3s /5.9s) 
2024-01-28 21:15:09,680 [nnabla]: epoch 23 of 100 cost=1.805136  time=(1.3s /5.8s) 
2024-01-28 21:15:09,716 [nnabla]: epoch 24 of 100 cost=1.752929  time=(1.4s /5.7s) 
2024-01-28 21:15:09,752 [nnabla]: epoch 25 of 100 cost=1.705663  time=(1.4s /5.6s) 
2024-01-28 21:15:09,788 [nnabla]: epoch 26 of 100 cost=1.663752  time=(1.4s /5.5s) 
2024-01-28 21:15:09,824 [nnabla]: epoch 27 of 100 cost=1.625599  time=(1.5s /5.5s) 
2024-01-28 21:15:09,860 [nnabla]: epoch 28 of 100 cost=1.591362  time=(1.5s /5.4s) 
2024-01-28 21:15:09,897 [nnabla]: epoch 29 of 100 cost=1.560666  time=(1.6s /5.3s) 
2024-01-28 21:15:09,989 [nnabla]: epoch 30 of 100 cost=1.530807  {train_error=1.517685, valid_error=1.519190} time=(1.6s /5.3s) 
2024-01-28 21:15:10,025 [nnabla]: epoch 31 of 100 cost=1.506145  time=(1.7s /5.4s) 
2024-01-28 21:15:10,061 [nnabla]: epoch 32 of 100 cost=1.480806  time=(1.7s /5.4s) 
2024-01-28 21:15:10,098 [nnabla]: epoch 33 of 100 cost=1.460460  time=(1.8s /5.3s) 
2024-01-28 21:15:10,140 [nnabla]: epoch 34 of 100 cost=1.439997  time=(1.8s /5.3s) 
2024-01-28 21:15:10,177 [nnabla]: epoch 35 of 100 cost=1.421521  time=(1.8s /5.2s) 
2024-01-28 21:15:10,214 [nnabla]: epoch 36 of 100 cost=1.404195  time=(1.9s /5.2s) 
2024-01-28 21:15:10,250 [nnabla]: epoch 37 of 100 cost=1.389114  time=(1.9s /5.1s) 
2024-01-28 21:15:10,286 [nnabla]: epoch 38 of 100 cost=1.373699  time=(1.9s /5.1s) 
2024-01-28 21:15:10,322 [nnabla]: epoch 39 of 100 cost=1.360252  time=(2.0s /5.1s) 
2024-01-28 21:15:10,414 [nnabla]: epoch 40 of 100 cost=1.348315  {train_error=1.341642, valid_error=1.341381} time=(2.0s /5.0s) 
2024-01-28 21:15:10,451 [nnabla]: epoch 41 of 100 cost=1.335964  time=(2.1s /5.1s) 
2024-01-28 21:15:10,486 [nnabla]: epoch 42 of 100 cost=1.325604  time=(2.1s /5.1s) 
2024-01-28 21:15:10,521 [nnabla]: epoch 43 of 100 cost=1.315426  time=(2.2s /5.1s) 
2024-01-28 21:15:10,557 [nnabla]: epoch 44 of 100 cost=1.305832  time=(2.2s /5.0s) 
2024-01-28 21:15:10,606 [nnabla]: epoch 45 of 100 cost=1.296977  time=(2.2s /5.0s) 
2024-01-28 21:15:10,643 [nnabla]: epoch 46 of 100 cost=1.288542  time=(2.3s /5.0s) 
2024-01-28 21:15:10,680 [nnabla]: epoch 47 of 100 cost=1.280506  time=(2.3s /5.0s) 
2024-01-28 21:15:10,717 [nnabla]: epoch 48 of 100 cost=1.273277  time=(2.4s /4.9s) 
2024-01-28 21:15:10,753 [nnabla]: epoch 49 of 100 cost=1.266519  time=(2.4s /4.9s) 
2024-01-28 21:15:10,844 [nnabla]: epoch 50 of 100 cost=1.259725  {train_error=1.256699, valid_error=1.255943} time=(2.4s /4.9s) 
2024-01-28 21:15:10,880 [nnabla]: epoch 51 of 100 cost=1.253710  time=(2.5s /5.0s) 
2024-01-28 21:15:10,917 [nnabla]: epoch 52 of 100 cost=1.247828  time=(2.6s /4.9s) 
2024-01-28 21:15:10,953 [nnabla]: epoch 53 of 100 cost=1.242452  time=(2.6s /4.9s) 
2024-01-28 21:15:10,990 [nnabla]: epoch 54 of 100 cost=1.237534  time=(2.6s /4.9s) 
2024-01-28 21:15:11,026 [nnabla]: epoch 55 of 100 cost=1.232229  time=(2.7s /4.9s) 
2024-01-28 21:15:11,071 [nnabla]: epoch 56 of 100 cost=1.227607  time=(2.7s /4.8s) 
2024-01-28 21:15:11,107 [nnabla]: epoch 57 of 100 cost=1.223061  time=(2.8s /4.8s) 
2024-01-28 21:15:11,142 [nnabla]: epoch 58 of 100 cost=1.219187  time=(2.8s /4.8s) 
2024-01-28 21:15:11,182 [nnabla]: epoch 59 of 100 cost=1.214861  time=(2.8s /4.8s) 
2024-01-28 21:15:11,283 [nnabla]: epoch 60 of 100 cost=1.211232  {train_error=1.209142, valid_error=1.208871} time=(2.9s /4.8s) 
2024-01-28 21:15:11,318 [nnabla]: epoch 61 of 100 cost=1.207480  time=(3.0s /4.9s) 
2024-01-28 21:15:11,352 [nnabla]: epoch 62 of 100 cost=1.204281  time=(3.0s /4.8s) 
2024-01-28 21:15:11,388 [nnabla]: epoch 63 of 100 cost=1.200688  time=(3.0s /4.8s) 
2024-01-28 21:15:11,423 [nnabla]: epoch 64 of 100 cost=1.197705  time=(3.1s /4.8s) 
2024-01-28 21:15:11,463 [nnabla]: epoch 65 of 100 cost=1.194486  time=(3.1s /4.8s) 
2024-01-28 21:15:11,503 [nnabla]: epoch 66 of 100 cost=1.191944  time=(3.2s /4.8s) 
2024-01-28 21:15:11,545 [nnabla]: epoch 67 of 100 cost=1.189061  time=(3.2s /4.8s) 
2024-01-28 21:15:11,581 [nnabla]: epoch 68 of 100 cost=1.186320  time=(3.2s /4.8s) 
2024-01-28 21:15:11,617 [nnabla]: epoch 69 of 100 cost=1.183979  time=(3.3s /4.7s) 
2024-01-28 21:15:11,709 [nnabla]: epoch 70 of 100 cost=1.181485  {train_error=1.180241, valid_error=1.179994} time=(3.3s /4.7s) 
2024-01-28 21:15:11,749 [nnabla]: epoch 71 of 100 cost=1.179131  time=(3.4s /4.8s) 
2024-01-28 21:15:11,791 [nnabla]: epoch 72 of 100 cost=1.176892  time=(3.4s /4.8s) 
2024-01-28 21:15:11,829 [nnabla]: epoch 73 of 100 cost=1.174874  time=(3.5s /4.8s) 
2024-01-28 21:15:11,865 [nnabla]: epoch 74 of 100 cost=1.172777  time=(3.5s /4.8s) 
2024-01-28 21:15:11,902 [nnabla]: epoch 75 of 100 cost=1.170729  time=(3.6s /4.7s) 
2024-01-28 21:15:11,938 [nnabla]: epoch 76 of 100 cost=1.168946  time=(3.6s /4.7s) 
2024-01-28 21:15:11,974 [nnabla]: epoch 77 of 100 cost=1.167054  time=(3.6s /4.7s) 
2024-01-28 21:15:12,021 [nnabla]: epoch 78 of 100 cost=1.165350  time=(3.7s /4.7s) 
2024-01-28 21:15:12,059 [nnabla]: epoch 79 of 100 cost=1.163561  time=(3.7s /4.7s) 
2024-01-28 21:15:12,150 [nnabla]: epoch 80 of 100 cost=1.162000  {train_error=1.161096, valid_error=1.161061} time=(3.7s /4.7s) 
2024-01-28 21:15:12,187 [nnabla]: epoch 81 of 100 cost=1.160380  time=(3.8s /4.7s) 
2024-01-28 21:15:12,221 [nnabla]: epoch 82 of 100 cost=1.158903  time=(3.9s /4.7s) 
2024-01-28 21:15:12,257 [nnabla]: epoch 83 of 100 cost=1.157394  time=(3.9s /4.7s) 
2024-01-28 21:15:12,293 [nnabla]: epoch 84 of 100 cost=1.155997  time=(3.9s /4.7s) 
2024-01-28 21:15:12,329 [nnabla]: epoch 85 of 100 cost=1.154616  time=(4.0s /4.7s) 
2024-01-28 21:15:12,366 [nnabla]: epoch 86 of 100 cost=1.153343  time=(4.0s /4.7s) 
2024-01-28 21:15:12,402 [nnabla]: epoch 87 of 100 cost=1.152008  time=(4.1s /4.7s) 
2024-01-28 21:15:12,438 [nnabla]: epoch 88 of 100 cost=1.150769  time=(4.1s /4.6s) 
2024-01-28 21:15:12,481 [nnabla]: epoch 89 of 100 cost=1.149710  time=(4.1s /4.6s) 
2024-01-28 21:15:12,574 [nnabla]: epoch 90 of 100 cost=1.148427  {train_error=1.147836, valid_error=1.147746} time=(4.2s /4.6s) 
2024-01-28 21:15:12,608 [nnabla]: epoch 91 of 100 cost=1.147388  time=(4.3s /4.7s) 
2024-01-28 21:15:12,643 [nnabla]: epoch 92 of 100 cost=1.146270  time=(4.3s /4.7s) 
2024-01-28 21:15:12,678 [nnabla]: epoch 93 of 100 cost=1.145213  time=(4.3s /4.7s) 
2024-01-28 21:15:12,714 [nnabla]: epoch 94 of 100 cost=1.144158  time=(4.4s /4.6s) 
2024-01-28 21:15:12,751 [nnabla]: epoch 95 of 100 cost=1.143201  time=(4.4s /4.6s) 
2024-01-28 21:15:12,787 [nnabla]: epoch 96 of 100 cost=1.142228  time=(4.4s /4.6s) 
2024-01-28 21:15:12,822 [nnabla]: epoch 97 of 100 cost=1.141282  time=(4.5s /4.6s) 
2024-01-28 21:15:12,857 [nnabla]: epoch 98 of 100 cost=1.140411  time=(4.5s /4.6s) 
2024-01-28 21:15:12,894 [nnabla]: epoch 99 of 100 cost=1.139479  time=(4.5s /4.6s) 
2024-01-28 21:15:12,999 [nnabla]: epoch 100 of 100 cost=1.138592  {train_error=1.138169, valid_error=1.138033} time=(4.6s /4.6s) 
2024-01-28 21:15:13,014 [nnabla]: Training Completed.
NNabla command line interface (Version:1.33.1, Build:230206070804, Callback:NNabla SSH callback module.)

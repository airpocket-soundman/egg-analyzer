2024-01-28 22:42:00,262 Training process is started.
python "C:\Users\yamas\Desktop\tools\neural_network_console\libs\Python\Lib\site-packages\nnabla\utils\cli\cli.py" train
	-c "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_224200\net.nntxt"
	-o "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_224200"
2024-01-28 22:42:00,803 [nnabla]: [CALLBACK]: Exec train on local
2024-01-28 22:42:00,809 [nnabla]: Using context "Context(backend=['cpu:float'], array_class='CpuCachedArray', device_id='')"
2024-01-28 22:42:00,809 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_test_3class_onsen.csv"
2024-01-28 22:42:01,394 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_valid_3class_onsen.csv"
2024-01-28 22:42:01,774 [nnabla]: Train with contexts ['cpu']
2024-01-28 22:42:01,798 [nnabla]: Training epoch 1 of 200 begin
2024-01-28 22:42:01,798 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 22:42:01,798 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 22:42:02,007 [nnabla]: epoch 1 of 200 cost=4.441790  {train_error=4.386507, valid_error=4.384255} time=(0.1s /19.3s) 
2024-01-28 22:42:02,095 [nnabla]: epoch 2 of 200 cost=4.335125  {train_error=4.280133, valid_error=4.277944} time=(0.3s /25.2s) 
2024-01-28 22:42:02,180 [nnabla]: epoch 3 of 200 cost=4.229488  {train_error=4.174615, valid_error=4.172310} time=(0.3s /22.6s) 
2024-01-28 22:42:02,266 [nnabla]: epoch 4 of 200 cost=4.123716  {train_error=4.069787, valid_error=4.067519} time=(0.4s /21.2s) 
2024-01-28 22:42:02,363 [nnabla]: epoch 5 of 200 cost=4.019478  {train_error=3.965719, valid_error=3.963571} time=(0.5s /20.4s) 
2024-01-28 22:42:02,406 [nnabla]: epoch 6 of 200 cost=3.916484  time=(0.6s /20.3s) 
2024-01-28 22:42:02,450 [nnabla]: epoch 7 of 200 cost=3.813382  time=(0.7s /18.6s) 
2024-01-28 22:42:02,493 [nnabla]: epoch 8 of 200 cost=3.712125  time=(0.7s /17.4s) 
2024-01-28 22:42:02,537 [nnabla]: epoch 9 of 200 cost=3.611984  time=(0.7s /16.4s) 
2024-01-28 22:42:02,630 [nnabla]: epoch 10 of 200 cost=3.513204  {train_error=3.462676, valid_error=3.460356} time=(0.8s /15.6s) 
2024-01-28 22:42:02,674 [nnabla]: epoch 11 of 200 cost=3.416052  time=(0.9s /15.9s) 
2024-01-28 22:42:02,725 [nnabla]: epoch 12 of 200 cost=3.319851  time=(0.9s /15.3s) 
2024-01-28 22:42:02,769 [nnabla]: epoch 13 of 200 cost=3.226664  time=(1.0s /14.9s) 
2024-01-28 22:42:02,812 [nnabla]: epoch 14 of 200 cost=3.134252  time=(1.0s /14.5s) 
2024-01-28 22:42:02,855 [nnabla]: epoch 15 of 200 cost=3.043937  time=(1.1s /14.1s) 
2024-01-28 22:42:02,897 [nnabla]: epoch 16 of 200 cost=2.956386  time=(1.1s /13.7s) 
2024-01-28 22:42:02,943 [nnabla]: epoch 17 of 200 cost=2.870399  time=(1.1s /13.5s) 
2024-01-28 22:42:02,987 [nnabla]: epoch 18 of 200 cost=2.787175  time=(1.2s /13.2s) 
2024-01-28 22:42:03,030 [nnabla]: epoch 19 of 200 cost=2.706248  time=(1.2s /12.9s) 
2024-01-28 22:42:03,124 [nnabla]: epoch 20 of 200 cost=2.628174  {train_error=2.588518, valid_error=2.586277} time=(1.3s /12.8s) 
2024-01-28 22:42:03,169 [nnabla]: epoch 21 of 200 cost=2.552395  time=(1.4s /13.1s) 
2024-01-28 22:42:03,213 [nnabla]: epoch 22 of 200 cost=2.479156  time=(1.4s /12.9s) 
2024-01-28 22:42:03,264 [nnabla]: epoch 23 of 200 cost=2.409788  time=(1.5s /12.7s) 
2024-01-28 22:42:03,307 [nnabla]: epoch 24 of 200 cost=2.342020  time=(1.5s /12.6s) 
2024-01-28 22:42:03,352 [nnabla]: epoch 25 of 200 cost=2.278224  time=(1.6s /12.4s) 
2024-01-28 22:42:03,398 [nnabla]: epoch 26 of 200 cost=2.216640  time=(1.6s /12.3s) 
2024-01-28 22:42:03,441 [nnabla]: epoch 27 of 200 cost=2.157770  time=(1.6s /12.2s) 
2024-01-28 22:42:03,484 [nnabla]: epoch 28 of 200 cost=2.101973  time=(1.7s /12.0s) 
2024-01-28 22:42:03,528 [nnabla]: epoch 29 of 200 cost=2.049348  time=(1.7s /11.9s) 
2024-01-28 22:42:03,623 [nnabla]: epoch 30 of 200 cost=1.999402  {train_error=1.974006, valid_error=1.972393} time=(1.8s /11.8s) 
2024-01-28 22:42:03,667 [nnabla]: epoch 31 of 200 cost=1.951245  time=(1.9s /12.1s) 
2024-01-28 22:42:03,709 [nnabla]: epoch 32 of 200 cost=1.907821  time=(1.9s /11.9s) 
2024-01-28 22:42:03,753 [nnabla]: epoch 33 of 200 cost=1.864290  time=(2.0s /11.8s) 
2024-01-28 22:42:03,803 [nnabla]: epoch 34 of 200 cost=1.824625  time=(2.0s /11.7s) 
2024-01-28 22:42:03,848 [nnabla]: epoch 35 of 200 cost=1.787307  time=(2.0s /11.7s) 
2024-01-28 22:42:03,891 [nnabla]: epoch 36 of 200 cost=1.752159  time=(2.1s /11.6s) 
2024-01-28 22:42:03,938 [nnabla]: epoch 37 of 200 cost=1.718030  time=(2.1s /11.6s) 
2024-01-28 22:42:03,981 [nnabla]: epoch 38 of 200 cost=1.687964  time=(2.2s /11.5s) 
2024-01-28 22:42:04,025 [nnabla]: epoch 39 of 200 cost=1.658164  time=(2.2s /11.4s) 
2024-01-28 22:42:04,118 [nnabla]: epoch 40 of 200 cost=1.630479  {train_error=1.616979, valid_error=1.616658} time=(2.3s /11.3s) 
2024-01-28 22:42:04,167 [nnabla]: epoch 41 of 200 cost=1.604537  time=(2.4s /11.6s) 
2024-01-28 22:42:04,211 [nnabla]: epoch 42 of 200 cost=1.580266  time=(2.4s /11.5s) 
2024-01-28 22:42:04,254 [nnabla]: epoch 43 of 200 cost=1.557266  time=(2.5s /11.4s) 
2024-01-28 22:42:04,297 [nnabla]: epoch 44 of 200 cost=1.535762  time=(2.5s /11.4s) 
2024-01-28 22:42:04,355 [nnabla]: epoch 45 of 200 cost=1.515111  time=(2.5s /11.3s) 
2024-01-28 22:42:04,398 [nnabla]: epoch 46 of 200 cost=1.497008  time=(2.6s /11.3s) 
2024-01-28 22:42:04,441 [nnabla]: epoch 47 of 200 cost=1.478949  time=(2.6s /11.2s) 
2024-01-28 22:42:04,484 [nnabla]: epoch 48 of 200 cost=1.462030  time=(2.7s /11.2s) 
2024-01-28 22:42:04,526 [nnabla]: epoch 49 of 200 cost=1.446150  time=(2.7s /11.1s) 
2024-01-28 22:42:04,621 [nnabla]: epoch 50 of 200 cost=1.431509  {train_error=1.423714, valid_error=1.424274} time=(2.8s /11.1s) 
2024-01-28 22:42:04,665 [nnabla]: epoch 51 of 200 cost=1.416878  time=(2.9s /11.2s) 
2024-01-28 22:42:04,711 [nnabla]: epoch 52 of 200 cost=1.404206  time=(2.9s /11.2s) 
2024-01-28 22:42:04,754 [nnabla]: epoch 53 of 200 cost=1.391487  time=(3.0s /11.2s) 
2024-01-28 22:42:04,797 [nnabla]: epoch 54 of 200 cost=1.379329  time=(3.0s /11.1s) 
2024-01-28 22:42:04,840 [nnabla]: epoch 55 of 200 cost=1.368624  time=(3.0s /11.1s) 
2024-01-28 22:42:04,891 [nnabla]: epoch 56 of 200 cost=1.358052  time=(3.1s /11.0s) 
2024-01-28 22:42:04,934 [nnabla]: epoch 57 of 200 cost=1.347960  time=(3.1s /11.0s) 
2024-01-28 22:42:04,978 [nnabla]: epoch 58 of 200 cost=1.338334  time=(3.2s /11.0s) 
2024-01-28 22:42:05,021 [nnabla]: epoch 59 of 200 cost=1.329639  time=(3.2s /10.9s) 
2024-01-28 22:42:05,117 [nnabla]: epoch 60 of 200 cost=1.320978  {train_error=1.316865, valid_error=1.317039} time=(3.3s /10.9s) 
2024-01-28 22:42:05,163 [nnabla]: epoch 61 of 200 cost=1.313266  time=(3.4s /11.0s) 
2024-01-28 22:42:05,207 [nnabla]: epoch 62 of 200 cost=1.305079  time=(3.4s /11.0s) 
2024-01-28 22:42:05,253 [nnabla]: epoch 63 of 200 cost=1.298278  time=(3.5s /11.0s) 
2024-01-28 22:42:05,303 [nnabla]: epoch 64 of 200 cost=1.291011  time=(3.5s /10.9s) 
2024-01-28 22:42:05,345 [nnabla]: epoch 65 of 200 cost=1.284653  time=(3.5s /10.9s) 
2024-01-28 22:42:05,390 [nnabla]: epoch 66 of 200 cost=1.278214  time=(3.6s /10.9s) 
2024-01-28 22:42:05,441 [nnabla]: epoch 67 of 200 cost=1.272180  time=(3.6s /10.9s) 
2024-01-28 22:42:05,484 [nnabla]: epoch 68 of 200 cost=1.266868  time=(3.7s /10.8s) 
2024-01-28 22:42:05,528 [nnabla]: epoch 69 of 200 cost=1.260956  time=(3.7s /10.8s) 
2024-01-28 22:42:05,622 [nnabla]: epoch 70 of 200 cost=1.256115  {train_error=1.253330, valid_error=1.253476} time=(3.8s /10.8s) 
2024-01-28 22:42:05,665 [nnabla]: epoch 71 of 200 cost=1.251058  time=(3.9s /10.9s) 
2024-01-28 22:42:05,708 [nnabla]: epoch 72 of 200 cost=1.246346  time=(3.9s /10.9s) 
2024-01-28 22:42:05,752 [nnabla]: epoch 73 of 200 cost=1.241742  time=(4.0s /10.8s) 
2024-01-28 22:42:05,796 [nnabla]: epoch 74 of 200 cost=1.237282  time=(4.0s /10.8s) 
2024-01-28 22:42:05,841 [nnabla]: epoch 75 of 200 cost=1.233315  time=(4.0s /10.8s) 
2024-01-28 22:42:05,886 [nnabla]: epoch 76 of 200 cost=1.229421  time=(4.1s /10.8s) 
2024-01-28 22:42:05,930 [nnabla]: epoch 77 of 200 cost=1.225532  time=(4.1s /10.7s) 
2024-01-28 22:42:05,979 [nnabla]: epoch 78 of 200 cost=1.221848  time=(4.2s /10.7s) 
2024-01-28 22:42:06,024 [nnabla]: epoch 79 of 200 cost=1.218362  time=(4.2s /10.7s) 
2024-01-28 22:42:06,118 [nnabla]: epoch 80 of 200 cost=1.214913  {train_error=1.213260, valid_error=1.213363} time=(4.3s /10.7s) 
2024-01-28 22:42:06,162 [nnabla]: epoch 81 of 200 cost=1.211719  time=(4.4s /10.8s) 
2024-01-28 22:42:06,206 [nnabla]: epoch 82 of 200 cost=1.208627  time=(4.4s /10.7s) 
2024-01-28 22:42:06,251 [nnabla]: epoch 83 of 200 cost=1.205576  time=(4.5s /10.7s) 
2024-01-28 22:42:06,293 [nnabla]: epoch 84 of 200 cost=1.202822  time=(4.5s /10.7s) 
2024-01-28 22:42:06,337 [nnabla]: epoch 85 of 200 cost=1.199964  time=(4.5s /10.7s) 
2024-01-28 22:42:06,382 [nnabla]: epoch 86 of 200 cost=1.197357  time=(4.6s /10.7s) 
2024-01-28 22:42:06,427 [nnabla]: epoch 87 of 200 cost=1.194784  time=(4.6s /10.6s) 
2024-01-28 22:42:06,470 [nnabla]: epoch 88 of 200 cost=1.192268  time=(4.7s /10.6s) 
2024-01-28 22:42:06,523 [nnabla]: epoch 89 of 200 cost=1.189950  time=(4.7s /10.6s) 
2024-01-28 22:42:06,618 [nnabla]: epoch 90 of 200 cost=1.187645  {train_error=1.186406, valid_error=1.186439} time=(4.8s /10.6s) 
2024-01-28 22:42:06,663 [nnabla]: epoch 91 of 200 cost=1.185376  time=(4.9s /10.7s) 
2024-01-28 22:42:06,706 [nnabla]: epoch 92 of 200 cost=1.183228  time=(4.9s /10.7s) 
2024-01-28 22:42:06,750 [nnabla]: epoch 93 of 200 cost=1.181227  time=(5.0s /10.7s) 
2024-01-28 22:42:06,794 [nnabla]: epoch 94 of 200 cost=1.179156  time=(5.0s /10.6s) 
2024-01-28 22:42:06,838 [nnabla]: epoch 95 of 200 cost=1.177271  time=(5.0s /10.6s) 
2024-01-28 22:42:06,882 [nnabla]: epoch 96 of 200 cost=1.175415  time=(5.1s /10.6s) 
2024-01-28 22:42:06,928 [nnabla]: epoch 97 of 200 cost=1.173587  time=(5.1s /10.6s) 
2024-01-28 22:42:06,970 [nnabla]: epoch 98 of 200 cost=1.171860  time=(5.2s /10.6s) 
2024-01-28 22:42:07,016 [nnabla]: epoch 99 of 200 cost=1.170132  time=(5.2s /10.5s) 
2024-01-28 22:42:07,126 [nnabla]: epoch 100 of 200 cost=1.168493  {train_error=1.167667, valid_error=1.167602} time=(5.3s /10.5s) 
2024-01-28 22:42:07,172 [nnabla]: epoch 101 of 200 cost=1.166938  time=(5.4s /10.6s) 
2024-01-28 22:42:07,215 [nnabla]: epoch 102 of 200 cost=1.165429  time=(5.4s /10.6s) 
2024-01-28 22:42:07,259 [nnabla]: epoch 103 of 200 cost=1.163925  time=(5.5s /10.6s) 
2024-01-28 22:42:07,302 [nnabla]: epoch 104 of 200 cost=1.162428  time=(5.5s /10.6s) 
2024-01-28 22:42:07,346 [nnabla]: epoch 105 of 200 cost=1.161048  time=(5.5s /10.6s) 
2024-01-28 22:42:07,391 [nnabla]: epoch 106 of 200 cost=1.159681  time=(5.6s /10.6s) 
2024-01-28 22:42:07,436 [nnabla]: epoch 107 of 200 cost=1.158411  time=(5.6s /10.5s) 
2024-01-28 22:42:07,480 [nnabla]: epoch 108 of 200 cost=1.157157  time=(5.7s /10.5s) 
2024-01-28 22:42:07,524 [nnabla]: epoch 109 of 200 cost=1.155857  time=(5.7s /10.5s) 
2024-01-28 22:42:07,619 [nnabla]: epoch 110 of 200 cost=1.154703  {train_error=1.154020, valid_error=1.154004} time=(5.8s /10.5s) 
2024-01-28 22:42:07,671 [nnabla]: epoch 111 of 200 cost=1.153490  time=(5.9s /10.6s) 
2024-01-28 22:42:07,717 [nnabla]: epoch 112 of 200 cost=1.152469  time=(5.9s /10.6s) 
2024-01-28 22:42:07,758 [nnabla]: epoch 113 of 200 cost=1.151259  time=(6.0s /10.5s) 
2024-01-28 22:42:07,801 [nnabla]: epoch 114 of 200 cost=1.150257  time=(6.0s /10.5s) 
2024-01-28 22:42:07,844 [nnabla]: epoch 115 of 200 cost=1.149107  time=(6.0s /10.5s) 
2024-01-28 22:42:07,887 [nnabla]: epoch 116 of 200 cost=1.148207  time=(6.1s /10.5s) 
2024-01-28 22:42:07,930 [nnabla]: epoch 117 of 200 cost=1.147198  time=(6.1s /10.5s) 
2024-01-28 22:42:07,974 [nnabla]: epoch 118 of 200 cost=1.146163  time=(6.2s /10.5s) 
2024-01-28 22:42:08,018 [nnabla]: epoch 119 of 200 cost=1.145243  time=(6.2s /10.5s) 
2024-01-28 22:42:08,112 [nnabla]: epoch 120 of 200 cost=1.144326  {train_error=1.143867, valid_error=1.143906} time=(6.3s /10.4s) 
2024-01-28 22:42:08,156 [nnabla]: epoch 121 of 200 cost=1.143505  time=(6.4s /10.5s) 
2024-01-28 22:42:08,208 [nnabla]: epoch 122 of 200 cost=1.142662  time=(6.4s /10.5s) 
2024-01-28 22:42:08,252 [nnabla]: epoch 123 of 200 cost=1.141792  time=(6.5s /10.5s) 
2024-01-28 22:42:08,296 [nnabla]: epoch 124 of 200 cost=1.140930  time=(6.5s /10.5s) 
2024-01-28 22:42:08,338 [nnabla]: epoch 125 of 200 cost=1.140199  time=(6.5s /10.5s) 
2024-01-28 22:42:08,380 [nnabla]: epoch 126 of 200 cost=1.139365  time=(6.6s /10.4s) 
2024-01-28 22:42:08,424 [nnabla]: epoch 127 of 200 cost=1.138607  time=(6.6s /10.4s) 
2024-01-28 22:42:08,468 [nnabla]: epoch 128 of 200 cost=1.137939  time=(6.7s /10.4s) 
2024-01-28 22:42:08,511 [nnabla]: epoch 129 of 200 cost=1.137170  time=(6.7s /10.4s) 
2024-01-28 22:42:08,604 [nnabla]: epoch 130 of 200 cost=1.136480  {train_error=1.136032, valid_error=1.136181} time=(6.8s /10.4s) 
2024-01-28 22:42:08,647 [nnabla]: epoch 131 of 200 cost=1.135812  time=(6.8s /10.5s) 
2024-01-28 22:42:08,693 [nnabla]: epoch 132 of 200 cost=1.135133  time=(6.9s /10.4s) 
2024-01-28 22:42:08,745 [nnabla]: epoch 133 of 200 cost=1.134516  time=(6.9s /10.4s) 
2024-01-28 22:42:08,791 [nnabla]: epoch 134 of 200 cost=1.133827  time=(7.0s /10.4s) 
2024-01-28 22:42:08,835 [nnabla]: epoch 135 of 200 cost=1.133223  time=(7.0s /10.4s) 
2024-01-28 22:42:08,878 [nnabla]: epoch 136 of 200 cost=1.132597  time=(7.1s /10.4s) 
2024-01-28 22:42:08,921 [nnabla]: epoch 137 of 200 cost=1.132018  time=(7.1s /10.4s) 
2024-01-28 22:42:08,964 [nnabla]: epoch 138 of 200 cost=1.131476  time=(7.2s /10.4s) 
2024-01-28 22:42:09,008 [nnabla]: epoch 139 of 200 cost=1.130898  time=(7.2s /10.4s) 
2024-01-28 22:42:09,103 [nnabla]: epoch 140 of 200 cost=1.130354  {train_error=1.129980, valid_error=1.130074} time=(7.3s /10.4s) 
2024-01-28 22:42:09,146 [nnabla]: epoch 141 of 200 cost=1.129812  time=(7.3s /10.4s) 
2024-01-28 22:42:09,190 [nnabla]: epoch 142 of 200 cost=1.129261  time=(7.4s /10.4s) 
2024-01-28 22:42:09,234 [nnabla]: epoch 143 of 200 cost=1.128734  time=(7.4s /10.4s) 
2024-01-28 22:42:09,284 [nnabla]: epoch 144 of 200 cost=1.128279  time=(7.5s /10.4s) 
2024-01-28 22:42:09,328 [nnabla]: epoch 145 of 200 cost=1.127783  time=(7.5s /10.4s) 
2024-01-28 22:42:09,373 [nnabla]: epoch 146 of 200 cost=1.127254  time=(7.6s /10.4s) 
2024-01-28 22:42:09,416 [nnabla]: epoch 147 of 200 cost=1.126824  time=(7.6s /10.4s) 
2024-01-28 22:42:09,458 [nnabla]: epoch 148 of 200 cost=1.126345  time=(7.7s /10.4s) 
2024-01-28 22:42:09,502 [nnabla]: epoch 149 of 200 cost=1.125953  time=(7.7s /10.3s) 
2024-01-28 22:42:09,597 [nnabla]: epoch 150 of 200 cost=1.125413  {train_error=1.125140, valid_error=1.125114} time=(7.7s /10.3s) 
2024-01-28 22:42:09,641 [nnabla]: epoch 151 of 200 cost=1.125031  time=(7.8s /10.4s) 
2024-01-28 22:42:09,685 [nnabla]: epoch 152 of 200 cost=1.124636  time=(7.9s /10.4s) 
2024-01-28 22:42:09,727 [nnabla]: epoch 153 of 200 cost=1.124253  time=(7.9s /10.4s) 
2024-01-28 22:42:09,771 [nnabla]: epoch 154 of 200 cost=1.123928  time=(8.0s /10.4s) 
2024-01-28 22:42:09,830 [nnabla]: epoch 155 of 200 cost=1.123397  time=(8.0s /10.3s) 
2024-01-28 22:42:09,874 [nnabla]: epoch 156 of 200 cost=1.122901  time=(8.1s /10.4s) 
2024-01-28 22:42:09,917 [nnabla]: epoch 157 of 200 cost=1.122750  time=(8.1s /10.3s) 
2024-01-28 22:42:09,960 [nnabla]: epoch 158 of 200 cost=1.122291  time=(8.2s /10.3s) 
2024-01-28 22:42:10,004 [nnabla]: epoch 159 of 200 cost=1.121918  time=(8.2s /10.3s) 
2024-01-28 22:42:10,098 [nnabla]: epoch 160 of 200 cost=1.121442  {train_error=1.121281, valid_error=1.121294} time=(8.2s /10.3s) 
2024-01-28 22:42:10,141 [nnabla]: epoch 161 of 200 cost=1.121248  time=(8.3s /10.4s) 
2024-01-28 22:42:10,185 [nnabla]: epoch 162 of 200 cost=1.120830  time=(8.4s /10.4s) 
2024-01-28 22:42:10,229 [nnabla]: epoch 163 of 200 cost=1.120480  time=(8.4s /10.3s) 
2024-01-28 22:42:10,272 [nnabla]: epoch 164 of 200 cost=1.120213  time=(8.5s /10.3s) 
2024-01-28 22:42:10,316 [nnabla]: epoch 165 of 200 cost=1.119882  time=(8.5s /10.3s) 
2024-01-28 22:42:10,367 [nnabla]: epoch 166 of 200 cost=1.119571  time=(8.6s /10.3s) 
2024-01-28 22:42:10,414 [nnabla]: epoch 167 of 200 cost=1.119217  time=(8.6s /10.3s) 
2024-01-28 22:42:10,457 [nnabla]: epoch 168 of 200 cost=1.118881  time=(8.7s /10.3s) 
2024-01-28 22:42:10,500 [nnabla]: epoch 169 of 200 cost=1.118634  time=(8.7s /10.3s) 
2024-01-28 22:42:10,595 [nnabla]: epoch 170 of 200 cost=1.118312  {train_error=1.118105, valid_error=1.118037} time=(8.7s /10.3s) 
2024-01-28 22:42:10,641 [nnabla]: epoch 171 of 200 cost=1.118031  time=(8.8s /10.3s) 
2024-01-28 22:42:10,688 [nnabla]: epoch 172 of 200 cost=1.117790  time=(8.9s /10.3s) 
2024-01-28 22:42:10,730 [nnabla]: epoch 173 of 200 cost=1.117573  time=(8.9s /10.3s) 
2024-01-28 22:42:10,772 [nnabla]: epoch 174 of 200 cost=1.117226  time=(9.0s /10.3s) 
2024-01-28 22:42:10,816 [nnabla]: epoch 175 of 200 cost=1.116933  time=(9.0s /10.3s) 
2024-01-28 22:42:10,858 [nnabla]: epoch 176 of 200 cost=1.116747  time=(9.1s /10.3s) 
2024-01-28 22:42:10,910 [nnabla]: epoch 177 of 200 cost=1.116426  time=(9.1s /10.3s) 
2024-01-28 22:42:10,956 [nnabla]: epoch 178 of 200 cost=1.116185  time=(9.2s /10.3s) 
2024-01-28 22:42:10,998 [nnabla]: epoch 179 of 200 cost=1.115915  time=(9.2s /10.3s) 
2024-01-28 22:42:11,093 [nnabla]: epoch 180 of 200 cost=1.115699  {train_error=1.115488, valid_error=1.115551} time=(9.2s /10.3s) 
2024-01-28 22:42:11,137 [nnabla]: epoch 181 of 200 cost=1.115444  time=(9.3s /10.3s) 
2024-01-28 22:42:11,183 [nnabla]: epoch 182 of 200 cost=1.115174  time=(9.4s /10.3s) 
2024-01-28 22:42:11,226 [nnabla]: epoch 183 of 200 cost=1.115005  time=(9.4s /10.3s) 
2024-01-28 22:42:11,269 [nnabla]: epoch 184 of 200 cost=1.114705  time=(9.5s /10.3s) 
2024-01-28 22:42:11,313 [nnabla]: epoch 185 of 200 cost=1.114505  time=(9.5s /10.3s) 
2024-01-28 22:42:11,356 [nnabla]: epoch 186 of 200 cost=1.114377  time=(9.6s /10.3s) 
2024-01-28 22:42:11,399 [nnabla]: epoch 187 of 200 cost=1.114061  time=(9.6s /10.3s) 
2024-01-28 22:42:11,451 [nnabla]: epoch 188 of 200 cost=1.113990  time=(9.6s /10.3s) 
2024-01-28 22:42:11,495 [nnabla]: epoch 189 of 200 cost=1.113685  time=(9.7s /10.3s) 
2024-01-28 22:42:11,591 [nnabla]: epoch 190 of 200 cost=1.113456  {train_error=1.113286, valid_error=1.113283} time=(9.7s /10.3s) 
2024-01-28 22:42:11,635 [nnabla]: epoch 191 of 200 cost=1.113234  time=(9.8s /10.3s) 
2024-01-28 22:42:11,679 [nnabla]: epoch 192 of 200 cost=1.113022  time=(9.9s /10.3s) 
2024-01-28 22:42:11,721 [nnabla]: epoch 193 of 200 cost=1.112884  time=(9.9s /10.3s) 
2024-01-28 22:42:11,764 [nnabla]: epoch 194 of 200 cost=1.112701  time=(10.0s /10.3s) 
2024-01-28 22:42:11,807 [nnabla]: epoch 195 of 200 cost=1.112467  time=(10.0s /10.3s) 
2024-01-28 22:42:11,852 [nnabla]: epoch 196 of 200 cost=1.112375  time=(10.1s /10.3s) 
2024-01-28 22:42:11,895 [nnabla]: epoch 197 of 200 cost=1.112124  time=(10.1s /10.2s) 
2024-01-28 22:42:11,937 [nnabla]: epoch 198 of 200 cost=1.111921  time=(10.1s /10.2s) 
2024-01-28 22:42:11,988 [nnabla]: epoch 199 of 200 cost=1.111829  time=(10.2s /10.2s) 
2024-01-28 22:42:12,082 [nnabla]: epoch 200 of 200 cost=1.111700  {train_error=1.111384, valid_error=1.111574} time=(10.2s /10.2s) 
2024-01-28 22:42:12,096 [nnabla]: Training Completed.
NNabla command line interface (Version:1.33.1, Build:230206070804, Callback:NNabla SSH callback module.)

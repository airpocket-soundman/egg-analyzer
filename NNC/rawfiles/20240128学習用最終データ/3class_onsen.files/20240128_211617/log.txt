2024-01-28 21:16:17,970 Training process is started.
python "C:\Users\yamas\Desktop\tools\neural_network_console\libs\Python\Lib\site-packages\nnabla\utils\cli\cli.py" train
	-c "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_211617\net.nntxt"
	-o "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_211617"
2024-01-28 21:16:18,525 [nnabla]: [CALLBACK]: Exec train on local
2024-01-28 21:16:18,532 [nnabla]: Using context "Context(backend=['cpu:float'], array_class='CpuCachedArray', device_id='')"
2024-01-28 21:16:18,532 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_test_3class_onsen.csv"
2024-01-28 21:16:19,131 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_valid_3class_onsen.csv"
2024-01-28 21:16:19,514 [nnabla]: Train with contexts ['cpu']
2024-01-28 21:16:19,534 [nnabla]: Training epoch 1 of 100 begin
2024-01-28 21:16:19,534 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 21:16:19,534 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 21:16:19,739 [nnabla]: epoch 1 of 100 cost=4.384549  {train_error=4.098502, valid_error=4.093275} time=(0.1s /9.6s) 
2024-01-28 21:16:19,837 [nnabla]: epoch 2 of 100 cost=3.877999  {train_error=3.761286, valid_error=3.734061} time=(0.2s /12.3s) 
2024-01-28 21:16:19,932 [nnabla]: epoch 3 of 100 cost=3.528815  {train_error=3.301736, valid_error=3.285152} time=(0.3s /11.4s) 
2024-01-28 21:16:20,028 [nnabla]: epoch 4 of 100 cost=3.252018  {train_error=3.120760, valid_error=3.109088} time=(0.4s /11.0s) 
2024-01-28 21:16:20,131 [nnabla]: epoch 5 of 100 cost=3.021379  {train_error=2.832159, valid_error=2.827646} time=(0.5s /10.7s) 
2024-01-28 21:16:20,173 [nnabla]: epoch 6 of 100 cost=2.859845  time=(0.6s /10.7s) 
2024-01-28 21:16:20,216 [nnabla]: epoch 7 of 100 cost=2.728662  time=(0.7s /9.7s) 
2024-01-28 21:16:20,255 [nnabla]: epoch 8 of 100 cost=2.613238  time=(0.7s /9.0s) 
2024-01-28 21:16:20,295 [nnabla]: epoch 9 of 100 cost=2.509360  time=(0.8s /8.5s) 
2024-01-28 21:16:20,398 [nnabla]: epoch 10 of 100 cost=2.407281  {train_error=2.284707, valid_error=2.287911} time=(0.8s /8.0s) 
2024-01-28 21:16:20,439 [nnabla]: epoch 11 of 100 cost=2.312927  time=(0.9s /8.2s) 
2024-01-28 21:16:20,491 [nnabla]: epoch 12 of 100 cost=2.217927  time=(0.9s /7.9s) 
2024-01-28 21:16:20,532 [nnabla]: epoch 13 of 100 cost=2.134297  time=(1.0s /7.7s) 
2024-01-28 21:16:20,572 [nnabla]: epoch 14 of 100 cost=2.049322  time=(1.0s /7.4s) 
2024-01-28 21:16:20,612 [nnabla]: epoch 15 of 100 cost=1.962730  time=(1.1s /7.2s) 
2024-01-28 21:16:20,653 [nnabla]: epoch 16 of 100 cost=1.884053  time=(1.1s /7.0s) 
2024-01-28 21:16:20,694 [nnabla]: epoch 17 of 100 cost=1.801478  time=(1.2s /6.8s) 
2024-01-28 21:16:20,737 [nnabla]: epoch 18 of 100 cost=1.733505  time=(1.2s /6.7s) 
2024-01-28 21:16:20,778 [nnabla]: epoch 19 of 100 cost=1.649078  time=(1.2s /6.5s) 
2024-01-28 21:16:20,883 [nnabla]: epoch 20 of 100 cost=1.589321  {train_error=1.509850, valid_error=1.512175} time=(1.3s /6.4s) 
2024-01-28 21:16:20,925 [nnabla]: epoch 21 of 100 cost=1.510987  time=(1.4s /6.6s) 
2024-01-28 21:16:20,966 [nnabla]: epoch 22 of 100 cost=1.453172  time=(1.4s /6.5s) 
2024-01-28 21:16:21,015 [nnabla]: epoch 23 of 100 cost=1.382563  time=(1.5s /6.4s) 
2024-01-28 21:16:21,056 [nnabla]: epoch 24 of 100 cost=1.317325  time=(1.5s /6.3s) 
2024-01-28 21:16:21,099 [nnabla]: epoch 25 of 100 cost=1.271384  time=(1.6s /6.3s) 
2024-01-28 21:16:21,139 [nnabla]: epoch 26 of 100 cost=1.202063  time=(1.6s /6.2s) 
2024-01-28 21:16:21,179 [nnabla]: epoch 27 of 100 cost=1.165663  time=(1.6s /6.1s) 
2024-01-28 21:16:21,221 [nnabla]: epoch 28 of 100 cost=1.107161  time=(1.7s /6.0s) 
2024-01-28 21:16:21,262 [nnabla]: epoch 29 of 100 cost=1.059912  time=(1.7s /6.0s) 
2024-01-28 21:16:21,366 [nnabla]: epoch 30 of 100 cost=1.004288  {train_error=0.944592, valid_error=0.947318} time=(1.8s /5.9s) 
2024-01-28 21:16:21,408 [nnabla]: epoch 31 of 100 cost=0.961448  time=(1.9s /6.0s) 
2024-01-28 21:16:21,450 [nnabla]: epoch 32 of 100 cost=0.919524  time=(1.9s /6.0s) 
2024-01-28 21:16:21,491 [nnabla]: epoch 33 of 100 cost=0.872221  time=(2.0s /5.9s) 
2024-01-28 21:16:21,542 [nnabla]: epoch 34 of 100 cost=0.839524  time=(2.0s /5.9s) 
2024-01-28 21:16:21,583 [nnabla]: epoch 35 of 100 cost=0.797799  time=(2.0s /5.9s) 
2024-01-28 21:16:21,623 [nnabla]: epoch 36 of 100 cost=0.761227  time=(2.1s /5.8s) 
2024-01-28 21:16:21,664 [nnabla]: epoch 37 of 100 cost=0.742570  time=(2.1s /5.8s) 
2024-01-28 21:16:21,704 [nnabla]: epoch 38 of 100 cost=0.711018  time=(2.2s /5.7s) 
2024-01-28 21:16:21,745 [nnabla]: epoch 39 of 100 cost=0.665448  time=(2.2s /5.7s) 
2024-01-28 21:16:21,849 [nnabla]: epoch 40 of 100 cost=0.642472  {train_error=0.594793, valid_error=0.596139} time=(2.3s /5.6s) 
2024-01-28 21:16:21,892 [nnabla]: epoch 41 of 100 cost=0.609195  time=(2.4s /5.7s) 
2024-01-28 21:16:21,932 [nnabla]: epoch 42 of 100 cost=0.590450  time=(2.4s /5.7s) 
2024-01-28 21:16:21,974 [nnabla]: epoch 43 of 100 cost=0.566002  time=(2.4s /5.7s) 
2024-01-28 21:16:22,015 [nnabla]: epoch 44 of 100 cost=0.535546  time=(2.5s /5.6s) 
2024-01-28 21:16:22,071 [nnabla]: epoch 45 of 100 cost=0.511698  time=(2.5s /5.6s) 
2024-01-28 21:16:22,113 [nnabla]: epoch 46 of 100 cost=0.500174  time=(2.6s /5.6s) 
2024-01-28 21:16:22,156 [nnabla]: epoch 47 of 100 cost=0.475231  time=(2.6s /5.6s) 
2024-01-28 21:16:22,202 [nnabla]: epoch 48 of 100 cost=0.455870  time=(2.7s /5.6s) 
2024-01-28 21:16:22,241 [nnabla]: epoch 49 of 100 cost=0.438982  time=(2.7s /5.5s) 
2024-01-28 21:16:22,345 [nnabla]: epoch 50 of 100 cost=0.416422  {train_error=0.389130, valid_error=0.396943} time=(2.7s /5.5s) 
2024-01-28 21:16:22,389 [nnabla]: epoch 51 of 100 cost=0.411517  time=(2.9s /5.6s) 
2024-01-28 21:16:22,432 [nnabla]: epoch 52 of 100 cost=0.393375  time=(2.9s /5.6s) 
2024-01-28 21:16:22,473 [nnabla]: epoch 53 of 100 cost=0.380016  time=(2.9s /5.5s) 
2024-01-28 21:16:22,514 [nnabla]: epoch 54 of 100 cost=0.362612  time=(3.0s /5.5s) 
2024-01-28 21:16:22,555 [nnabla]: epoch 55 of 100 cost=0.350646  time=(3.0s /5.5s) 
2024-01-28 21:16:22,605 [nnabla]: epoch 56 of 100 cost=0.332106  time=(3.1s /5.5s) 
2024-01-28 21:16:22,650 [nnabla]: epoch 57 of 100 cost=0.327070  time=(3.1s /5.5s) 
2024-01-28 21:16:22,693 [nnabla]: epoch 58 of 100 cost=0.308175  time=(3.2s /5.4s) 
2024-01-28 21:16:22,739 [nnabla]: epoch 59 of 100 cost=0.299851  time=(3.2s /5.4s) 
2024-01-28 21:16:22,843 [nnabla]: epoch 60 of 100 cost=0.284938  {train_error=0.263255, valid_error=0.263806} time=(3.2s /5.4s) 
2024-01-28 21:16:22,886 [nnabla]: epoch 61 of 100 cost=0.281651  time=(3.4s /5.5s) 
2024-01-28 21:16:22,931 [nnabla]: epoch 62 of 100 cost=0.277948  time=(3.4s /5.5s) 
2024-01-28 21:16:22,974 [nnabla]: epoch 63 of 100 cost=0.264601  time=(3.4s /5.5s) 
2024-01-28 21:16:23,015 [nnabla]: epoch 64 of 100 cost=0.258495  time=(3.5s /5.4s) 
2024-01-28 21:16:23,055 [nnabla]: epoch 65 of 100 cost=0.245270  time=(3.5s /5.4s) 
2024-01-28 21:16:23,096 [nnabla]: epoch 66 of 100 cost=0.243339  time=(3.6s /5.4s) 
2024-01-28 21:16:23,145 [nnabla]: epoch 67 of 100 cost=0.229635  time=(3.6s /5.4s) 
2024-01-28 21:16:23,187 [nnabla]: epoch 68 of 100 cost=0.220434  time=(3.7s /5.4s) 
2024-01-28 21:16:23,230 [nnabla]: epoch 69 of 100 cost=0.214943  time=(3.7s /5.4s) 
2024-01-28 21:16:23,334 [nnabla]: epoch 70 of 100 cost=0.217396  {train_error=0.185274, valid_error=0.188716} time=(3.7s /5.3s) 
2024-01-28 21:16:23,376 [nnabla]: epoch 71 of 100 cost=0.204217  time=(3.8s /5.4s) 
2024-01-28 21:16:23,418 [nnabla]: epoch 72 of 100 cost=0.198672  time=(3.9s /5.4s) 
2024-01-28 21:16:23,460 [nnabla]: epoch 73 of 100 cost=0.193120  time=(3.9s /5.4s) 
2024-01-28 21:16:23,502 [nnabla]: epoch 74 of 100 cost=0.186063  time=(4.0s /5.4s) 
2024-01-28 21:16:23,542 [nnabla]: epoch 75 of 100 cost=0.179330  time=(4.0s /5.3s) 
2024-01-28 21:16:23,583 [nnabla]: epoch 76 of 100 cost=0.175406  time=(4.0s /5.3s) 
2024-01-28 21:16:23,624 [nnabla]: epoch 77 of 100 cost=0.166114  time=(4.1s /5.3s) 
2024-01-28 21:16:23,673 [nnabla]: epoch 78 of 100 cost=0.168002  time=(4.1s /5.3s) 
2024-01-28 21:16:23,715 [nnabla]: epoch 79 of 100 cost=0.158374  time=(4.2s /5.3s) 
2024-01-28 21:16:23,818 [nnabla]: epoch 80 of 100 cost=0.157093  {train_error=0.137109, valid_error=0.140050} time=(4.2s /5.3s) 
2024-01-28 21:16:23,861 [nnabla]: epoch 81 of 100 cost=0.154167  time=(4.3s /5.3s) 
2024-01-28 21:16:23,902 [nnabla]: epoch 82 of 100 cost=0.152308  time=(4.4s /5.3s) 
2024-01-28 21:16:23,943 [nnabla]: epoch 83 of 100 cost=0.145700  time=(4.4s /5.3s) 
2024-01-28 21:16:23,984 [nnabla]: epoch 84 of 100 cost=0.139760  time=(4.4s /5.3s) 
2024-01-28 21:16:24,027 [nnabla]: epoch 85 of 100 cost=0.132521  time=(4.5s /5.3s) 
2024-01-28 21:16:24,067 [nnabla]: epoch 86 of 100 cost=0.136283  time=(4.5s /5.3s) 
2024-01-28 21:16:24,108 [nnabla]: epoch 87 of 100 cost=0.130544  time=(4.6s /5.3s) 
2024-01-28 21:16:24,148 [nnabla]: epoch 88 of 100 cost=0.132725  time=(4.6s /5.2s) 
2024-01-28 21:16:24,198 [nnabla]: epoch 89 of 100 cost=0.126770  time=(4.7s /5.2s) 
2024-01-28 21:16:24,304 [nnabla]: epoch 90 of 100 cost=0.122596  {train_error=0.104835, valid_error=0.107971} time=(4.7s /5.2s) 
2024-01-28 21:16:24,345 [nnabla]: epoch 91 of 100 cost=0.120268  time=(4.8s /5.3s) 
2024-01-28 21:16:24,387 [nnabla]: epoch 92 of 100 cost=0.110644  time=(4.9s /5.3s) 
2024-01-28 21:16:24,428 [nnabla]: epoch 93 of 100 cost=0.116206  time=(4.9s /5.3s) 
2024-01-28 21:16:24,470 [nnabla]: epoch 94 of 100 cost=0.106013  time=(4.9s /5.3s) 
2024-01-28 21:16:24,512 [nnabla]: epoch 95 of 100 cost=0.111442  time=(5.0s /5.2s) 
2024-01-28 21:16:24,552 [nnabla]: epoch 96 of 100 cost=0.101054  time=(5.0s /5.2s) 
2024-01-28 21:16:24,593 [nnabla]: epoch 97 of 100 cost=0.101568  time=(5.1s /5.2s) 
2024-01-28 21:16:24,634 [nnabla]: epoch 98 of 100 cost=0.096373  time=(5.1s /5.2s) 
2024-01-28 21:16:24,674 [nnabla]: epoch 99 of 100 cost=0.098705  time=(5.1s /5.2s) 
2024-01-28 21:16:24,795 [nnabla]: epoch 100 of 100 cost=0.093525  {train_error=0.081792, valid_error=0.084067} time=(5.2s /5.2s) 
2024-01-28 21:16:24,812 [nnabla]: Training Completed.
NNabla command line interface (Version:1.33.1, Build:230206070804, Callback:NNabla SSH callback module.)

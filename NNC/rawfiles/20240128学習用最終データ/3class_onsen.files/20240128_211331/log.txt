2024-01-28 21:13:31,817 Training process is started.
python "C:\Users\yamas\Desktop\tools\neural_network_console\libs\Python\Lib\site-packages\nnabla\utils\cli\cli.py" train
	-c "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_211331\net.nntxt"
	-o "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_211331"
2024-01-28 21:13:33,510 [nnabla]: [CALLBACK]: Exec train on local
2024-01-28 21:13:33,518 [nnabla]: Using context "Context(backend=['cpu:float'], array_class='CpuCachedArray', device_id='')"
2024-01-28 21:13:33,518 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_test_3class_onsen.csv"
2024-01-28 21:13:34,416 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_valid_3class_onsen.csv"
2024-01-28 21:13:35,222 [nnabla]: Train with contexts ['cpu']
2024-01-28 21:13:35,259 [nnabla]: Training epoch 1 of 100 begin
2024-01-28 21:13:35,259 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 21:13:35,259 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 21:13:35,461 [nnabla]: epoch 1 of 100 cost=4.542359  {train_error=4.480671, valid_error=4.480768} time=(0.1s /8.5s) 
2024-01-28 21:13:35,551 [nnabla]: epoch 2 of 100 cost=4.423130  {train_error=4.361005, valid_error=4.360776} time=(0.2s /12.1s) 
2024-01-28 21:13:35,639 [nnabla]: epoch 3 of 100 cost=4.302592  {train_error=4.239369, valid_error=4.238659} time=(0.3s /11.0s) 
2024-01-28 21:13:35,728 [nnabla]: epoch 4 of 100 cost=4.179279  {train_error=4.113976, valid_error=4.113138} time=(0.4s /10.5s) 
2024-01-28 21:13:35,827 [nnabla]: epoch 5 of 100 cost=4.051852  {train_error=3.984356, valid_error=3.982833} time=(0.5s /10.2s) 
2024-01-28 21:13:35,867 [nnabla]: epoch 6 of 100 cost=3.920115  time=(0.6s /10.1s) 
2024-01-28 21:13:35,908 [nnabla]: epoch 7 of 100 cost=3.782949  time=(0.6s /9.3s) 
2024-01-28 21:13:35,953 [nnabla]: epoch 8 of 100 cost=3.643379  time=(0.7s /8.7s) 
2024-01-28 21:13:35,994 [nnabla]: epoch 9 of 100 cost=3.500909  time=(0.7s /8.2s) 
2024-01-28 21:13:36,091 [nnabla]: epoch 10 of 100 cost=3.357162  {train_error=3.282871, valid_error=3.279065} time=(0.8s /7.7s) 
2024-01-28 21:13:36,129 [nnabla]: epoch 11 of 100 cost=3.213472  time=(0.9s /7.9s) 
2024-01-28 21:13:36,175 [nnabla]: epoch 12 of 100 cost=3.067360  time=(0.9s /7.6s) 
2024-01-28 21:13:36,217 [nnabla]: epoch 13 of 100 cost=2.924029  time=(1.0s /7.4s) 
2024-01-28 21:13:36,257 [nnabla]: epoch 14 of 100 cost=2.778866  time=(1.0s /7.1s) 
2024-01-28 21:13:36,297 [nnabla]: epoch 15 of 100 cost=2.634909  time=(1.0s /6.9s) 
2024-01-28 21:13:36,333 [nnabla]: epoch 16 of 100 cost=2.498133  time=(1.1s /6.7s) 
2024-01-28 21:13:36,372 [nnabla]: epoch 17 of 100 cost=2.370905  time=(1.1s /6.5s) 
2024-01-28 21:13:36,409 [nnabla]: epoch 18 of 100 cost=2.253543  time=(1.1s /6.4s) 
2024-01-28 21:13:36,447 [nnabla]: epoch 19 of 100 cost=2.143347  time=(1.2s /6.3s) 
2024-01-28 21:13:36,544 [nnabla]: epoch 20 of 100 cost=2.043238  {train_error=1.995332, valid_error=1.991889} time=(1.2s /6.1s) 
2024-01-28 21:13:36,585 [nnabla]: epoch 21 of 100 cost=1.954519  time=(1.3s /6.3s) 
2024-01-28 21:13:36,623 [nnabla]: epoch 22 of 100 cost=1.877315  time=(1.4s /6.2s) 
2024-01-28 21:13:36,668 [nnabla]: epoch 23 of 100 cost=1.811628  time=(1.4s /6.1s) 
2024-01-28 21:13:36,707 [nnabla]: epoch 24 of 100 cost=1.752963  time=(1.4s /6.0s) 
2024-01-28 21:13:36,745 [nnabla]: epoch 25 of 100 cost=1.702397  time=(1.5s /5.9s) 
2024-01-28 21:13:36,784 [nnabla]: epoch 26 of 100 cost=1.657115  time=(1.5s /5.9s) 
2024-01-28 21:13:36,822 [nnabla]: epoch 27 of 100 cost=1.616618  time=(1.6s /5.8s) 
2024-01-28 21:13:36,863 [nnabla]: epoch 28 of 100 cost=1.580618  time=(1.6s /5.7s) 
2024-01-28 21:13:36,908 [nnabla]: epoch 29 of 100 cost=1.548609  time=(1.6s /5.7s) 
2024-01-28 21:13:37,009 [nnabla]: epoch 30 of 100 cost=1.519418  {train_error=1.505140, valid_error=1.504221} time=(1.7s /5.6s) 
2024-01-28 21:13:37,049 [nnabla]: epoch 31 of 100 cost=1.492713  time=(1.8s /5.8s) 
2024-01-28 21:13:37,091 [nnabla]: epoch 32 of 100 cost=1.469451  time=(1.8s /5.7s) 
2024-01-28 21:13:37,132 [nnabla]: epoch 33 of 100 cost=1.447041  time=(1.9s /5.7s) 
2024-01-28 21:13:37,182 [nnabla]: epoch 34 of 100 cost=1.427166  time=(1.9s /5.6s) 
2024-01-28 21:13:37,221 [nnabla]: epoch 35 of 100 cost=1.408981  time=(2.0s /5.6s) 
2024-01-28 21:13:37,261 [nnabla]: epoch 36 of 100 cost=1.392251  time=(2.0s /5.6s) 
2024-01-28 21:13:37,302 [nnabla]: epoch 37 of 100 cost=1.376501  time=(2.0s /5.5s) 
2024-01-28 21:13:37,342 [nnabla]: epoch 38 of 100 cost=1.362679  time=(2.1s /5.5s) 
2024-01-28 21:13:37,383 [nnabla]: epoch 39 of 100 cost=1.349265  time=(2.1s /5.4s) 
2024-01-28 21:13:37,479 [nnabla]: epoch 40 of 100 cost=1.337056  {train_error=1.331065, valid_error=1.330940} time=(2.2s /5.4s) 
2024-01-28 21:13:37,516 [nnabla]: epoch 41 of 100 cost=1.325663  time=(2.3s /5.5s) 
2024-01-28 21:13:37,554 [nnabla]: epoch 42 of 100 cost=1.315206  time=(2.3s /5.5s) 
2024-01-28 21:13:37,594 [nnabla]: epoch 43 of 100 cost=1.305346  time=(2.3s /5.4s) 
2024-01-28 21:13:37,632 [nnabla]: epoch 44 of 100 cost=1.296172  time=(2.4s /5.4s) 
2024-01-28 21:13:37,687 [nnabla]: epoch 45 of 100 cost=1.287469  time=(2.4s /5.4s) 
2024-01-28 21:13:37,725 [nnabla]: epoch 46 of 100 cost=1.279728  time=(2.5s /5.4s) 
2024-01-28 21:13:37,764 [nnabla]: epoch 47 of 100 cost=1.272131  time=(2.5s /5.3s) 
2024-01-28 21:13:37,804 [nnabla]: epoch 48 of 100 cost=1.265050  time=(2.5s /5.3s) 
2024-01-28 21:13:37,841 [nnabla]: epoch 49 of 100 cost=1.258425  time=(2.6s /5.3s) 
2024-01-28 21:13:37,939 [nnabla]: epoch 50 of 100 cost=1.252225  {train_error=1.249036, valid_error=1.249144} time=(2.6s /5.2s) 
2024-01-28 21:13:37,978 [nnabla]: epoch 51 of 100 cost=1.246233  time=(2.7s /5.3s) 
2024-01-28 21:13:38,017 [nnabla]: epoch 52 of 100 cost=1.240814  time=(2.8s /5.3s) 
2024-01-28 21:13:38,056 [nnabla]: epoch 53 of 100 cost=1.235537  time=(2.8s /5.3s) 
2024-01-28 21:13:38,092 [nnabla]: epoch 54 of 100 cost=1.230531  time=(2.8s /5.2s) 
2024-01-28 21:13:38,130 [nnabla]: epoch 55 of 100 cost=1.225919  time=(2.9s /5.2s) 
2024-01-28 21:13:38,176 [nnabla]: epoch 56 of 100 cost=1.221475  time=(2.9s /5.2s) 
2024-01-28 21:13:38,214 [nnabla]: epoch 57 of 100 cost=1.217270  time=(3.0s /5.2s) 
2024-01-28 21:13:38,254 [nnabla]: epoch 58 of 100 cost=1.213225  time=(3.0s /5.2s) 
2024-01-28 21:13:38,292 [nnabla]: epoch 59 of 100 cost=1.209456  time=(3.0s /5.1s) 
2024-01-28 21:13:38,385 [nnabla]: epoch 60 of 100 cost=1.205798  {train_error=1.203990, valid_error=1.204013} time=(3.1s /5.1s) 
2024-01-28 21:13:38,424 [nnabla]: epoch 61 of 100 cost=1.202422  time=(3.2s /5.2s) 
2024-01-28 21:13:38,463 [nnabla]: epoch 62 of 100 cost=1.199148  time=(3.2s /5.2s) 
2024-01-28 21:13:38,501 [nnabla]: epoch 63 of 100 cost=1.196021  time=(3.2s /5.1s) 
2024-01-28 21:13:38,538 [nnabla]: epoch 64 of 100 cost=1.192955  time=(3.3s /5.1s) 
2024-01-28 21:13:38,574 [nnabla]: epoch 65 of 100 cost=1.190130  time=(3.3s /5.1s) 
2024-01-28 21:13:38,612 [nnabla]: epoch 66 of 100 cost=1.187465  time=(3.4s /5.1s) 
2024-01-28 21:13:38,657 [nnabla]: epoch 67 of 100 cost=1.184759  time=(3.4s /5.1s) 
2024-01-28 21:13:38,697 [nnabla]: epoch 68 of 100 cost=1.182363  time=(3.4s /5.1s) 
2024-01-28 21:13:38,735 [nnabla]: epoch 69 of 100 cost=1.179926  time=(3.5s /5.0s) 
2024-01-28 21:13:38,830 [nnabla]: epoch 70 of 100 cost=1.177682  {train_error=1.176436, valid_error=1.176447} time=(3.5s /5.0s) 
2024-01-28 21:13:38,870 [nnabla]: epoch 71 of 100 cost=1.175445  time=(3.6s /5.1s) 
2024-01-28 21:13:38,907 [nnabla]: epoch 72 of 100 cost=1.173350  time=(3.6s /5.1s) 
2024-01-28 21:13:38,944 [nnabla]: epoch 73 of 100 cost=1.171343  time=(3.7s /5.0s) 
2024-01-28 21:13:38,982 [nnabla]: epoch 74 of 100 cost=1.169297  time=(3.7s /5.0s) 
2024-01-28 21:13:39,024 [nnabla]: epoch 75 of 100 cost=1.167531  time=(3.8s /5.0s) 
2024-01-28 21:13:39,066 [nnabla]: epoch 76 of 100 cost=1.165757  time=(3.8s /5.0s) 
2024-01-28 21:13:39,103 [nnabla]: epoch 77 of 100 cost=1.164045  time=(3.8s /5.0s) 
2024-01-28 21:13:39,148 [nnabla]: epoch 78 of 100 cost=1.162345  time=(3.9s /5.0s) 
2024-01-28 21:13:39,187 [nnabla]: epoch 79 of 100 cost=1.160697  time=(3.9s /5.0s) 
2024-01-28 21:13:39,279 [nnabla]: epoch 80 of 100 cost=1.159155  {train_error=1.158356, valid_error=1.158438} time=(4.0s /5.0s) 
2024-01-28 21:13:39,320 [nnabla]: epoch 81 of 100 cost=1.157676  time=(4.1s /5.0s) 
2024-01-28 21:13:39,357 [nnabla]: epoch 82 of 100 cost=1.156241  time=(4.1s /5.0s) 
2024-01-28 21:13:39,395 [nnabla]: epoch 83 of 100 cost=1.154808  time=(4.1s /5.0s) 
2024-01-28 21:13:39,433 [nnabla]: epoch 84 of 100 cost=1.153576  time=(4.2s /5.0s) 
2024-01-28 21:13:39,471 [nnabla]: epoch 85 of 100 cost=1.152197  time=(4.2s /5.0s) 
2024-01-28 21:13:39,509 [nnabla]: epoch 86 of 100 cost=1.151006  time=(4.2s /4.9s) 
2024-01-28 21:13:39,547 [nnabla]: epoch 87 of 100 cost=1.149777  time=(4.3s /4.9s) 
2024-01-28 21:13:39,586 [nnabla]: epoch 88 of 100 cost=1.148579  time=(4.3s /4.9s) 
2024-01-28 21:13:39,633 [nnabla]: epoch 89 of 100 cost=1.147559  time=(4.4s /4.9s) 
2024-01-28 21:13:39,728 [nnabla]: epoch 90 of 100 cost=1.146396  {train_error=1.145789, valid_error=1.145793} time=(4.4s /4.9s) 
2024-01-28 21:13:39,766 [nnabla]: epoch 91 of 100 cost=1.145359  time=(4.5s /5.0s) 
2024-01-28 21:13:39,806 [nnabla]: epoch 92 of 100 cost=1.144287  time=(4.5s /4.9s) 
2024-01-28 21:13:39,845 [nnabla]: epoch 93 of 100 cost=1.143364  time=(4.6s /4.9s) 
2024-01-28 21:13:39,888 [nnabla]: epoch 94 of 100 cost=1.142312  time=(4.6s /4.9s) 
2024-01-28 21:13:39,925 [nnabla]: epoch 95 of 100 cost=1.141440  time=(4.7s /4.9s) 
2024-01-28 21:13:39,961 [nnabla]: epoch 96 of 100 cost=1.140542  time=(4.7s /4.9s) 
2024-01-28 21:13:40,000 [nnabla]: epoch 97 of 100 cost=1.139638  time=(4.7s /4.9s) 
2024-01-28 21:13:40,039 [nnabla]: epoch 98 of 100 cost=1.138813  time=(4.8s /4.9s) 
2024-01-28 21:13:40,078 [nnabla]: epoch 99 of 100 cost=1.137939  time=(4.8s /4.9s) 
2024-01-28 21:13:40,190 [nnabla]: epoch 100 of 100 cost=1.137127  {train_error=1.136719, valid_error=1.136624} time=(4.9s /4.9s) 
2024-01-28 21:13:40,204 [nnabla]: Training Completed.
NNabla command line interface (Version:1.33.1, Build:230206070804, Callback:NNabla SSH callback module.)

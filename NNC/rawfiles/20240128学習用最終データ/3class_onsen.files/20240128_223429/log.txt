2024-01-28 22:34:29,607 Training process is started.
python "C:\Users\yamas\Desktop\tools\neural_network_console\libs\Python\Lib\site-packages\nnabla\utils\cli\cli.py" train
	-c "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_223429\net.nntxt"
	-o "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_223429"
2024-01-28 22:34:30,153 [nnabla]: [CALLBACK]: Exec train on local
2024-01-28 22:34:30,159 [nnabla]: Using context "Context(backend=['cpu:float'], array_class='CpuCachedArray', device_id='')"
2024-01-28 22:34:30,160 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_test_3class_onsen.csv"
2024-01-28 22:34:30,741 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_valid_3class_onsen.csv"
2024-01-28 22:34:31,125 [nnabla]: Train with contexts ['cpu']
2024-01-28 22:34:31,150 [nnabla]: Training epoch 1 of 100 begin
2024-01-28 22:34:31,150 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 22:34:31,150 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 22:34:31,355 [nnabla]: epoch 1 of 100 cost=4.527108  {train_error=4.375250, valid_error=4.389742} time=(0.1s /9.3s) 
2024-01-28 22:34:31,429 [nnabla]: epoch 2 of 100 cost=4.357331  {train_error=4.101264, valid_error=4.097885} time=(0.2s /11.7s) 
2024-01-28 22:34:31,507 [nnabla]: epoch 3 of 100 cost=4.121019  {train_error=3.822159, valid_error=3.808778} time=(0.3s /10.3s) 
2024-01-28 22:34:31,587 [nnabla]: epoch 4 of 100 cost=3.846914  {train_error=3.699780, valid_error=3.681715} time=(0.4s /9.7s) 
2024-01-28 22:34:31,671 [nnabla]: epoch 5 of 100 cost=3.592497  {train_error=3.542107, valid_error=3.520190} time=(0.5s /9.3s) 
2024-01-28 22:34:31,701 [nnabla]: epoch 6 of 100 cost=3.392105  time=(0.6s /9.2s) 
2024-01-28 22:34:31,733 [nnabla]: epoch 7 of 100 cost=3.194687  time=(0.6s /8.3s) 
2024-01-28 22:34:31,763 [nnabla]: epoch 8 of 100 cost=3.006942  time=(0.6s /7.6s) 
2024-01-28 22:34:31,792 [nnabla]: epoch 9 of 100 cost=2.817073  time=(0.6s /7.1s) 
2024-01-28 22:34:31,875 [nnabla]: epoch 10 of 100 cost=2.638595  {train_error=2.493091, valid_error=2.490511} time=(0.7s /6.7s) 
2024-01-28 22:34:31,906 [nnabla]: epoch 11 of 100 cost=2.480834  time=(0.8s /6.9s) 
2024-01-28 22:34:31,942 [nnabla]: epoch 12 of 100 cost=2.338993  time=(0.8s /6.5s) 
2024-01-28 22:34:31,975 [nnabla]: epoch 13 of 100 cost=2.222019  time=(0.8s /6.3s) 
2024-01-28 22:34:32,004 [nnabla]: epoch 14 of 100 cost=2.112206  time=(0.9s /6.1s) 
2024-01-28 22:34:32,033 [nnabla]: epoch 15 of 100 cost=2.004727  time=(0.9s /5.9s) 
2024-01-28 22:34:32,063 [nnabla]: epoch 16 of 100 cost=1.908618  time=(0.9s /5.7s) 
2024-01-28 22:34:32,093 [nnabla]: epoch 17 of 100 cost=1.813346  time=(0.9s /5.5s) 
2024-01-28 22:34:32,123 [nnabla]: epoch 18 of 100 cost=1.735503  time=(1.0s /5.4s) 
2024-01-28 22:34:32,152 [nnabla]: epoch 19 of 100 cost=1.641187  time=(1.0s /5.3s) 
2024-01-28 22:34:32,237 [nnabla]: epoch 20 of 100 cost=1.575399  {train_error=1.476979, valid_error=1.476551} time=(1.0s /5.2s) 
2024-01-28 22:34:32,267 [nnabla]: epoch 21 of 100 cost=1.490145  time=(1.1s /5.3s) 
2024-01-28 22:34:32,296 [nnabla]: epoch 22 of 100 cost=1.427958  time=(1.1s /5.2s) 
2024-01-28 22:34:32,334 [nnabla]: epoch 23 of 100 cost=1.353790  time=(1.2s /5.1s) 
2024-01-28 22:34:32,365 [nnabla]: epoch 24 of 100 cost=1.285769  time=(1.2s /5.1s) 
2024-01-28 22:34:32,394 [nnabla]: epoch 25 of 100 cost=1.237747  time=(1.2s /5.0s) 
2024-01-28 22:34:32,424 [nnabla]: epoch 26 of 100 cost=1.166573  time=(1.3s /4.9s) 
2024-01-28 22:34:32,454 [nnabla]: epoch 27 of 100 cost=1.130577  time=(1.3s /4.8s) 
2024-01-28 22:34:32,485 [nnabla]: epoch 28 of 100 cost=1.070845  time=(1.3s /4.8s) 
2024-01-28 22:34:32,515 [nnabla]: epoch 29 of 100 cost=1.023055  time=(1.4s /4.7s) 
2024-01-28 22:34:32,596 [nnabla]: epoch 30 of 100 cost=0.967529  {train_error=0.903286, valid_error=0.902135} time=(1.4s /4.6s) 
2024-01-28 22:34:32,626 [nnabla]: epoch 31 of 100 cost=0.924921  time=(1.5s /4.8s) 
2024-01-28 22:34:32,657 [nnabla]: epoch 32 of 100 cost=0.881478  time=(1.5s /4.7s) 
2024-01-28 22:34:32,687 [nnabla]: epoch 33 of 100 cost=0.838037  time=(1.5s /4.7s) 
2024-01-28 22:34:32,723 [nnabla]: epoch 34 of 100 cost=0.803822  time=(1.6s /4.6s) 
2024-01-28 22:34:32,754 [nnabla]: epoch 35 of 100 cost=0.764537  time=(1.6s /4.6s) 
2024-01-28 22:34:32,783 [nnabla]: epoch 36 of 100 cost=0.728632  time=(1.6s /4.5s) 
2024-01-28 22:34:32,813 [nnabla]: epoch 37 of 100 cost=0.711644  time=(1.7s /4.5s) 
2024-01-28 22:34:32,843 [nnabla]: epoch 38 of 100 cost=0.679525  time=(1.7s /4.5s) 
2024-01-28 22:34:32,874 [nnabla]: epoch 39 of 100 cost=0.634985  time=(1.7s /4.4s) 
2024-01-28 22:34:32,957 [nnabla]: epoch 40 of 100 cost=0.614694  {train_error=0.571060, valid_error=0.568360} time=(1.8s /4.4s) 
2024-01-28 22:34:32,987 [nnabla]: epoch 41 of 100 cost=0.581875  time=(1.8s /4.5s) 
2024-01-28 22:34:33,017 [nnabla]: epoch 42 of 100 cost=0.564172  time=(1.9s /4.4s) 
2024-01-28 22:34:33,049 [nnabla]: epoch 43 of 100 cost=0.541860  time=(1.9s /4.4s) 
2024-01-28 22:34:33,078 [nnabla]: epoch 44 of 100 cost=0.511262  time=(1.9s /4.4s) 
2024-01-28 22:34:33,122 [nnabla]: epoch 45 of 100 cost=0.490257  time=(2.0s /4.3s) 
2024-01-28 22:34:33,152 [nnabla]: epoch 46 of 100 cost=0.478594  time=(2.0s /4.4s) 
2024-01-28 22:34:33,180 [nnabla]: epoch 47 of 100 cost=0.454169  time=(2.0s /4.3s) 
2024-01-28 22:34:33,209 [nnabla]: epoch 48 of 100 cost=0.436709  time=(2.1s /4.3s) 
2024-01-28 22:34:33,239 [nnabla]: epoch 49 of 100 cost=0.419806  time=(2.1s /4.3s) 
2024-01-28 22:34:33,323 [nnabla]: epoch 50 of 100 cost=0.398533  {train_error=0.377300, valid_error=0.380765} time=(2.1s /4.2s) 
2024-01-28 22:34:33,352 [nnabla]: epoch 51 of 100 cost=0.394910  time=(2.2s /4.3s) 
2024-01-28 22:34:33,382 [nnabla]: epoch 52 of 100 cost=0.376974  time=(2.2s /4.3s) 
2024-01-28 22:34:33,412 [nnabla]: epoch 53 of 100 cost=0.364551  time=(2.3s /4.3s) 
2024-01-28 22:34:33,442 [nnabla]: epoch 54 of 100 cost=0.348713  time=(2.3s /4.2s) 
2024-01-28 22:34:33,473 [nnabla]: epoch 55 of 100 cost=0.336947  time=(2.3s /4.2s) 
2024-01-28 22:34:33,509 [nnabla]: epoch 56 of 100 cost=0.318647  time=(2.4s /4.2s) 
2024-01-28 22:34:33,539 [nnabla]: epoch 57 of 100 cost=0.314362  time=(2.4s /4.2s) 
2024-01-28 22:34:33,570 [nnabla]: epoch 58 of 100 cost=0.296348  time=(2.4s /4.2s) 
2024-01-28 22:34:33,602 [nnabla]: epoch 59 of 100 cost=0.287617  time=(2.5s /4.2s) 
2024-01-28 22:34:33,685 [nnabla]: epoch 60 of 100 cost=0.275593  {train_error=0.261493, valid_error=0.255550} time=(2.5s /4.1s) 
2024-01-28 22:34:33,716 [nnabla]: epoch 61 of 100 cost=0.271088  time=(2.6s /4.2s) 
2024-01-28 22:34:33,745 [nnabla]: epoch 62 of 100 cost=0.269079  time=(2.6s /4.2s) 
2024-01-28 22:34:33,775 [nnabla]: epoch 63 of 100 cost=0.253779  time=(2.6s /4.2s) 
2024-01-28 22:34:33,804 [nnabla]: epoch 64 of 100 cost=0.250625  time=(2.7s /4.1s) 
2024-01-28 22:34:33,834 [nnabla]: epoch 65 of 100 cost=0.237237  time=(2.7s /4.1s) 
2024-01-28 22:34:33,866 [nnabla]: epoch 66 of 100 cost=0.235921  time=(2.7s /4.1s) 
2024-01-28 22:34:33,908 [nnabla]: epoch 67 of 100 cost=0.222952  time=(2.8s /4.1s) 
2024-01-28 22:34:33,937 [nnabla]: epoch 68 of 100 cost=0.212360  time=(2.8s /4.1s) 
2024-01-28 22:34:33,966 [nnabla]: epoch 69 of 100 cost=0.208367  time=(2.8s /4.1s) 
2024-01-28 22:34:34,052 [nnabla]: epoch 70 of 100 cost=0.211216  {train_error=0.179132, valid_error=0.175201} time=(2.8s /4.1s) 
2024-01-28 22:34:34,082 [nnabla]: epoch 71 of 100 cost=0.197353  time=(2.9s /4.1s) 
2024-01-28 22:34:34,112 [nnabla]: epoch 72 of 100 cost=0.192665  time=(3.0s /4.1s) 
2024-01-28 22:34:34,144 [nnabla]: epoch 73 of 100 cost=0.187938  time=(3.0s /4.1s) 
2024-01-28 22:34:34,174 [nnabla]: epoch 74 of 100 cost=0.180699  time=(3.0s /4.1s) 
2024-01-28 22:34:34,203 [nnabla]: epoch 75 of 100 cost=0.173988  time=(3.1s /4.1s) 
2024-01-28 22:34:34,234 [nnabla]: epoch 76 of 100 cost=0.170515  time=(3.1s /4.1s) 
2024-01-28 22:34:34,263 [nnabla]: epoch 77 of 100 cost=0.161197  time=(3.1s /4.0s) 
2024-01-28 22:34:34,303 [nnabla]: epoch 78 of 100 cost=0.162898  time=(3.1s /4.0s) 
2024-01-28 22:34:34,333 [nnabla]: epoch 79 of 100 cost=0.154456  time=(3.2s /4.0s) 
2024-01-28 22:34:34,422 [nnabla]: epoch 80 of 100 cost=0.152926  {train_error=0.133189, valid_error=0.133155} time=(3.2s /4.0s) 
2024-01-28 22:34:34,452 [nnabla]: epoch 81 of 100 cost=0.150786  time=(3.3s /4.1s) 
2024-01-28 22:34:34,482 [nnabla]: epoch 82 of 100 cost=0.147811  time=(3.3s /4.1s) 
2024-01-28 22:34:34,511 [nnabla]: epoch 83 of 100 cost=0.142473  time=(3.4s /4.0s) 
2024-01-28 22:34:34,540 [nnabla]: epoch 84 of 100 cost=0.136047  time=(3.4s /4.0s) 
2024-01-28 22:34:34,572 [nnabla]: epoch 85 of 100 cost=0.129761  time=(3.4s /4.0s) 
2024-01-28 22:34:34,604 [nnabla]: epoch 86 of 100 cost=0.132203  time=(3.5s /4.0s) 
2024-01-28 22:34:34,635 [nnabla]: epoch 87 of 100 cost=0.127037  time=(3.5s /4.0s) 
2024-01-28 22:34:34,669 [nnabla]: epoch 88 of 100 cost=0.130174  time=(3.5s /4.0s) 
2024-01-28 22:34:34,707 [nnabla]: epoch 89 of 100 cost=0.124047  time=(3.5s /4.0s) 
2024-01-28 22:34:34,789 [nnabla]: epoch 90 of 100 cost=0.119277  {train_error=0.102712, valid_error=0.101672} time=(3.6s /4.0s) 
2024-01-28 22:34:34,819 [nnabla]: epoch 91 of 100 cost=0.117812  time=(3.7s /4.0s) 
2024-01-28 22:34:34,849 [nnabla]: epoch 92 of 100 cost=0.108652  time=(3.7s /4.0s) 
2024-01-28 22:34:34,878 [nnabla]: epoch 93 of 100 cost=0.113720  time=(3.7s /4.0s) 
2024-01-28 22:34:34,908 [nnabla]: epoch 94 of 100 cost=0.103686  time=(3.8s /4.0s) 
2024-01-28 22:34:34,938 [nnabla]: epoch 95 of 100 cost=0.109356  time=(3.8s /4.0s) 
2024-01-28 22:34:34,967 [nnabla]: epoch 96 of 100 cost=0.098164  time=(3.8s /4.0s) 
2024-01-28 22:34:34,998 [nnabla]: epoch 97 of 100 cost=0.099413  time=(3.8s /4.0s) 
2024-01-28 22:34:35,027 [nnabla]: epoch 98 of 100 cost=0.094277  time=(3.9s /4.0s) 
2024-01-28 22:34:35,057 [nnabla]: epoch 99 of 100 cost=0.096725  time=(3.9s /3.9s) 
2024-01-28 22:34:35,156 [nnabla]: epoch 100 of 100 cost=0.091927  {train_error=0.079909, valid_error=0.079879} time=(3.9s /3.9s) 
2024-01-28 22:34:35,171 [nnabla]: Training Completed.
NNabla command line interface (Version:1.33.1, Build:230206070804, Callback:NNabla SSH callback module.)

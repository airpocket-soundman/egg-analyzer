2024-01-28 22:24:23,006 Training process is started.
python "C:\Users\yamas\Desktop\tools\neural_network_console\libs\Python\Lib\site-packages\nnabla\utils\cli\cli.py" train
	-c "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_222422\net.nntxt"
	-o "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_222422"
2024-01-28 22:24:23,539 [nnabla]: [CALLBACK]: Exec train on local
2024-01-28 22:24:23,545 [nnabla]: Using context "Context(backend=['cpu:float'], array_class='CpuCachedArray', device_id='')"
2024-01-28 22:24:23,545 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_test_3class_onsen.csv"
2024-01-28 22:24:24,125 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_valid_3class_onsen.csv"
2024-01-28 22:24:24,507 [nnabla]: Train with contexts ['cpu']
2024-01-28 22:24:24,529 [nnabla]: Training epoch 1 of 100 begin
2024-01-28 22:24:24,530 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 22:24:24,530 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 22:24:24,735 [nnabla]: epoch 1 of 100 cost=4.579324  {train_error=5.301450, valid_error=5.269840} time=(0.1s /9.4s) 
2024-01-28 22:24:24,816 [nnabla]: epoch 2 of 100 cost=4.525693  {train_error=4.493724, valid_error=4.495446} time=(0.2s /12.2s) 
2024-01-28 22:24:24,888 [nnabla]: epoch 3 of 100 cost=4.472149  {train_error=4.605365, valid_error=4.602303} time=(0.3s /10.8s) 
2024-01-28 22:24:24,961 [nnabla]: epoch 4 of 100 cost=4.418746  {train_error=4.588955, valid_error=4.588031} time=(0.4s /9.9s) 
2024-01-28 22:24:25,050 [nnabla]: epoch 5 of 100 cost=4.365507  {train_error=4.340765, valid_error=4.356831} time=(0.5s /9.4s) 
2024-01-28 22:24:25,090 [nnabla]: epoch 6 of 100 cost=4.312405  time=(0.6s /9.3s) 
2024-01-28 22:24:25,128 [nnabla]: epoch 7 of 100 cost=4.259474  time=(0.6s /8.5s) 
2024-01-28 22:24:25,169 [nnabla]: epoch 8 of 100 cost=4.206711  time=(0.6s /8.0s) 
2024-01-28 22:24:25,208 [nnabla]: epoch 9 of 100 cost=4.154138  time=(0.7s /7.5s) 
2024-01-28 22:24:25,295 [nnabla]: epoch 10 of 100 cost=4.101783  {train_error=4.239918, valid_error=4.245453} time=(0.7s /7.2s) 
2024-01-28 22:24:25,334 [nnabla]: epoch 11 of 100 cost=4.049627  time=(0.8s /7.3s) 
2024-01-28 22:24:25,384 [nnabla]: epoch 12 of 100 cost=3.997712  time=(0.8s /7.0s) 
2024-01-28 22:24:25,425 [nnabla]: epoch 13 of 100 cost=3.946022  time=(0.9s /6.9s) 
2024-01-28 22:24:25,462 [nnabla]: epoch 14 of 100 cost=3.894599  time=(0.9s /6.7s) 
2024-01-28 22:24:25,503 [nnabla]: epoch 15 of 100 cost=3.843432  time=(1.0s /6.5s) 
2024-01-28 22:24:25,542 [nnabla]: epoch 16 of 100 cost=3.792538  time=(1.0s /6.3s) 
2024-01-28 22:24:25,585 [nnabla]: epoch 17 of 100 cost=3.741936  time=(1.1s /6.2s) 
2024-01-28 22:24:25,625 [nnabla]: epoch 18 of 100 cost=3.691626  time=(1.1s /6.1s) 
2024-01-28 22:24:25,664 [nnabla]: epoch 19 of 100 cost=3.641646  time=(1.1s /6.0s) 
2024-01-28 22:24:25,751 [nnabla]: epoch 20 of 100 cost=3.591980  {train_error=3.306561, valid_error=3.292039} time=(1.2s /5.9s) 
2024-01-28 22:24:25,790 [nnabla]: epoch 21 of 100 cost=3.542654  time=(1.3s /6.0s) 
2024-01-28 22:24:25,834 [nnabla]: epoch 22 of 100 cost=3.493693  time=(1.3s /5.9s) 
2024-01-28 22:24:25,884 [nnabla]: epoch 23 of 100 cost=3.445103  time=(1.3s /5.8s) 
2024-01-28 22:24:25,923 [nnabla]: epoch 24 of 100 cost=3.396894  time=(1.4s /5.8s) 
2024-01-28 22:24:25,962 [nnabla]: epoch 25 of 100 cost=3.349079  time=(1.4s /5.7s) 
2024-01-28 22:24:26,001 [nnabla]: epoch 26 of 100 cost=3.301684  time=(1.5s /5.7s) 
2024-01-28 22:24:26,040 [nnabla]: epoch 27 of 100 cost=3.254726  time=(1.5s /5.6s) 
2024-01-28 22:24:26,079 [nnabla]: epoch 28 of 100 cost=3.208213  time=(1.5s /5.5s) 
2024-01-28 22:24:26,120 [nnabla]: epoch 29 of 100 cost=3.162182  time=(1.6s /5.5s) 
2024-01-28 22:24:26,195 [nnabla]: epoch 30 of 100 cost=3.116589  {train_error=3.333617, valid_error=3.323557} time=(1.6s /5.4s) 
2024-01-28 22:24:26,232 [nnabla]: epoch 31 of 100 cost=3.071541  time=(1.7s /5.5s) 
2024-01-28 22:24:26,273 [nnabla]: epoch 32 of 100 cost=3.026962  time=(1.7s /5.4s) 
2024-01-28 22:24:26,310 [nnabla]: epoch 33 of 100 cost=2.982944  time=(1.8s /5.4s) 
2024-01-28 22:24:26,358 [nnabla]: epoch 34 of 100 cost=2.939437  time=(1.8s /5.4s) 
2024-01-28 22:24:26,401 [nnabla]: epoch 35 of 100 cost=2.896492  time=(1.9s /5.3s) 
2024-01-28 22:24:26,440 [nnabla]: epoch 36 of 100 cost=2.854113  time=(1.9s /5.3s) 
2024-01-28 22:24:26,479 [nnabla]: epoch 37 of 100 cost=2.812333  time=(1.9s /5.3s) 
2024-01-28 22:24:26,521 [nnabla]: epoch 38 of 100 cost=2.771152  time=(2.0s /5.2s) 
2024-01-28 22:24:26,560 [nnabla]: epoch 39 of 100 cost=2.730540  time=(2.0s /5.2s) 
2024-01-28 22:24:26,646 [nnabla]: epoch 40 of 100 cost=2.690607  {train_error=2.742494, valid_error=2.731206} time=(2.1s /5.2s) 
2024-01-28 22:24:26,690 [nnabla]: epoch 41 of 100 cost=2.651260  time=(2.2s /5.3s) 
2024-01-28 22:24:26,730 [nnabla]: epoch 42 of 100 cost=2.612609  time=(2.2s /5.2s) 
2024-01-28 22:24:26,771 [nnabla]: epoch 43 of 100 cost=2.574583  time=(2.2s /5.2s) 
2024-01-28 22:24:26,813 [nnabla]: epoch 44 of 100 cost=2.537224  time=(2.3s /5.2s) 
2024-01-28 22:24:26,867 [nnabla]: epoch 45 of 100 cost=2.500528  time=(2.3s /5.2s) 
2024-01-28 22:24:26,907 [nnabla]: epoch 46 of 100 cost=2.464555  time=(2.4s /5.2s) 
2024-01-28 22:24:26,946 [nnabla]: epoch 47 of 100 cost=2.429226  time=(2.4s /5.1s) 
2024-01-28 22:24:26,986 [nnabla]: epoch 48 of 100 cost=2.394608  time=(2.5s /5.1s) 
2024-01-28 22:24:27,025 [nnabla]: epoch 49 of 100 cost=2.360696  time=(2.5s /5.1s) 
2024-01-28 22:24:27,111 [nnabla]: epoch 50 of 100 cost=2.327475  {train_error=2.318117, valid_error=2.306264} time=(2.5s /5.1s) 
2024-01-28 22:24:27,151 [nnabla]: epoch 51 of 100 cost=2.294952  time=(2.6s /5.1s) 
2024-01-28 22:24:27,191 [nnabla]: epoch 52 of 100 cost=2.263167  time=(2.7s /5.1s) 
2024-01-28 22:24:27,229 [nnabla]: epoch 53 of 100 cost=2.232076  time=(2.7s /5.1s) 
2024-01-28 22:24:27,269 [nnabla]: epoch 54 of 100 cost=2.201696  time=(2.7s /5.1s) 
2024-01-28 22:24:27,307 [nnabla]: epoch 55 of 100 cost=2.172019  time=(2.8s /5.0s) 
2024-01-28 22:24:27,354 [nnabla]: epoch 56 of 100 cost=2.143050  time=(2.8s /5.0s) 
2024-01-28 22:24:27,393 [nnabla]: epoch 57 of 100 cost=2.114773  time=(2.9s /5.0s) 
2024-01-28 22:24:27,434 [nnabla]: epoch 58 of 100 cost=2.087213  time=(2.9s /5.0s) 
2024-01-28 22:24:27,474 [nnabla]: epoch 59 of 100 cost=2.060319  time=(2.9s /5.0s) 
2024-01-28 22:24:27,561 [nnabla]: epoch 60 of 100 cost=2.034125  {train_error=1.913067, valid_error=1.903997} time=(3.0s /5.0s) 
2024-01-28 22:24:27,602 [nnabla]: epoch 61 of 100 cost=2.008617  time=(3.1s /5.0s) 
2024-01-28 22:24:27,640 [nnabla]: epoch 62 of 100 cost=1.983771  time=(3.1s /5.0s) 
2024-01-28 22:24:27,680 [nnabla]: epoch 63 of 100 cost=1.959578  time=(3.1s /5.0s) 
2024-01-28 22:24:27,719 [nnabla]: epoch 64 of 100 cost=1.936043  time=(3.2s /5.0s) 
2024-01-28 22:24:27,758 [nnabla]: epoch 65 of 100 cost=1.913149  time=(3.2s /5.0s) 
2024-01-28 22:24:27,796 [nnabla]: epoch 66 of 100 cost=1.890932  time=(3.3s /4.9s) 
2024-01-28 22:24:27,844 [nnabla]: epoch 67 of 100 cost=1.869282  time=(3.3s /4.9s) 
2024-01-28 22:24:27,884 [nnabla]: epoch 68 of 100 cost=1.848282  time=(3.4s /4.9s) 
2024-01-28 22:24:27,923 [nnabla]: epoch 69 of 100 cost=1.827855  time=(3.4s /4.9s) 
2024-01-28 22:24:28,011 [nnabla]: epoch 70 of 100 cost=1.808044  {train_error=1.856524, valid_error=1.849699} time=(3.4s /4.9s) 
2024-01-28 22:24:28,050 [nnabla]: epoch 71 of 100 cost=1.788779  time=(3.5s /5.0s) 
2024-01-28 22:24:28,089 [nnabla]: epoch 72 of 100 cost=1.770091  time=(3.6s /4.9s) 
2024-01-28 22:24:28,129 [nnabla]: epoch 73 of 100 cost=1.751967  time=(3.6s /4.9s) 
2024-01-28 22:24:28,168 [nnabla]: epoch 74 of 100 cost=1.734353  time=(3.6s /4.9s) 
2024-01-28 22:24:28,208 [nnabla]: epoch 75 of 100 cost=1.717274  time=(3.7s /4.9s) 
2024-01-28 22:24:28,247 [nnabla]: epoch 76 of 100 cost=1.700741  time=(3.7s /4.9s) 
2024-01-28 22:24:28,285 [nnabla]: epoch 77 of 100 cost=1.684648  time=(3.8s /4.9s) 
2024-01-28 22:24:28,331 [nnabla]: epoch 78 of 100 cost=1.669075  time=(3.8s /4.9s) 
2024-01-28 22:24:28,371 [nnabla]: epoch 79 of 100 cost=1.653948  time=(3.8s /4.9s) 
2024-01-28 22:24:28,459 [nnabla]: epoch 80 of 100 cost=1.639299  {train_error=1.592702, valid_error=1.587577} time=(3.9s /4.9s) 
2024-01-28 22:24:28,498 [nnabla]: epoch 81 of 100 cost=1.625085  time=(4.0s /4.9s) 
2024-01-28 22:24:28,537 [nnabla]: epoch 82 of 100 cost=1.611320  time=(4.0s /4.9s) 
2024-01-28 22:24:28,576 [nnabla]: epoch 83 of 100 cost=1.597953  time=(4.0s /4.9s) 
2024-01-28 22:24:28,616 [nnabla]: epoch 84 of 100 cost=1.585018  time=(4.1s /4.9s) 
2024-01-28 22:24:28,656 [nnabla]: epoch 85 of 100 cost=1.572457  time=(4.1s /4.9s) 
2024-01-28 22:24:28,695 [nnabla]: epoch 86 of 100 cost=1.560304  time=(4.2s /4.8s) 
2024-01-28 22:24:28,735 [nnabla]: epoch 87 of 100 cost=1.548497  time=(4.2s /4.8s) 
2024-01-28 22:24:28,775 [nnabla]: epoch 88 of 100 cost=1.537058  time=(4.2s /4.8s) 
2024-01-28 22:24:28,819 [nnabla]: epoch 89 of 100 cost=1.526000  time=(4.3s /4.8s) 
2024-01-28 22:24:28,907 [nnabla]: epoch 90 of 100 cost=1.515230  {train_error=1.513297, valid_error=1.510297} time=(4.3s /4.8s) 
2024-01-28 22:24:28,947 [nnabla]: epoch 91 of 100 cost=1.504824  time=(4.4s /4.9s) 
2024-01-28 22:24:28,986 [nnabla]: epoch 92 of 100 cost=1.494720  time=(4.5s /4.8s) 
2024-01-28 22:24:29,026 [nnabla]: epoch 93 of 100 cost=1.484922  time=(4.5s /4.8s) 
2024-01-28 22:24:29,063 [nnabla]: epoch 94 of 100 cost=1.475416  time=(4.5s /4.8s) 
2024-01-28 22:24:29,105 [nnabla]: epoch 95 of 100 cost=1.466209  time=(4.6s /4.8s) 
2024-01-28 22:24:29,146 [nnabla]: epoch 96 of 100 cost=1.457272  time=(4.6s /4.8s) 
2024-01-28 22:24:29,184 [nnabla]: epoch 97 of 100 cost=1.448601  time=(4.7s /4.8s) 
2024-01-28 22:24:29,224 [nnabla]: epoch 98 of 100 cost=1.440199  time=(4.7s /4.8s) 
2024-01-28 22:24:29,263 [nnabla]: epoch 99 of 100 cost=1.432028  time=(4.7s /4.8s) 
2024-01-28 22:24:29,368 [nnabla]: epoch 100 of 100 cost=1.424106  {train_error=1.476801, valid_error=1.458656} time=(4.8s /4.8s) 
2024-01-28 22:24:29,385 [nnabla]: Training Completed.
NNabla command line interface (Version:1.33.1, Build:230206070804, Callback:NNabla SSH callback module.)

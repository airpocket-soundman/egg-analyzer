2024-01-28 22:30:11,999 Training process is started.
python "C:\Users\yamas\Desktop\tools\neural_network_console\libs\Python\Lib\site-packages\nnabla\utils\cli\cli.py" train
	-c "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_223011\net.nntxt"
	-o "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_223011"
2024-01-28 22:30:12,539 [nnabla]: [CALLBACK]: Exec train on local
2024-01-28 22:30:12,545 [nnabla]: Using context "Context(backend=['cpu:float'], array_class='CpuCachedArray', device_id='')"
2024-01-28 22:30:12,546 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_test_3class_onsen.csv"
2024-01-28 22:30:13,125 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_valid_3class_onsen.csv"
2024-01-28 22:30:13,509 [nnabla]: Train with contexts ['cpu']
2024-01-28 22:30:13,533 [nnabla]: Training epoch 1 of 100 begin
2024-01-28 22:30:13,533 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 22:30:13,533 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 22:30:13,736 [nnabla]: epoch 1 of 100 cost=4.356077  {train_error=4.054480, valid_error=4.026872} time=(0.1s /9.4s) 
2024-01-28 22:30:13,829 [nnabla]: epoch 2 of 100 cost=3.890266  {train_error=3.502925, valid_error=3.464646} time=(0.2s /12.3s) 
2024-01-28 22:30:13,923 [nnabla]: epoch 3 of 100 cost=3.555715  {train_error=3.384728, valid_error=3.347605} time=(0.3s /11.4s) 
2024-01-28 22:30:14,016 [nnabla]: epoch 4 of 100 cost=3.316973  {train_error=3.226200, valid_error=3.202320} time=(0.4s /10.9s) 
2024-01-28 22:30:14,119 [nnabla]: epoch 5 of 100 cost=3.128057  {train_error=2.953189, valid_error=2.935148} time=(0.5s /10.6s) 
2024-01-28 22:30:14,164 [nnabla]: epoch 6 of 100 cost=2.980584  time=(0.6s /10.5s) 
2024-01-28 22:30:14,209 [nnabla]: epoch 7 of 100 cost=2.858568  time=(0.7s /9.7s) 
2024-01-28 22:30:14,255 [nnabla]: epoch 8 of 100 cost=2.737461  time=(0.7s /9.0s) 
2024-01-28 22:30:14,299 [nnabla]: epoch 9 of 100 cost=2.638901  time=(0.8s /8.5s) 
2024-01-28 22:30:14,399 [nnabla]: epoch 10 of 100 cost=2.536485  {train_error=2.384483, valid_error=2.393307} time=(0.8s /8.1s) 
2024-01-28 22:30:14,445 [nnabla]: epoch 11 of 100 cost=2.432763  time=(0.9s /8.3s) 
2024-01-28 22:30:14,499 [nnabla]: epoch 12 of 100 cost=2.340217  time=(1.0s /8.0s) 
2024-01-28 22:30:14,543 [nnabla]: epoch 13 of 100 cost=2.259616  time=(1.0s /7.8s) 
2024-01-28 22:30:14,587 [nnabla]: epoch 14 of 100 cost=2.174113  time=(1.1s /7.5s) 
2024-01-28 22:30:14,634 [nnabla]: epoch 15 of 100 cost=2.095874  time=(1.1s /7.3s) 
2024-01-28 22:30:14,678 [nnabla]: epoch 16 of 100 cost=2.020360  time=(1.1s /7.2s) 
2024-01-28 22:30:14,722 [nnabla]: epoch 17 of 100 cost=1.924734  time=(1.2s /7.0s) 
2024-01-28 22:30:14,766 [nnabla]: epoch 18 of 100 cost=1.863258  time=(1.2s /6.9s) 
2024-01-28 22:30:14,811 [nnabla]: epoch 19 of 100 cost=1.775761  time=(1.3s /6.7s) 
2024-01-28 22:30:14,911 [nnabla]: epoch 20 of 100 cost=1.716120  {train_error=1.529155, valid_error=1.538054} time=(1.3s /6.6s) 
2024-01-28 22:30:14,956 [nnabla]: epoch 21 of 100 cost=1.637856  time=(1.4s /6.8s) 
2024-01-28 22:30:15,000 [nnabla]: epoch 22 of 100 cost=1.585142  time=(1.5s /6.7s) 
2024-01-28 22:30:15,053 [nnabla]: epoch 23 of 100 cost=1.512958  time=(1.5s /6.6s) 
2024-01-28 22:30:15,099 [nnabla]: epoch 24 of 100 cost=1.450372  time=(1.6s /6.5s) 
2024-01-28 22:30:15,145 [nnabla]: epoch 25 of 100 cost=1.392587  time=(1.6s /6.4s) 
2024-01-28 22:30:15,191 [nnabla]: epoch 26 of 100 cost=1.330624  time=(1.7s /6.4s) 
2024-01-28 22:30:15,236 [nnabla]: epoch 27 of 100 cost=1.295918  time=(1.7s /6.3s) 
2024-01-28 22:30:15,282 [nnabla]: epoch 28 of 100 cost=1.234522  time=(1.7s /6.2s) 
2024-01-28 22:30:15,326 [nnabla]: epoch 29 of 100 cost=1.187555  time=(1.8s /6.2s) 
2024-01-28 22:30:15,429 [nnabla]: epoch 30 of 100 cost=1.123329  {train_error=1.007060, valid_error=1.015920} time=(1.8s /6.1s) 
2024-01-28 22:30:15,478 [nnabla]: epoch 31 of 100 cost=1.082965  time=(1.9s /6.3s) 
2024-01-28 22:30:15,522 [nnabla]: epoch 32 of 100 cost=1.041026  time=(2.0s /6.2s) 
2024-01-28 22:30:15,566 [nnabla]: epoch 33 of 100 cost=0.985173  time=(2.0s /6.2s) 
2024-01-28 22:30:15,618 [nnabla]: epoch 34 of 100 cost=0.947359  time=(2.1s /6.1s) 
2024-01-28 22:30:15,662 [nnabla]: epoch 35 of 100 cost=0.908802  time=(2.1s /6.1s) 
2024-01-28 22:30:15,710 [nnabla]: epoch 36 of 100 cost=0.867299  time=(2.2s /6.0s) 
2024-01-28 22:30:15,756 [nnabla]: epoch 37 of 100 cost=0.845002  time=(2.2s /6.0s) 
2024-01-28 22:30:15,799 [nnabla]: epoch 38 of 100 cost=0.818068  time=(2.3s /6.0s) 
2024-01-28 22:30:15,844 [nnabla]: epoch 39 of 100 cost=0.765102  time=(2.3s /5.9s) 
2024-01-28 22:30:15,944 [nnabla]: epoch 40 of 100 cost=0.745294  {train_error=0.607522, valid_error=0.614210} time=(2.4s /5.9s) 
2024-01-28 22:30:15,991 [nnabla]: epoch 41 of 100 cost=0.699830  time=(2.5s /6.0s) 
2024-01-28 22:30:16,037 [nnabla]: epoch 42 of 100 cost=0.670112  time=(2.5s /6.0s) 
2024-01-28 22:30:16,080 [nnabla]: epoch 43 of 100 cost=0.657101  time=(2.5s /5.9s) 
2024-01-28 22:30:16,122 [nnabla]: epoch 44 of 100 cost=0.612503  time=(2.6s /5.9s) 
2024-01-28 22:30:16,184 [nnabla]: epoch 45 of 100 cost=0.586427  time=(2.6s /5.9s) 
2024-01-28 22:30:16,231 [nnabla]: epoch 46 of 100 cost=0.572990  time=(2.7s /5.9s) 
2024-01-28 22:30:16,278 [nnabla]: epoch 47 of 100 cost=0.548437  time=(2.7s /5.8s) 
2024-01-28 22:30:16,322 [nnabla]: epoch 48 of 100 cost=0.525253  time=(2.8s /5.8s) 
2024-01-28 22:30:16,367 [nnabla]: epoch 49 of 100 cost=0.501088  time=(2.8s /5.8s) 
2024-01-28 22:30:16,472 [nnabla]: epoch 50 of 100 cost=0.475204  {train_error=0.384322, valid_error=0.392023} time=(2.9s /5.8s) 
2024-01-28 22:30:16,517 [nnabla]: epoch 51 of 100 cost=0.469726  time=(3.0s /5.8s) 
2024-01-28 22:30:16,563 [nnabla]: epoch 52 of 100 cost=0.449522  time=(3.0s /5.8s) 
2024-01-28 22:30:16,609 [nnabla]: epoch 53 of 100 cost=0.434206  time=(3.1s /5.8s) 
2024-01-28 22:30:16,652 [nnabla]: epoch 54 of 100 cost=0.414409  time=(3.1s /5.8s) 
2024-01-28 22:30:16,697 [nnabla]: epoch 55 of 100 cost=0.399817  time=(3.2s /5.8s) 
2024-01-28 22:30:16,749 [nnabla]: epoch 56 of 100 cost=0.379555  time=(3.2s /5.7s) 
2024-01-28 22:30:16,794 [nnabla]: epoch 57 of 100 cost=0.378729  time=(3.3s /5.7s) 
2024-01-28 22:30:16,839 [nnabla]: epoch 58 of 100 cost=0.354312  time=(3.3s /5.7s) 
2024-01-28 22:30:16,883 [nnabla]: epoch 59 of 100 cost=0.345431  time=(3.4s /5.7s) 
2024-01-28 22:30:16,985 [nnabla]: epoch 60 of 100 cost=0.329163  {train_error=0.263841, valid_error=0.265420} time=(3.4s /5.7s) 
2024-01-28 22:30:17,029 [nnabla]: epoch 61 of 100 cost=0.321735  time=(3.5s /5.7s) 
2024-01-28 22:30:17,075 [nnabla]: epoch 62 of 100 cost=0.318561  time=(3.5s /5.7s) 
2024-01-28 22:30:17,119 [nnabla]: epoch 63 of 100 cost=0.302802  time=(3.6s /5.7s) 
2024-01-28 22:30:17,164 [nnabla]: epoch 64 of 100 cost=0.296056  time=(3.6s /5.7s) 
2024-01-28 22:30:17,209 [nnabla]: epoch 65 of 100 cost=0.279595  time=(3.7s /5.7s) 
2024-01-28 22:30:17,254 [nnabla]: epoch 66 of 100 cost=0.282187  time=(3.7s /5.6s) 
2024-01-28 22:30:17,311 [nnabla]: epoch 67 of 100 cost=0.265977  time=(3.8s /5.6s) 
2024-01-28 22:30:17,356 [nnabla]: epoch 68 of 100 cost=0.253976  time=(3.8s /5.6s) 
2024-01-28 22:30:17,400 [nnabla]: epoch 69 of 100 cost=0.245828  time=(3.9s /5.6s) 
2024-01-28 22:30:17,502 [nnabla]: epoch 70 of 100 cost=0.243765  {train_error=0.175394, valid_error=0.180548} time=(3.9s /5.6s) 
2024-01-28 22:30:17,546 [nnabla]: epoch 71 of 100 cost=0.231428  time=(4.0s /5.7s) 
2024-01-28 22:30:17,591 [nnabla]: epoch 72 of 100 cost=0.226366  time=(4.1s /5.6s) 
2024-01-28 22:30:17,637 [nnabla]: epoch 73 of 100 cost=0.221041  time=(4.1s /5.6s) 
2024-01-28 22:30:17,680 [nnabla]: epoch 74 of 100 cost=0.216105  time=(4.1s /5.6s) 
2024-01-28 22:30:17,725 [nnabla]: epoch 75 of 100 cost=0.203869  time=(4.2s /5.6s) 
2024-01-28 22:30:17,777 [nnabla]: epoch 76 of 100 cost=0.198348  time=(4.2s /5.6s) 
2024-01-28 22:30:17,825 [nnabla]: epoch 77 of 100 cost=0.195632  time=(4.3s /5.6s) 
2024-01-28 22:30:17,877 [nnabla]: epoch 78 of 100 cost=0.192983  time=(4.3s /5.6s) 
2024-01-28 22:30:17,921 [nnabla]: epoch 79 of 100 cost=0.181911  time=(4.4s /5.6s) 
2024-01-28 22:30:18,022 [nnabla]: epoch 80 of 100 cost=0.178693  {train_error=0.130250, valid_error=0.134642} time=(4.4s /5.5s) 
2024-01-28 22:30:18,067 [nnabla]: epoch 81 of 100 cost=0.179217  time=(4.5s /5.6s) 
2024-01-28 22:30:18,114 [nnabla]: epoch 82 of 100 cost=0.171185  time=(4.6s /5.6s) 
2024-01-28 22:30:18,160 [nnabla]: epoch 83 of 100 cost=0.166950  time=(4.6s /5.6s) 
2024-01-28 22:30:18,206 [nnabla]: epoch 84 of 100 cost=0.164778  time=(4.7s /5.6s) 
2024-01-28 22:30:18,252 [nnabla]: epoch 85 of 100 cost=0.151858  time=(4.7s /5.6s) 
2024-01-28 22:30:18,298 [nnabla]: epoch 86 of 100 cost=0.155691  time=(4.8s /5.5s) 
2024-01-28 22:30:18,343 [nnabla]: epoch 87 of 100 cost=0.148872  time=(4.8s /5.5s) 
2024-01-28 22:30:18,387 [nnabla]: epoch 88 of 100 cost=0.150593  time=(4.9s /5.5s) 
2024-01-28 22:30:18,442 [nnabla]: epoch 89 of 100 cost=0.142391  time=(4.9s /5.5s) 
2024-01-28 22:30:18,544 [nnabla]: epoch 90 of 100 cost=0.141752  {train_error=0.095660, valid_error=0.099951} time=(5.0s /5.5s) 
2024-01-28 22:30:18,590 [nnabla]: epoch 91 of 100 cost=0.139432  time=(5.1s /5.6s) 
2024-01-28 22:30:18,633 [nnabla]: epoch 92 of 100 cost=0.128109  time=(5.1s /5.5s) 
2024-01-28 22:30:18,679 [nnabla]: epoch 93 of 100 cost=0.133039  time=(5.1s /5.5s) 
2024-01-28 22:30:18,723 [nnabla]: epoch 94 of 100 cost=0.123450  time=(5.2s /5.5s) 
2024-01-28 22:30:18,768 [nnabla]: epoch 95 of 100 cost=0.129534  time=(5.2s /5.5s) 
2024-01-28 22:30:18,814 [nnabla]: epoch 96 of 100 cost=0.115343  time=(5.3s /5.5s) 
2024-01-28 22:30:18,858 [nnabla]: epoch 97 of 100 cost=0.116793  time=(5.3s /5.5s) 
2024-01-28 22:30:18,902 [nnabla]: epoch 98 of 100 cost=0.113499  time=(5.4s /5.5s) 
2024-01-28 22:30:18,947 [nnabla]: epoch 99 of 100 cost=0.113398  time=(5.4s /5.5s) 
2024-01-28 22:30:19,067 [nnabla]: epoch 100 of 100 cost=0.110211  {train_error=0.071478, valid_error=0.074139} time=(5.5s /5.5s) 
2024-01-28 22:30:19,084 [nnabla]: Training Completed.
NNabla command line interface (Version:1.33.1, Build:230206070804, Callback:NNabla SSH callback module.)

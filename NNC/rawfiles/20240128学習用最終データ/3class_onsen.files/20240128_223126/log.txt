2024-01-28 22:31:26,341 Training process is started.
python "C:\Users\yamas\Desktop\tools\neural_network_console\libs\Python\Lib\site-packages\nnabla\utils\cli\cli.py" train
	-c "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_223126\net.nntxt"
	-o "C:\Users\yamas\Desktop\20240128\3class_onsen.files\20240128_223126"
2024-01-28 22:31:26,899 [nnabla]: [CALLBACK]: Exec train on local
2024-01-28 22:31:26,906 [nnabla]: Using context "Context(backend=['cpu:float'], array_class='CpuCachedArray', device_id='')"
2024-01-28 22:31:26,907 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_test_3class_onsen.csv"
2024-01-28 22:31:27,492 [nnabla]: Creating cache data for "C:\Users\yamas\Desktop\20240128\egg_data_set_valid_3class_onsen.csv"
2024-01-28 22:31:27,876 [nnabla]: Train with contexts ['cpu']
2024-01-28 22:31:27,895 [nnabla]: Training epoch 1 of 100 begin
2024-01-28 22:31:27,895 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 22:31:27,895 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-01-28 22:31:28,097 [nnabla]: epoch 1 of 100 cost=4.391605  {train_error=3.567992, valid_error=3.526202} time=(0.1s /9.2s) 
2024-01-28 22:31:28,185 [nnabla]: epoch 2 of 100 cost=3.760154  {train_error=3.456919, valid_error=3.439901} time=(0.2s /12.3s) 
2024-01-28 22:31:28,273 [nnabla]: epoch 3 of 100 cost=3.493749  {train_error=3.276012, valid_error=3.272948} time=(0.3s /11.1s) 
2024-01-28 22:31:28,357 [nnabla]: epoch 4 of 100 cost=3.301589  {train_error=3.080209, valid_error=3.078602} time=(0.4s /10.5s) 
2024-01-28 22:31:28,451 [nnabla]: epoch 5 of 100 cost=3.123417  {train_error=2.920953, valid_error=2.934440} time=(0.5s /10.1s) 
2024-01-28 22:31:28,493 [nnabla]: epoch 6 of 100 cost=2.977420  time=(0.6s /10.0s) 
2024-01-28 22:31:28,534 [nnabla]: epoch 7 of 100 cost=2.834846  time=(0.6s /9.1s) 
2024-01-28 22:31:28,576 [nnabla]: epoch 8 of 100 cost=2.712061  time=(0.7s /8.5s) 
2024-01-28 22:31:28,616 [nnabla]: epoch 9 of 100 cost=2.606650  time=(0.7s /8.0s) 
2024-01-28 22:31:28,709 [nnabla]: epoch 10 of 100 cost=2.516929  {train_error=2.361070, valid_error=2.388407} time=(0.8s /7.6s) 
2024-01-28 22:31:28,750 [nnabla]: epoch 11 of 100 cost=2.423671  time=(0.9s /7.8s) 
2024-01-28 22:31:28,799 [nnabla]: epoch 12 of 100 cost=2.338752  time=(0.9s /7.5s) 
2024-01-28 22:31:28,840 [nnabla]: epoch 13 of 100 cost=2.259538  time=(0.9s /7.3s) 
2024-01-28 22:31:28,881 [nnabla]: epoch 14 of 100 cost=2.168731  time=(1.0s /7.0s) 
2024-01-28 22:31:28,922 [nnabla]: epoch 15 of 100 cost=2.088028  time=(1.0s /6.8s) 
2024-01-28 22:31:28,962 [nnabla]: epoch 16 of 100 cost=2.016156  time=(1.1s /6.7s) 
2024-01-28 22:31:29,004 [nnabla]: epoch 17 of 100 cost=1.933619  time=(1.1s /6.5s) 
2024-01-28 22:31:29,045 [nnabla]: epoch 18 of 100 cost=1.865781  time=(1.1s /6.4s) 
2024-01-28 22:31:29,088 [nnabla]: epoch 19 of 100 cost=1.779248  time=(1.2s /6.3s) 
2024-01-28 22:31:29,179 [nnabla]: epoch 20 of 100 cost=1.727490  {train_error=1.571713, valid_error=1.600347} time=(1.2s /6.2s) 
2024-01-28 22:31:29,221 [nnabla]: epoch 21 of 100 cost=1.642357  time=(1.3s /6.3s) 
2024-01-28 22:31:29,261 [nnabla]: epoch 22 of 100 cost=1.581489  time=(1.4s /6.2s) 
2024-01-28 22:31:29,310 [nnabla]: epoch 23 of 100 cost=1.507099  time=(1.4s /6.1s) 
2024-01-28 22:31:29,350 [nnabla]: epoch 24 of 100 cost=1.446208  time=(1.5s /6.1s) 
2024-01-28 22:31:29,390 [nnabla]: epoch 25 of 100 cost=1.391448  time=(1.5s /6.0s) 
2024-01-28 22:31:29,432 [nnabla]: epoch 26 of 100 cost=1.318408  time=(1.5s /5.9s) 
2024-01-28 22:31:29,472 [nnabla]: epoch 27 of 100 cost=1.281548  time=(1.6s /5.8s) 
2024-01-28 22:31:29,511 [nnabla]: epoch 28 of 100 cost=1.218326  time=(1.6s /5.8s) 
2024-01-28 22:31:29,552 [nnabla]: epoch 29 of 100 cost=1.174302  time=(1.7s /5.7s) 
2024-01-28 22:31:29,647 [nnabla]: epoch 30 of 100 cost=1.103972  {train_error=0.985164, valid_error=1.002580} time=(1.7s /5.7s) 
2024-01-28 22:31:29,688 [nnabla]: epoch 31 of 100 cost=1.062715  time=(1.8s /5.8s) 
2024-01-28 22:31:29,727 [nnabla]: epoch 32 of 100 cost=1.008079  time=(1.8s /5.7s) 
2024-01-28 22:31:29,767 [nnabla]: epoch 33 of 100 cost=0.961468  time=(1.9s /5.7s) 
2024-01-28 22:31:29,817 [nnabla]: epoch 34 of 100 cost=0.926958  time=(1.9s /5.6s) 
2024-01-28 22:31:29,860 [nnabla]: epoch 35 of 100 cost=0.877289  time=(2.0s /5.6s) 
2024-01-28 22:31:29,900 [nnabla]: epoch 36 of 100 cost=0.835073  time=(2.0s /5.6s) 
2024-01-28 22:31:29,941 [nnabla]: epoch 37 of 100 cost=0.818815  time=(2.0s /5.5s) 
2024-01-28 22:31:29,981 [nnabla]: epoch 38 of 100 cost=0.783177  time=(2.1s /5.5s) 
2024-01-28 22:31:30,022 [nnabla]: epoch 39 of 100 cost=0.726896  time=(2.1s /5.5s) 
2024-01-28 22:31:30,118 [nnabla]: epoch 40 of 100 cost=0.701619  {train_error=0.586063, valid_error=0.590393} time=(2.2s /5.4s) 
2024-01-28 22:31:30,159 [nnabla]: epoch 41 of 100 cost=0.667171  time=(2.3s /5.5s) 
2024-01-28 22:31:30,200 [nnabla]: epoch 42 of 100 cost=0.641229  time=(2.3s /5.5s) 
2024-01-28 22:31:30,242 [nnabla]: epoch 43 of 100 cost=0.617767  time=(2.3s /5.5s) 
2024-01-28 22:31:30,282 [nnabla]: epoch 44 of 100 cost=0.580842  time=(2.4s /5.4s) 
2024-01-28 22:31:30,344 [nnabla]: epoch 45 of 100 cost=0.556304  time=(2.4s /5.4s) 
2024-01-28 22:31:30,384 [nnabla]: epoch 46 of 100 cost=0.542209  time=(2.5s /5.4s) 
2024-01-28 22:31:30,425 [nnabla]: epoch 47 of 100 cost=0.515490  time=(2.5s /5.4s) 
2024-01-28 22:31:30,465 [nnabla]: epoch 48 of 100 cost=0.493463  time=(2.6s /5.4s) 
2024-01-28 22:31:30,507 [nnabla]: epoch 49 of 100 cost=0.473761  time=(2.6s /5.3s) 
2024-01-28 22:31:30,607 [nnabla]: epoch 50 of 100 cost=0.450640  {train_error=0.370995, valid_error=0.375520} time=(2.7s /5.3s) 
2024-01-28 22:31:30,646 [nnabla]: epoch 51 of 100 cost=0.443114  time=(2.8s /5.4s) 
2024-01-28 22:31:30,686 [nnabla]: epoch 52 of 100 cost=0.421814  time=(2.8s /5.4s) 
2024-01-28 22:31:30,728 [nnabla]: epoch 53 of 100 cost=0.408269  time=(2.8s /5.3s) 
2024-01-28 22:31:30,770 [nnabla]: epoch 54 of 100 cost=0.387774  time=(2.9s /5.3s) 
2024-01-28 22:31:30,809 [nnabla]: epoch 55 of 100 cost=0.375946  time=(2.9s /5.3s) 
2024-01-28 22:31:30,861 [nnabla]: epoch 56 of 100 cost=0.351102  time=(3.0s /5.3s) 
2024-01-28 22:31:30,902 [nnabla]: epoch 57 of 100 cost=0.350367  time=(3.0s /5.3s) 
2024-01-28 22:31:30,943 [nnabla]: epoch 58 of 100 cost=0.330216  time=(3.0s /5.3s) 
2024-01-28 22:31:30,983 [nnabla]: epoch 59 of 100 cost=0.318880  time=(3.1s /5.2s) 
2024-01-28 22:31:31,077 [nnabla]: epoch 60 of 100 cost=0.306614  {train_error=0.251470, valid_error=0.254228} time=(3.1s /5.2s) 
2024-01-28 22:31:31,122 [nnabla]: epoch 61 of 100 cost=0.302489  time=(3.2s /5.3s) 
2024-01-28 22:31:31,161 [nnabla]: epoch 62 of 100 cost=0.294731  time=(3.3s /5.3s) 
2024-01-28 22:31:31,201 [nnabla]: epoch 63 of 100 cost=0.283761  time=(3.3s /5.2s) 
2024-01-28 22:31:31,242 [nnabla]: epoch 64 of 100 cost=0.278783  time=(3.3s /5.2s) 
2024-01-28 22:31:31,283 [nnabla]: epoch 65 of 100 cost=0.264981  time=(3.4s /5.2s) 
2024-01-28 22:31:31,325 [nnabla]: epoch 66 of 100 cost=0.258414  time=(3.4s /5.2s) 
2024-01-28 22:31:31,377 [nnabla]: epoch 67 of 100 cost=0.244091  time=(3.5s /5.2s) 
2024-01-28 22:31:31,417 [nnabla]: epoch 68 of 100 cost=0.235559  time=(3.5s /5.2s) 
2024-01-28 22:31:31,460 [nnabla]: epoch 69 of 100 cost=0.229772  time=(3.6s /5.2s) 
2024-01-28 22:31:31,557 [nnabla]: epoch 70 of 100 cost=0.236413  {train_error=0.174600, valid_error=0.176203} time=(3.6s /5.2s) 
2024-01-28 22:31:31,600 [nnabla]: epoch 71 of 100 cost=0.217310  time=(3.7s /5.2s) 
2024-01-28 22:31:31,641 [nnabla]: epoch 72 of 100 cost=0.213359  time=(3.7s /5.2s) 
2024-01-28 22:31:31,680 [nnabla]: epoch 73 of 100 cost=0.205119  time=(3.8s /5.2s) 
2024-01-28 22:31:31,721 [nnabla]: epoch 74 of 100 cost=0.199237  time=(3.8s /5.2s) 
2024-01-28 22:31:31,762 [nnabla]: epoch 75 of 100 cost=0.189490  time=(3.9s /5.2s) 
2024-01-28 22:31:31,803 [nnabla]: epoch 76 of 100 cost=0.187545  time=(3.9s /5.1s) 
2024-01-28 22:31:31,845 [nnabla]: epoch 77 of 100 cost=0.181336  time=(4.0s /5.1s) 
2024-01-28 22:31:31,896 [nnabla]: epoch 78 of 100 cost=0.180056  time=(4.0s /5.1s) 
2024-01-28 22:31:31,939 [nnabla]: epoch 79 of 100 cost=0.170276  time=(4.0s /5.1s) 
2024-01-28 22:31:32,029 [nnabla]: epoch 80 of 100 cost=0.168796  {train_error=0.128836, valid_error=0.130328} time=(4.1s /5.1s) 
2024-01-28 22:31:32,072 [nnabla]: epoch 81 of 100 cost=0.165842  time=(4.2s /5.2s) 
2024-01-28 22:31:32,113 [nnabla]: epoch 82 of 100 cost=0.160640  time=(4.2s /5.1s) 
2024-01-28 22:31:32,153 [nnabla]: epoch 83 of 100 cost=0.155059  time=(4.3s /5.1s) 
2024-01-28 22:31:32,194 [nnabla]: epoch 84 of 100 cost=0.153455  time=(4.3s /5.1s) 
2024-01-28 22:31:32,234 [nnabla]: epoch 85 of 100 cost=0.142079  time=(4.3s /5.1s) 
2024-01-28 22:31:32,275 [nnabla]: epoch 86 of 100 cost=0.153025  time=(4.4s /5.1s) 
2024-01-28 22:31:32,316 [nnabla]: epoch 87 of 100 cost=0.140633  time=(4.4s /5.1s) 
2024-01-28 22:31:32,357 [nnabla]: epoch 88 of 100 cost=0.142232  time=(4.5s /5.1s) 
2024-01-28 22:31:32,408 [nnabla]: epoch 89 of 100 cost=0.132683  time=(4.5s /5.1s) 
2024-01-28 22:31:32,501 [nnabla]: epoch 90 of 100 cost=0.131313  {train_error=0.093477, valid_error=0.094690} time=(4.6s /5.1s) 
2024-01-28 22:31:32,543 [nnabla]: epoch 91 of 100 cost=0.131013  time=(4.6s /5.1s) 
2024-01-28 22:31:32,582 [nnabla]: epoch 92 of 100 cost=0.128616  time=(4.7s /5.1s) 
2024-01-28 22:31:32,623 [nnabla]: epoch 93 of 100 cost=0.123698  time=(4.7s /5.1s) 
2024-01-28 22:31:32,663 [nnabla]: epoch 94 of 100 cost=0.115075  time=(4.8s /5.1s) 
2024-01-28 22:31:32,705 [nnabla]: epoch 95 of 100 cost=0.122108  time=(4.8s /5.1s) 
2024-01-28 22:31:32,747 [nnabla]: epoch 96 of 100 cost=0.111259  time=(4.9s /5.1s) 
2024-01-28 22:31:32,787 [nnabla]: epoch 97 of 100 cost=0.113338  time=(4.9s /5.0s) 
2024-01-28 22:31:32,829 [nnabla]: epoch 98 of 100 cost=0.109860  time=(4.9s /5.0s) 
2024-01-28 22:31:32,869 [nnabla]: epoch 99 of 100 cost=0.106817  time=(5.0s /5.0s) 
2024-01-28 22:31:32,980 [nnabla]: epoch 100 of 100 cost=0.103000  {train_error=0.075768, valid_error=0.076260} time=(5.0s /5.0s) 
2024-01-28 22:31:32,998 [nnabla]: Training Completed.
NNabla command line interface (Version:1.33.1, Build:230206070804, Callback:NNabla SSH callback module.)
